{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import matplotlib.pyplot as plt\n",
    "import GPy\n",
    "import GPyOpt\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "class Model:\n",
    "    # Network Parameters\n",
    "    # n_neurons, learning_rate, num_layers, rnn_type(RNN|BasicLSTM|LSTM|LSTM peelhole)\n",
    "    # Control Parameters\n",
    "    # risk_aversion - the margin added to the courtage that leads an buy or sell operation\n",
    "    # learning_period - how many sequences model should learn before predicting next sequences\n",
    "    # prediction_period - how many sequences the model should predict\n",
    "    # max_repeats - how many times in maximum the model should learn\n",
    "    # min_profit - what is the minimum profit in average during training phase, if the minimum is not reached, the model should not predict\n",
    "    # gamma - what is the gamma used when preprocessing data\n",
    "    \n",
    "    step_profit_list = []\n",
    "    mixed_domain = [{'name': 'n_neurons', 'type': 'discrete', 'domain': tuple(range(20,160,20))},\n",
    "          {'name': 'learning_rate', 'type': 'discrete', 'domain': (0.001,0.002,0.003,0.004)},\n",
    "          {'name': 'num_layers', 'type': 'discrete', 'domain': (1,2,3,4)},\n",
    "          {'name': 'rnn_type', 'type': 'discrete', 'domain': (0,1,2)},\n",
    "          {'name': 'learning_period', 'type': 'discrete', 'domain': tuple(range(10,40,10))},\n",
    "          {'name': 'prediction_period', 'type': 'discrete', 'domain': tuple(range(5,10,5))},\n",
    "          {'name': 'max_repeats', 'type': 'discrete', 'domain': tuple(range(1,50,10))},\n",
    "          {'name': 'beta', 'type': 'discrete', 'domain': (99, 98)},\n",
    "          {'name': 'ema', 'type': 'discrete', 'domain': (10,20)},\n",
    "          {'name': 'time_input', 'type': 'discrete', 'domain': (0,1)},\n",
    "         ]\n",
    "    def __init__(self, regen):\n",
    "        if regen == False:\n",
    "            return\n",
    "        def column_filter(x):\n",
    "            if x == 'stepofweek':\n",
    "                return True\n",
    "            elif 'diff_ema' in x:\n",
    "                return True\n",
    "            elif 'volume' in x:\n",
    "                return True\n",
    "            elif 'value_ema' in x:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        for ema in (10, 20):\n",
    "            for beta in (99, 98):\n",
    "                filename = \"data-prep-ema{}-beta{}.csv\".format(ema, beta)\n",
    "                print(\"pre-processing {}\".format(filename))\n",
    "                data = pd.read_csv(filename, parse_dates=[\"timestamp\"])\n",
    "                data['dayofweek'] = data['timestamp'].apply(lambda x: x.weekday())\n",
    "                groups = data.set_index('timestamp').groupby(lambda x: x.date())\n",
    "                \n",
    "                # get maximum steps\n",
    "                max_steps = 0\n",
    "                for index, df in groups:\n",
    "                    df_len = len(df)\n",
    "                    if df_len > max_steps:\n",
    "                        max_steps = df_len\n",
    "                        \n",
    "                np_data = np.zeros((len(groups), max_steps, 30*3+1))\n",
    "                filtered_columns = list(filter(column_filter, data.columns))\n",
    "\n",
    "                i = 0\n",
    "                for index, df in groups:\n",
    "                    df['stepofday'] = np.arange(0, max_steps)\n",
    "                    df['stepofweek'] = df['dayofweek'] * max_steps + df['stepofday']\n",
    "                    np_data[i] = df[['stepofweek'] + filtered_columns ].to_numpy()\n",
    "\n",
    "                    i += 1\n",
    "                    \n",
    "                numpy_file_name = \"np_ema{}_beta{}.npz\".format(ema, beta)\n",
    "                np.savez_compressed(numpy_file_name, np_data)\n",
    "                \n",
    "\n",
    "        return\n",
    "        \n",
    "    def get_parameter_str(self, X):\n",
    "        parameter_str = \"\"\n",
    "        for i in range(len(self.mixed_domain)):\n",
    "            parameter_str += self.mixed_domain[i][\"name\"]\n",
    "            parameter_str += ':'\n",
    "            parameter_str += str(X[i])\n",
    "            parameter_str += ','\n",
    "        return parameter_str\n",
    "    \n",
    "    def reset_graph(self, seed=42):\n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    \n",
    "    def log(self, verbose, msg):\n",
    "        if verbose:\n",
    "            print(msg)\n",
    "\n",
    "    def get_batch(self, seq_index, data_train_input, data_train_output):\n",
    "        X_batch = data_train_input[seq_index:seq_index+1]\n",
    "        y_batch = data_train_output[seq_index:seq_index+1]\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def transform(self, data_all, n_inputs, n_outputs):\n",
    "        orig_shape = data_all.shape\n",
    "        data_train_reshape = data_all.reshape((orig_shape[0] * orig_shape[1], orig_shape[2]))\n",
    "        \n",
    "        self.scaler_input = preprocessing.MinMaxScaler().fit(data_train_reshape[:,:n_inputs])\n",
    "        data_train_input_scaled = self.scaler_input.transform(data_train_reshape[:,:n_inputs])\n",
    "        \n",
    "        # the invalid step, we change it to zero!\n",
    "        data_train_input_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "        data_train_input = data_train_input_scaled.reshape(orig_shape[0], orig_shape[1], n_inputs)\n",
    "        \n",
    "        self.scaler_output = preprocessing.MinMaxScaler().fit(data_train_reshape[:,-n_outputs:])\n",
    "        data_train_output_scaled = self.scaler_output.transform(data_train_reshape[:,-n_outputs:])\n",
    "        # the invalid step, we change it to zero!\n",
    "        data_train_output_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "        data_train_output = data_train_output_scaled.reshape(orig_shape[0], orig_shape[1], n_outputs)\n",
    "        \n",
    "        return data_train_input, data_train_output\n",
    "    \n",
    "    def inverse_transform_output(self, scaled_outputs):\n",
    "        outputs_reshaped = scaled_outputs.reshape((scaled_outputs.shape[1], scaled_outputs.shape[2]))\n",
    "        #outputs = np.exp(self.scaler_output.inverse_transform(outputs_reshaped)) - 1\n",
    "        outputs = self.scaler_output.inverse_transform(outputs_reshaped)\n",
    "        return outputs\n",
    "    \n",
    "    def inverse_transform_input(self, scaled_inputs):\n",
    "        inputs_reshaped = scaled_inputs.reshape((scaled_inputs.shape[1], scaled_inputs.shape[2]))\n",
    "        #inputs_reshaped[:,4:6] = np.exp(self.scaler_input.inverse_transform(inputs_reshaped)[:,4:6]) - 1\n",
    "        inputs = self.scaler_input.inverse_transform(inputs_reshaped)\n",
    "        # TODO: the volume and hold should be transformed back.\n",
    "        return inputs\n",
    "        \n",
    "        \n",
    "    def get_answer(self, features):\n",
    "        n_neurons = int(features[0])\n",
    "        learning_rate = features[1]\n",
    "        num_layers = int(features[2])\n",
    "        rnn_type = int(features[3])\n",
    "        learning_period = int(features[4])\n",
    "        prediction_period = int(features[5])\n",
    "        max_repeats = int(features[6])\n",
    "        beta = int(features[7])\n",
    "        ema = int(features[8])\n",
    "        time_input = int(features[9])\n",
    "\n",
    "        # load data\n",
    "        file_name = \"np_ema{}_beta{}.npz\".format(ema, beta)\n",
    "        data_all = np.load(file_name)['arr_0']\n",
    "        print(data_all)\n",
    "        # pick the data for stock_id\n",
    "        stock_index = 20\n",
    "        n_inputs = 1\n",
    "        if time_input != 0:\n",
    "            n_inputs += 1\n",
    "        n_outputs = 1\n",
    "        \n",
    "        # we must convert the array to 2D\n",
    "        orig_shape = data_all.shape\n",
    "        print(\"original shape: \")\n",
    "        print(orig_shape)\n",
    "        reshaped_data = data_all.reshape((orig_shape[0] * orig_shape[1], orig_shape[2]))\n",
    "        \n",
    "        input_column_list = [1 + 30 + stock_index]\n",
    "        if time_input != 0:\n",
    "            input_column_list = [0] + input_column_list\n",
    "        output_column_list = [1 + 60 + stock_index]\n",
    "        \n",
    "        data_filtered = reshaped_data[:, input_column_list + output_column_list].reshape((orig_shape[0], orig_shape[1], n_inputs+n_outputs))\n",
    "        \n",
    "\n",
    "        batch_size = 1\n",
    "        data_train_input, data_train_output = self.transform(data_filtered, n_inputs, n_outputs)\n",
    "\n",
    "        # data_train_input in the shape [seq, steps, features]\n",
    "        days = data_train_input.shape[0]\n",
    "        max_steps = data_train_input.shape[1]\n",
    "\n",
    "        self.reset_graph()\n",
    "        \n",
    "        X = tf.placeholder(tf.float32, [None, max_steps, n_inputs])\n",
    "        y = tf.placeholder(tf.float32, [None, max_steps, n_outputs])\n",
    "        \n",
    "        layers = None\n",
    "        if rnn_type == 0:\n",
    "            layers = [tf.nn.rnn_cell.BasicLSTMCell(n_neurons) \n",
    "              for _ in range(num_layers)]\n",
    "        elif rnn_type == 1:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(n_neurons, use_peepholes=False) \n",
    "              for _ in range(num_layers)]\n",
    "        elif rnn_type == 2:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(n_neurons, use_peepholes=True) \n",
    "              for _ in range(num_layers)]\n",
    "        else:\n",
    "            print(\"WRONG\")\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "        \n",
    "        # For each layer, get the initial state. states will be a tuple of LSTMStateTuples.\n",
    "        init_state = tf.placeholder(tf.float32, [num_layers, 2, batch_size, n_neurons])\n",
    "        state_per_layer_list = tf.unstack(init_state, axis=0)\n",
    "        rnn_tuple_state = tuple(\n",
    "            [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "             for idx in range(num_layers)]\n",
    "        )\n",
    "\n",
    "        rnn_outputs, new_states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32, \n",
    "                                                    initial_state=rnn_tuple_state)\n",
    "        \n",
    "        stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "        stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "        outputs = tf.reshape(stacked_outputs, [-1, max_steps, n_outputs])\n",
    "        \n",
    "        \n",
    "        loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # now run the model to get answer:\n",
    "        rnn_states_after_training = np.zeros((num_layers, 2, batch_size, n_neurons))\n",
    "        asset = 1\n",
    "        market_asset = 1\n",
    "        graph_data = []\n",
    "        my_loss_test_list = []\n",
    "        with tf.Session() as sess:\n",
    "            init.run()\n",
    "            for learn_end_seq in range(learning_period, \n",
    "                                       days - prediction_period, \n",
    "                                       prediction_period):\n",
    "                learning_start_seq = learn_end_seq - learning_period\n",
    "                for repeat in range(max_repeats):\n",
    "                    rnn_states = copy.deepcopy(rnn_states_after_training)\n",
    "                    my_loss_train_list = []\n",
    "                    train_asset = 1\n",
    "                    for seq in range(learning_start_seq, learn_end_seq):\n",
    "                        X_batch, y_batch = self.get_batch(seq, data_train_input, data_train_output)\n",
    "                        feed_dict = {\n",
    "                            X: X_batch,\n",
    "                            y: y_batch,\n",
    "                            init_state: rnn_states_after_training\n",
    "                        }\n",
    "                        \n",
    "                        my_op, my_new_states, my_loss_train, my_outputs = sess.run([training_op, new_states, loss, outputs], feed_dict=feed_dict)\n",
    "                        my_loss_train_list.append(my_loss_train)\n",
    "                        rnn_states = my_new_states\n",
    "                        \n",
    "                    my_loss_train_avg = sum(my_loss_train_list) / len(my_loss_train_list)\n",
    "                    print(\"sequence:{} - {} repeat={} training finished, training MSE={} training asset={}\".format(learning_start_seq, learn_end_seq, repeat, my_loss_train_avg, train_asset))\n",
    "                # backup the states after training.\n",
    "                rnn_states_after_training = copy.deepcopy(rnn_states)\n",
    "                \n",
    "                \n",
    "                for seq in range(learn_end_seq, learn_end_seq + prediction_period):\n",
    "                    X_test, y_test = self.get_batch(seq, data_train_input, data_train_output)\n",
    "                    feed_dict = {\n",
    "                        X: X_test,\n",
    "                        y: y_test,\n",
    "                        init_state: rnn_states,\n",
    "                    }\n",
    "            \n",
    "                    my_new_states, my_loss_test, my_outputs = sess.run([new_states, loss, outputs], feed_dict=feed_dict)\n",
    "                    my_loss_test_list.append(my_loss_test)\n",
    "                    \n",
    "                    print(\"sequence:{} test finished, testing MSE={}\".format(seq, my_loss_test))\n",
    "                    rnn_states = my_new_states\n",
    "            my_loss_test_avg = sum(my_loss_test_list)/len(my_loss_test_list)\n",
    "            return my_loss_test_avg\n",
    "                    \n",
    "    def opt_wrapper(self, X_list):\n",
    "        answer = np.zeros((X_list.shape[0], 1))\n",
    "        for i in range(len(X_list)):\n",
    "            print(self.get_parameter_str(X_list[i]))\n",
    "            features = X_list[i]\n",
    "            answer[i][0] = self.get_answer(features)\n",
    "            #self.draw_step_profit_graph(self.step_profit_list, \"step_profit_{}\".format(answer[i][0]))\n",
    "            #self.step_profit_list = []\n",
    "            if answer[i][0] < self.min_answer:\n",
    "                print(\"find new opt:{}, {}\".format(answer[i][0], self.get_parameter_str(X_list[i])))\n",
    "                self.min_answer = answer[i][0]\n",
    "        return answer\n",
    "                \n",
    "        \n",
    "    def optimize(self, max_iter=300):\n",
    "        self.min_answer = 999\n",
    "        myBopt = GPyOpt.methods.BayesianOptimization(f=self.opt_wrapper,  # Objective function       \n",
    "                                             domain=self.mixed_domain,          # Box-constraints of the problem\n",
    "                                             initial_design_numdata = 20,   # Number data initial design\n",
    "                                             acquisition_type='EI',        # Expected Improvement\n",
    "                                             exact_feval = True)           # True evaluations, no sample noise\n",
    "        \n",
    "        myBopt.run_optimization(max_iter,eps=0)\n",
    "    \n",
    "    \n",
    "    # no optimize, we have already know the answer.\n",
    "    def run(self, n_neurons, learning_rate, \n",
    "            num_layers, rnn_type, risk_aversion, \n",
    "            learning_period, prediction_period, \n",
    "            max_repeats, min_profit, gamma):\n",
    "        features = [n_neurons, learning_rate, \n",
    "            num_layers, rnn_type, risk_aversion, \n",
    "            learning_period, prediction_period, \n",
    "            max_repeats, min_profit, gamma]\n",
    "        \n",
    "        answer = self.get_answer(features)\n",
    "        print(\"Finished, result:{}\".format(answer))\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neurons:140.0,learning_rate:0.002,num_layers:4.0,rnn_type:1.0,learning_period:20.0,prediction_period:5.0,max_repeats:9.0,beta:99.0,ema:10.0,time_input:0.0,\n",
      "[[[ 0.00000000e+00  3.36630000e+04  3.50900000e+03 ... -2.75575771e-03\n",
      "    2.03892795e-03  2.44253149e-03]\n",
      "  [ 1.00000000e+00  3.54190000e+04  2.20800000e+03 ... -1.76662947e-03\n",
      "    2.66519482e-03  2.62658406e-03]\n",
      "  [ 2.00000000e+00  1.55190000e+04  1.29890000e+04 ... -1.15381224e-03\n",
      "    2.96596715e-03  2.53920044e-03]\n",
      "  ...\n",
      "  [ 5.01000000e+02  1.10300000e+04  3.17700000e+03 ... -4.94910876e-04\n",
      "   -4.28745143e-04 -2.47870817e-04]\n",
      "  [ 5.02000000e+02  1.01710000e+04  4.75000000e+02 ... -1.77983619e-04\n",
      "   -2.39075745e-04 -1.12053011e-04]\n",
      "  [ 5.03000000e+02  2.03350000e+04  7.85100000e+03 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 5.04000000e+02  1.34970000e+04  3.86800000e+03 ...  1.47206372e-03\n",
      "    5.38031508e-04 -3.06835228e-03]\n",
      "  [ 5.05000000e+02  4.80960000e+04  1.50100000e+03 ...  1.34941244e-03\n",
      "    9.35052190e-04 -3.07480296e-03]\n",
      "  [ 5.06000000e+02  6.03300000e+03  1.50400000e+03 ...  8.81288386e-04\n",
      "    1.73067218e-03 -2.92057272e-03]\n",
      "  ...\n",
      "  [ 1.00500000e+03  4.76200000e+04  6.12000000e+03 ... -5.78988471e-06\n",
      "    1.72708465e-04 -5.16868122e-04]\n",
      "  [ 1.00600000e+03  3.08400000e+04  7.82600000e+03 ...  1.99686752e-05\n",
      "    1.50562452e-04 -2.33672204e-04]\n",
      "  [ 1.00700000e+03  1.55940000e+04  2.91200000e+03 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.00800000e+03  7.51100000e+03  3.15550000e+04 ...  2.19000162e-03\n",
      "   -4.86055217e-03  1.30710416e-03]\n",
      "  [ 1.00900000e+03  9.06900000e+03  6.70700000e+03 ...  5.13679974e-04\n",
      "   -5.83975229e-03  6.95581738e-04]\n",
      "  [ 1.01000000e+03  2.49290000e+04  2.00000000e+02 ... -6.91472196e-04\n",
      "   -6.57881338e-03  1.83617799e-04]\n",
      "  ...\n",
      "  [ 1.50900000e+03  1.00110000e+04  1.95700000e+03 ... -1.40159596e-04\n",
      "    5.22423604e-04 -4.35663920e-04]\n",
      "  [ 1.51000000e+03  1.49510000e+04  1.73600000e+03 ... -8.59035646e-05\n",
      "    2.65349703e-04 -2.86808996e-04]\n",
      "  [ 1.51100000e+03  2.45370000e+04  8.52200000e+03 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.00000000e+00  3.37720000e+04  4.17100000e+03 ... -1.46977182e-03\n",
      "   -2.36479345e-03 -4.57177871e-03]\n",
      "  [ 1.00000000e+00  1.02770000e+04  2.82480000e+04 ... -1.18909447e-03\n",
      "   -2.07742755e-03 -4.05790466e-03]\n",
      "  [ 2.00000000e+00  4.60800000e+03  6.60000000e+02 ... -8.94532781e-04\n",
      "   -1.69557367e-03 -3.76053257e-03]\n",
      "  ...\n",
      "  [ 5.01000000e+02  2.40640000e+04  7.42000000e+02 ...  2.31721841e-05\n",
      "   -3.51641558e-04 -2.49035102e-05]\n",
      "  [ 5.02000000e+02  3.64170000e+04  3.23700000e+03 ...  1.27990223e-04\n",
      "   -2.80613884e-04 -1.12573072e-05]\n",
      "  [ 5.03000000e+02  2.64010000e+04  7.63100000e+03 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 5.04000000e+02  1.08760000e+04  5.94000000e+02 ...  2.18473558e-04\n",
      "   -1.27439996e-03  1.13742555e-04]\n",
      "  [ 5.05000000e+02  4.41670000e+04  7.25300000e+03 ...  3.94835428e-04\n",
      "   -1.67129537e-03  4.78130248e-04]\n",
      "  [ 5.06000000e+02  7.88650000e+04  0.00000000e+00 ...  1.19439010e-03\n",
      "   -1.79580080e-03  1.49977195e-03]\n",
      "  ...\n",
      "  [ 1.00500000e+03  1.03370000e+04  4.84000000e+02 ... -3.64619150e-04\n",
      "   -2.90167625e-04 -2.16068094e-04]\n",
      "  [ 1.00600000e+03  6.75100000e+03  4.66000000e+03 ... -2.04692129e-04\n",
      "   -2.30073763e-04 -2.20902207e-04]\n",
      "  [ 1.00700000e+03  2.94390000e+04  3.30600000e+03 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.00800000e+03  5.54100000e+03  0.00000000e+00 ...  2.49629563e-03\n",
      "    2.15066505e-03  8.84140547e-05]\n",
      "  [ 1.00900000e+03  3.54000000e+03  0.00000000e+00 ...  2.64068134e-03\n",
      "    2.18910804e-03  7.67086609e-04]\n",
      "  [ 1.01000000e+03  3.49310000e+04  1.00000000e+00 ...  2.51314719e-03\n",
      "    2.23153945e-03  1.05830210e-03]\n",
      "  ...\n",
      "  [ 1.50900000e+03  3.05750000e+04  7.93100000e+03 ...  1.43711756e-04\n",
      "    2.42533514e-04  1.34486424e-04]\n",
      "  [ 1.51000000e+03  1.07840000e+04  8.63700000e+03 ...  6.49602905e-05\n",
      "    1.46591294e-04  1.01627135e-04]\n",
      "  [ 1.51100000e+03  3.80490000e+04  9.05300000e+03 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]]\n",
      "original shape: \n",
      "(53, 504, 91)\n",
      "sequence:0 - 20 repeat=0 training finished, training MSE=0.00802745613618754 training asset=1\n",
      "sequence:0 - 20 repeat=1 training finished, training MSE=0.0014849287836113945 training asset=1\n",
      "sequence:0 - 20 repeat=2 training finished, training MSE=0.0013470235950080677 training asset=1\n",
      "sequence:0 - 20 repeat=3 training finished, training MSE=0.001325701709720306 training asset=1\n",
      "sequence:0 - 20 repeat=4 training finished, training MSE=0.001321365506737493 training asset=1\n",
      "sequence:0 - 20 repeat=5 training finished, training MSE=0.001318666324368678 training asset=1\n",
      "sequence:0 - 20 repeat=6 training finished, training MSE=0.0013141536634066141 training asset=1\n",
      "sequence:0 - 20 repeat=7 training finished, training MSE=0.0013079701384413056 training asset=1\n",
      "sequence:0 - 20 repeat=8 training finished, training MSE=0.0012999466271139681 training asset=1\n",
      "sequence:20 test finished, testing MSE=0.0007731941877864301\n",
      "sequence:21 test finished, testing MSE=0.00046984953223727643\n",
      "sequence:22 test finished, testing MSE=0.0005271050031296909\n",
      "sequence:23 test finished, testing MSE=0.0006321114487946033\n",
      "sequence:24 test finished, testing MSE=0.0007611658074893057\n",
      "sequence:5 - 25 repeat=0 training finished, training MSE=0.0006492479718872346 training asset=1\n",
      "sequence:5 - 25 repeat=1 training finished, training MSE=0.0006737046292982996 training asset=1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-152a7c8a416d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-4cc4655f71c1>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, max_iter)\u001b[0m\n\u001b[1;32m    294\u001b[0m                                              \u001b[0minitial_design_numdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# Number data initial design\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                                              \u001b[0macquisition_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m# Expected Improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                                              exact_feval = True)           # True evaluations, no sample noise\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mmyBopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/methods/bayesian_optimization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, domain, constraints, cost_withGradients, model_type, X, Y, initial_design_numdata, initial_design_type, acquisition_type, normalize_Y, exact_feval, acquisition_optimizer_type, model_update_interval, evaluator_type, batch_size, num_cores, verbosity, verbosity_model, maximize, de_duplication, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_type\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minitial_design_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_numdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_design_numdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_design_chooser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# --- CHOOSE the model type. If an instance of a GPyOpt model is passed (possibly user defined), it is used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/methods/bayesian_optimization.py\u001b[0m in \u001b[0;36m_init_design_chooser\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_design\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_numdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;31m# Case 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/core/task/objective.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_procs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/core/task/objective.py\u001b[0m in \u001b[0;36m_eval_func\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mst_time\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mrlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mf_evals\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrlt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mcost_evals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-4cc4655f71c1>\u001b[0m in \u001b[0;36mopt_wrapper\u001b[0;34m(self, X_list)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameter_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;31m#self.draw_step_profit_graph(self.step_profit_list, \"step_profit_{}\".format(answer[i][0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;31m#self.step_profit_list = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-4cc4655f71c1>\u001b[0m in \u001b[0;36mget_answer\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    248\u001b[0m                         }\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                         \u001b[0mmy_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_new_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_loss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                         \u001b[0mmy_loss_train_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_loss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                         \u001b[0mrnn_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_new_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data-prep-ema10-beta99.csv\"\n",
    "print(\"pre-processing {}\".format(filename))\n",
    "data = pd.read_csv(filename, parse_dates=[\"timestamp\"])\n",
    "data['dayofweek'] = data['timestamp'].apply(lambda x: x.weekday())\n",
    "groups = data.set_index('timestamp').groupby(lambda x: x.date())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'timestamp',\n",
       " 'volume_0',\n",
       " 'volume_1',\n",
       " 'volume_2',\n",
       " 'volume_3',\n",
       " 'volume_4',\n",
       " 'volume_5',\n",
       " 'volume_6',\n",
       " 'volume_7',\n",
       " 'volume_8',\n",
       " 'volume_9',\n",
       " 'volume_10',\n",
       " 'volume_11',\n",
       " 'volume_12',\n",
       " 'volume_13',\n",
       " 'volume_14',\n",
       " 'volume_15',\n",
       " 'volume_16',\n",
       " 'volume_17',\n",
       " 'volume_18',\n",
       " 'volume_19',\n",
       " 'volume_20',\n",
       " 'volume_21',\n",
       " 'volume_22',\n",
       " 'volume_23',\n",
       " 'volume_24',\n",
       " 'volume_25',\n",
       " 'volume_26',\n",
       " 'volume_27',\n",
       " 'volume_28',\n",
       " 'volume_29',\n",
       " 'last_0',\n",
       " 'last_1',\n",
       " 'last_2',\n",
       " 'last_3',\n",
       " 'last_4',\n",
       " 'last_5',\n",
       " 'last_6',\n",
       " 'last_7',\n",
       " 'last_8',\n",
       " 'last_9',\n",
       " 'last_10',\n",
       " 'last_11',\n",
       " 'last_12',\n",
       " 'last_13',\n",
       " 'last_14',\n",
       " 'last_15',\n",
       " 'last_16',\n",
       " 'last_17',\n",
       " 'last_18',\n",
       " 'last_19',\n",
       " 'last_20',\n",
       " 'last_21',\n",
       " 'last_22',\n",
       " 'last_23',\n",
       " 'last_24',\n",
       " 'last_25',\n",
       " 'last_26',\n",
       " 'last_27',\n",
       " 'last_28',\n",
       " 'last_29',\n",
       " 'diff_ema_10_0',\n",
       " 'diff_ema_10_1',\n",
       " 'diff_ema_10_2',\n",
       " 'diff_ema_10_3',\n",
       " 'diff_ema_10_4',\n",
       " 'diff_ema_10_5',\n",
       " 'diff_ema_10_6',\n",
       " 'diff_ema_10_7',\n",
       " 'diff_ema_10_8',\n",
       " 'diff_ema_10_9',\n",
       " 'diff_ema_10_10',\n",
       " 'diff_ema_10_11',\n",
       " 'diff_ema_10_12',\n",
       " 'diff_ema_10_13',\n",
       " 'diff_ema_10_14',\n",
       " 'diff_ema_10_15',\n",
       " 'diff_ema_10_16',\n",
       " 'diff_ema_10_17',\n",
       " 'diff_ema_10_18',\n",
       " 'diff_ema_10_19',\n",
       " 'diff_ema_10_20',\n",
       " 'diff_ema_10_21',\n",
       " 'diff_ema_10_22',\n",
       " 'diff_ema_10_23',\n",
       " 'diff_ema_10_24',\n",
       " 'diff_ema_10_25',\n",
       " 'diff_ema_10_26',\n",
       " 'diff_ema_10_27',\n",
       " 'diff_ema_10_28',\n",
       " 'diff_ema_10_29',\n",
       " 'value_ema_10_beta_99_0',\n",
       " 'value_ema_10_beta_99_1',\n",
       " 'value_ema_10_beta_99_2',\n",
       " 'value_ema_10_beta_99_3',\n",
       " 'value_ema_10_beta_99_4',\n",
       " 'value_ema_10_beta_99_5',\n",
       " 'value_ema_10_beta_99_6',\n",
       " 'value_ema_10_beta_99_7',\n",
       " 'value_ema_10_beta_99_8',\n",
       " 'value_ema_10_beta_99_9',\n",
       " 'value_ema_10_beta_99_10',\n",
       " 'value_ema_10_beta_99_11',\n",
       " 'value_ema_10_beta_99_12',\n",
       " 'value_ema_10_beta_99_13',\n",
       " 'value_ema_10_beta_99_14',\n",
       " 'value_ema_10_beta_99_15',\n",
       " 'value_ema_10_beta_99_16',\n",
       " 'value_ema_10_beta_99_17',\n",
       " 'value_ema_10_beta_99_18',\n",
       " 'value_ema_10_beta_99_19',\n",
       " 'value_ema_10_beta_99_20',\n",
       " 'value_ema_10_beta_99_21',\n",
       " 'value_ema_10_beta_99_22',\n",
       " 'value_ema_10_beta_99_23',\n",
       " 'value_ema_10_beta_99_24',\n",
       " 'value_ema_10_beta_99_25',\n",
       " 'value_ema_10_beta_99_26',\n",
       " 'value_ema_10_beta_99_27',\n",
       " 'value_ema_10_beta_99_28',\n",
       " 'value_ema_10_beta_99_29',\n",
       " 'dayofweek']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
