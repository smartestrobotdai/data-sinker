{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import matplotlib.pyplot as plt\n",
    "import GPy\n",
    "import GPyOpt\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "class Model:\n",
    "    # Network Parameters\n",
    "    # n_neurons, learning_rate, num_layers, rnn_type(RNN|BasicLSTM|LSTM|LSTM peelhole)\n",
    "    # Control Parameters\n",
    "    # risk_aversion - the margin added to the courtage that leads an buy or sell operation\n",
    "    # learning_period - how many sequences model should learn before predicting next sequences\n",
    "    # prediction_period - how many sequences the model should predict\n",
    "    # max_repeats - how many times in maximum the model should learn\n",
    "    # min_profit - what is the minimum profit in average during training phase, if the minimum is not reached, the model should not predict\n",
    "    # gamma - what is the gamma used when preprocessing data\n",
    "    \n",
    "    step_profit_list = []\n",
    "    mixed_domain = [{'name': 'n_neurons', 'type': 'discrete', 'domain': tuple(range(20,160,20))},\n",
    "          {'name': 'learning_rate', 'type': 'discrete', 'domain': (0.001,0.002,0.003,0.004)},\n",
    "          {'name': 'num_layers', 'type': 'discrete', 'domain': (1,2,3,4)},\n",
    "          {'name': 'rnn_type', 'type': 'discrete', 'domain': (0,1,2)},\n",
    "          {'name': 'learning_period', 'type': 'discrete', 'domain': tuple(range(10,40,10))},\n",
    "          {'name': 'prediction_period', 'type': 'discrete', 'domain': tuple(range(5,10,5))},\n",
    "          {'name': 'max_repeats', 'type': 'discrete', 'domain': tuple(range(1,10,2))},\n",
    "          {'name': 'beta', 'type': 'discrete', 'domain': (99, 98)},\n",
    "          {'name': 'ema', 'type': 'discrete', 'domain': (10,20)},\n",
    "          {'name': 'time_input', 'type': 'discrete', 'domain': (0,1)},\n",
    "         ]\n",
    "    def __init__(self, regen):\n",
    "        if regen == False:\n",
    "            return\n",
    "        def column_filter(x):\n",
    "            if x == 'stepofweek':\n",
    "                return True\n",
    "            elif 'diff_ema' in x:\n",
    "                return True\n",
    "            elif 'volume' in x:\n",
    "                return True\n",
    "            elif 'value_ema' in x:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        for ema in (10, 20):\n",
    "            for beta in (99, 98):\n",
    "                filename = \"data-prep-ema{}-beta{}.csv\".format(ema, beta)\n",
    "                print(\"pre-processing {}\".format(filename))\n",
    "                data = pd.read_csv(filename, parse_dates=[\"timestamp\"])\n",
    "                data['dayofweek'] = data['timestamp'].apply(lambda x: x.weekday())\n",
    "                groups = data.set_index('timestamp').groupby(lambda x: x.date())\n",
    "                \n",
    "                # get maximum steps\n",
    "                max_steps = 0\n",
    "                for index, df in groups:\n",
    "                    df_len = len(df)\n",
    "                    if df_len > max_steps:\n",
    "                        max_steps = df_len\n",
    "                        \n",
    "                np_data = np.zeros((len(groups), max_steps, 30*3+1))\n",
    "                filtered_columns = list(filter(column_filter, data.columns))\n",
    "\n",
    "                i = 0\n",
    "                for index, df in groups:\n",
    "                    df['stepofday'] = np.arange(0, max_steps)\n",
    "                    df['stepofweek'] = df['dayofweek'] * max_steps + df['stepofday']\n",
    "                    np_data[i] = df[['stepofweek'] + filtered_columns ].to_numpy()\n",
    "                    print(np_data[i].shape)\n",
    "                    i += 1\n",
    "                    \n",
    "                numpy_file_name = \"np_ema{}_beta{}.npy\".format(ema, beta)\n",
    "                np.save(numpy_file_name, np_data)\n",
    "                \n",
    "\n",
    "        return\n",
    "        \n",
    "    def get_parameter_str(self, X):\n",
    "        parameter_str = \"\"\n",
    "        for i in range(len(self.mixed_domain)):\n",
    "            parameter_str += self.mixed_domain[i][\"name\"]\n",
    "            parameter_str += ':'\n",
    "            parameter_str += str(X[i])\n",
    "            parameter_str += ','\n",
    "        return parameter_str\n",
    "    \n",
    "    def reset_graph(self, seed=42):\n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    \n",
    "    def log(self, verbose, msg):\n",
    "        if verbose:\n",
    "            print(msg)\n",
    "\n",
    "    def get_batch(self, seq_index, data_train_input, data_train_output):\n",
    "        X_batch = data_train_input[seq_index:seq_index+1]\n",
    "        y_batch = data_train_output[seq_index:seq_index+1]\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def transform(self, data_all, n_inputs, n_outputs):\n",
    "        orig_shape = data_all.shape\n",
    "        data_train_reshape = data_all.reshape((orig_shape[0] * orig_shape[1], orig_shape[2]))\n",
    "        \n",
    "        self.scaler_input = preprocessing.MinMaxScaler().fit(data_train_reshape[:,:n_inputs])\n",
    "        data_train_input_scaled = self.scaler_input.transform(data_train_reshape[:,:n_inputs])\n",
    "        \n",
    "        # the invalid step, we change it to zero!\n",
    "        data_train_input_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "        data_train_input = data_train_input_scaled.reshape(orig_shape[0], orig_shape[1], n_inputs)\n",
    "        \n",
    "        self.scaler_output = preprocessing.MinMaxScaler().fit(data_train_reshape[:,-n_outputs:])\n",
    "        data_train_output_scaled = self.scaler_output.transform(data_train_reshape[:,-n_outputs:])\n",
    "        # the invalid step, we change it to zero!\n",
    "        data_train_output_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "        data_train_output = data_train_output_scaled.reshape(orig_shape[0], orig_shape[1], n_outputs)\n",
    "        \n",
    "        return data_train_input, data_train_output\n",
    "    \n",
    "    def inverse_transform_output(self, scaled_outputs):\n",
    "        outputs_reshaped = scaled_outputs.reshape((scaled_outputs.shape[1], scaled_outputs.shape[2]))\n",
    "        #outputs = np.exp(self.scaler_output.inverse_transform(outputs_reshaped)) - 1\n",
    "        outputs = self.scaler_output.inverse_transform(outputs_reshaped)\n",
    "        return outputs\n",
    "    \n",
    "    def inverse_transform_input(self, scaled_inputs):\n",
    "        inputs_reshaped = scaled_inputs.reshape((scaled_inputs.shape[1], scaled_inputs.shape[2]))\n",
    "        #inputs_reshaped[:,4:6] = np.exp(self.scaler_input.inverse_transform(inputs_reshaped)[:,4:6]) - 1\n",
    "        inputs = self.scaler_input.inverse_transform(inputs_reshaped)\n",
    "        # TODO: the volume and hold should be transformed back.\n",
    "        return inputs\n",
    "        \n",
    "        \n",
    "    def get_answer(self, features):\n",
    "        n_neurons = int(features[0])\n",
    "        learning_rate = features[1]\n",
    "        num_layers = int(features[2])\n",
    "        rnn_type = int(features[3])\n",
    "        learning_period = int(features[4])\n",
    "        prediction_period = int(features[5])\n",
    "        max_repeats = int(features[6])\n",
    "        beta = int(features[7])\n",
    "        ema = int(features[8])\n",
    "        time_input = int(features[9])\n",
    "\n",
    "        # load data\n",
    "        file_name = \"np_ema{}_beta{}.npy\".format(ema, beta)\n",
    "        data_all = np.load(file_name)\n",
    "        \n",
    "        # pick the data for stock_id\n",
    "        stock_index = 20\n",
    "        n_inputs = 1\n",
    "        if time_input != 0:\n",
    "            n_inputs += 1\n",
    "        n_outputs = 1\n",
    "        \n",
    "        # we must convert the array to 2D\n",
    "        orig_shape = data_all.shape\n",
    "        print(\"original shape: \")\n",
    "        print(orig_shape)\n",
    "        reshaped_data = data_all.reshape((orig_shape[0] * orig_shape[1], orig_shape[2]))\n",
    "        \n",
    "        input_column_list = [1 + 30 + stock_index]\n",
    "        if time_input != 0:\n",
    "            input_column_list = [0] + input_column_list\n",
    "        output_column_list = [1 + 60 + stock_index]\n",
    "        \n",
    "        data_filtered = reshaped_data[:, input_column_list + output_column_list].reshape((orig_shape[0], orig_shape[1], n_inputs+n_outputs))\n",
    "        \n",
    "\n",
    "        batch_size = 1\n",
    "        data_train_input, data_train_output = self.transform(data_filtered, n_inputs, n_outputs)\n",
    "\n",
    "        # data_train_input in the shape [seq, steps, features]\n",
    "        days = data_train_input.shape[0]\n",
    "        max_steps = data_train_input.shape[1]\n",
    "\n",
    "        self.reset_graph()\n",
    "        \n",
    "        X = tf.placeholder(tf.float32, [None, max_steps, n_inputs])\n",
    "        y = tf.placeholder(tf.float32, [None, max_steps, n_outputs])\n",
    "        \n",
    "        layers = None\n",
    "        if rnn_type == 0:\n",
    "            layers = [tf.nn.rnn_cell.BasicLSTMCell(n_neurons) \n",
    "              for _ in range(num_layers)]\n",
    "        elif rnn_type == 1:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(n_neurons, use_peepholes=False) \n",
    "              for _ in range(num_layers)]\n",
    "        elif rnn_type == 2:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(n_neurons, use_peepholes=True) \n",
    "              for _ in range(num_layers)]\n",
    "        else:\n",
    "            print(\"WRONG\")\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "        \n",
    "        # For each layer, get the initial state. states will be a tuple of LSTMStateTuples.\n",
    "        init_state = tf.placeholder(tf.float32, [num_layers, 2, batch_size, n_neurons])\n",
    "        state_per_layer_list = tf.unstack(init_state, axis=0)\n",
    "        rnn_tuple_state = tuple(\n",
    "            [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "             for idx in range(num_layers)]\n",
    "        )\n",
    "\n",
    "        rnn_outputs, new_states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32, \n",
    "                                                    initial_state=rnn_tuple_state)\n",
    "        \n",
    "        stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "        stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "        outputs = tf.reshape(stacked_outputs, [-1, max_steps, n_outputs])\n",
    "        \n",
    "        \n",
    "        loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # now run the model to get answer:\n",
    "        rnn_states_after_training = np.zeros((num_layers, 2, batch_size, n_neurons))\n",
    "        asset = 1\n",
    "        market_asset = 1\n",
    "        graph_data = []\n",
    "        my_loss_test_list = []\n",
    "        with tf.Session() as sess:\n",
    "            init.run()\n",
    "            for learn_end_seq in range(learning_period, \n",
    "                                       days - prediction_period, \n",
    "                                       prediction_period):\n",
    "                learning_start_seq = learn_end_seq - learning_period\n",
    "                for repeat in range(max_repeats):\n",
    "                    rnn_states = copy.deepcopy(rnn_states_after_training)\n",
    "                    my_loss_train_list = []\n",
    "                    train_asset = 1\n",
    "                    for seq in range(learning_start_seq, learn_end_seq):\n",
    "                        X_batch, y_batch = self.get_batch(seq, data_train_input, data_train_output)\n",
    "                        feed_dict = {\n",
    "                            X: X_batch,\n",
    "                            y: y_batch,\n",
    "                            init_state: rnn_states_after_training\n",
    "                        }\n",
    "                        \n",
    "                        my_op, my_new_states, my_loss_train, my_outputs = sess.run([training_op, new_states, loss, outputs], feed_dict=feed_dict)\n",
    "                        my_loss_train_list.append(my_loss_train)\n",
    "                        rnn_states = my_new_states\n",
    "                        \n",
    "                    my_loss_train_avg = sum(my_loss_train_list) / len(my_loss_train_list)\n",
    "                    print(\"sequence:{} - {} repeat={} training finished, training MSE={} training asset={}\".format(learning_start_seq, learn_end_seq, repeat, my_loss_train_avg, train_asset))\n",
    "                # backup the states after training.\n",
    "                rnn_states_after_training = copy.deepcopy(rnn_states)\n",
    "                \n",
    "                \n",
    "                for seq in range(learn_end_seq, learn_end_seq + prediction_period):\n",
    "                    X_test, y_test = self.get_batch(seq, data_train_input, data_train_output)\n",
    "                    feed_dict = {\n",
    "                        X: X_test,\n",
    "                        y: y_test,\n",
    "                        init_state: rnn_states,\n",
    "                    }\n",
    "            \n",
    "                    my_new_states, my_loss_test, my_outputs = sess.run([new_states, loss, outputs], feed_dict=feed_dict)\n",
    "                    my_loss_test_list.append(my_loss_test)\n",
    "                    \n",
    "                    print(\"sequence:{} test finished, testing MSE={}\".format(seq, my_loss_test))\n",
    "                    rnn_states = my_new_states\n",
    "            my_loss_test_avg = sum(my_loss_test_list)/len(my_loss_test_list)\n",
    "            return my_loss_test_avg\n",
    "                    \n",
    "    def opt_wrapper(self, X_list):\n",
    "        answer = np.zeros((X_list.shape[0], 1))\n",
    "        for i in range(len(X_list)):\n",
    "            print(self.get_parameter_str(X_list[i]))\n",
    "            features = X_list[i]\n",
    "            answer[i][0] = self.get_answer(features)\n",
    "            #self.draw_step_profit_graph(self.step_profit_list, \"step_profit_{}\".format(answer[i][0]))\n",
    "            #self.step_profit_list = []\n",
    "            if answer[i][0] < self.min_answer:\n",
    "                print(\"find new opt:{}, {}\".format(answer[i][0], self.get_parameter_str(X_list[i])))\n",
    "                self.min_answer = answer[i][0]\n",
    "        return answer\n",
    "                \n",
    "        \n",
    "    def optimize(self, max_iter=300):\n",
    "        self.min_answer = 999\n",
    "        myBopt = GPyOpt.methods.BayesianOptimization(f=self.opt_wrapper,  # Objective function       \n",
    "                                             domain=self.mixed_domain,          # Box-constraints of the problem\n",
    "                                             initial_design_numdata = 20,   # Number data initial design\n",
    "                                             acquisition_type='EI',        # Expected Improvement\n",
    "                                             exact_feval = True)           # True evaluations, no sample noise\n",
    "        \n",
    "        myBopt.run_optimization(max_iter,eps=0)\n",
    "    \n",
    "    \n",
    "    # no optimize, we have already know the answer.\n",
    "    def run(self, n_neurons, learning_rate, \n",
    "            num_layers, rnn_type, risk_aversion, \n",
    "            learning_period, prediction_period, \n",
    "            max_repeats, min_profit, gamma):\n",
    "        features = [n_neurons, learning_rate, \n",
    "            num_layers, rnn_type, risk_aversion, \n",
    "            learning_period, prediction_period, \n",
    "            max_repeats, min_profit, gamma]\n",
    "        \n",
    "        answer = self.get_answer(features)\n",
    "        print(\"Finished, result:{}\".format(answer))\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neurons:140.0,learning_rate:0.002,num_layers:4.0,rnn_type:1.0,learning_period:20.0,prediction_period:5.0,max_repeats:9.0,beta:99.0,ema:10.0,time_input:0.0,\n",
      "original shape: \n",
      "(53, 504, 91)\n",
      "sequence:0 - 20 repeat=0 training finished, training MSE=0.00802745613618754 training asset=1\n",
      "sequence:0 - 20 repeat=1 training finished, training MSE=0.0014849287836113945 training asset=1\n",
      "sequence:0 - 20 repeat=2 training finished, training MSE=0.0013470235950080677 training asset=1\n",
      "sequence:0 - 20 repeat=3 training finished, training MSE=0.001325701709720306 training asset=1\n",
      "sequence:0 - 20 repeat=4 training finished, training MSE=0.001321365506737493 training asset=1\n",
      "sequence:0 - 20 repeat=5 training finished, training MSE=0.001318666324368678 training asset=1\n",
      "sequence:0 - 20 repeat=6 training finished, training MSE=0.0013141536634066141 training asset=1\n",
      "sequence:0 - 20 repeat=7 training finished, training MSE=0.0013079701384413056 training asset=1\n",
      "sequence:0 - 20 repeat=8 training finished, training MSE=0.0012999466271139681 training asset=1\n",
      "sequence:20 test finished, testing MSE=0.0007731941877864301\n",
      "sequence:21 test finished, testing MSE=0.00046984953223727643\n",
      "sequence:22 test finished, testing MSE=0.0005271050031296909\n",
      "sequence:23 test finished, testing MSE=0.0006321114487946033\n",
      "sequence:24 test finished, testing MSE=0.0007611658074893057\n",
      "sequence:5 - 25 repeat=0 training finished, training MSE=0.0006492479718872346 training asset=1\n",
      "sequence:5 - 25 repeat=1 training finished, training MSE=0.0006737046292982996 training asset=1\n",
      "sequence:5 - 25 repeat=2 training finished, training MSE=0.0006847089593065902 training asset=1\n",
      "sequence:5 - 25 repeat=3 training finished, training MSE=0.0007003399849054403 training asset=1\n",
      "sequence:5 - 25 repeat=4 training finished, training MSE=0.0006998294440563769 training asset=1\n",
      "sequence:5 - 25 repeat=5 training finished, training MSE=0.0006804878124967217 training asset=1\n",
      "sequence:5 - 25 repeat=6 training finished, training MSE=0.0006595415805350057 training asset=1\n",
      "sequence:5 - 25 repeat=7 training finished, training MSE=0.0006514174907351844 training asset=1\n",
      "sequence:5 - 25 repeat=8 training finished, training MSE=0.0006530536702484824 training asset=1\n",
      "sequence:25 test finished, testing MSE=0.0003202599473297596\n",
      "sequence:26 test finished, testing MSE=0.0006739123491570354\n",
      "sequence:27 test finished, testing MSE=0.0006257662316784263\n",
      "sequence:28 test finished, testing MSE=0.0011364034144207835\n",
      "sequence:29 test finished, testing MSE=0.0006724060513079166\n",
      "sequence:10 - 30 repeat=0 training finished, training MSE=0.0006217480477062054 training asset=1\n",
      "sequence:10 - 30 repeat=1 training finished, training MSE=0.0006237834502826444 training asset=1\n",
      "sequence:10 - 30 repeat=2 training finished, training MSE=0.0006178312542033382 training asset=1\n",
      "sequence:10 - 30 repeat=3 training finished, training MSE=0.0006146968473331072 training asset=1\n",
      "sequence:10 - 30 repeat=4 training finished, training MSE=0.0006149862761958502 training asset=1\n",
      "sequence:10 - 30 repeat=5 training finished, training MSE=0.0006164457838167437 training asset=1\n",
      "sequence:10 - 30 repeat=6 training finished, training MSE=0.000617910415166989 training asset=1\n",
      "sequence:10 - 30 repeat=7 training finished, training MSE=0.000619085856305901 training asset=1\n",
      "sequence:10 - 30 repeat=8 training finished, training MSE=0.000619928898231592 training asset=1\n",
      "sequence:30 test finished, testing MSE=0.00032351844129152596\n",
      "sequence:31 test finished, testing MSE=0.00042977224802598357\n",
      "sequence:32 test finished, testing MSE=0.00027519636205397546\n",
      "sequence:33 test finished, testing MSE=0.00046494416892528534\n",
      "sequence:34 test finished, testing MSE=0.0004647135210689157\n",
      "sequence:15 - 35 repeat=0 training finished, training MSE=0.0005451599703519605 training asset=1\n",
      "sequence:15 - 35 repeat=1 training finished, training MSE=0.0005424859278718941 training asset=1\n",
      "sequence:15 - 35 repeat=2 training finished, training MSE=0.0005435074097476899 training asset=1\n",
      "sequence:15 - 35 repeat=3 training finished, training MSE=0.0005435218699858524 training asset=1\n",
      "sequence:15 - 35 repeat=4 training finished, training MSE=0.0005429428565548733 training asset=1\n",
      "sequence:15 - 35 repeat=5 training finished, training MSE=0.0005419725595857017 training asset=1\n",
      "sequence:15 - 35 repeat=6 training finished, training MSE=0.0005407090749940835 training asset=1\n",
      "sequence:15 - 35 repeat=7 training finished, training MSE=0.000539296718488913 training asset=1\n",
      "sequence:15 - 35 repeat=8 training finished, training MSE=0.0005379080816055648 training asset=1\n",
      "sequence:35 test finished, testing MSE=0.0003637086774688214\n",
      "sequence:36 test finished, testing MSE=0.0005964457523077726\n",
      "sequence:37 test finished, testing MSE=0.0006000864086672664\n",
      "sequence:38 test finished, testing MSE=0.0007248880574479699\n",
      "sequence:39 test finished, testing MSE=0.001479060621932149\n",
      "sequence:20 - 40 repeat=0 training finished, training MSE=0.0005959995993180201 training asset=1\n",
      "sequence:20 - 40 repeat=1 training finished, training MSE=0.0006107767898356542 training asset=1\n",
      "sequence:20 - 40 repeat=2 training finished, training MSE=0.000604632354225032 training asset=1\n",
      "sequence:20 - 40 repeat=3 training finished, training MSE=0.0005972313272650353 training asset=1\n",
      "sequence:20 - 40 repeat=4 training finished, training MSE=0.0005940657269093208 training asset=1\n",
      "sequence:20 - 40 repeat=5 training finished, training MSE=0.000590724130597664 training asset=1\n",
      "sequence:20 - 40 repeat=6 training finished, training MSE=0.0005868757267307956 training asset=1\n",
      "sequence:20 - 40 repeat=7 training finished, training MSE=0.0005831312235386576 training asset=1\n",
      "sequence:20 - 40 repeat=8 training finished, training MSE=0.0005795861441583838 training asset=1\n",
      "sequence:40 test finished, testing MSE=0.0011273802956566215\n",
      "sequence:41 test finished, testing MSE=0.0005605820333585143\n",
      "sequence:42 test finished, testing MSE=0.0015821660635992885\n",
      "sequence:43 test finished, testing MSE=0.0012407490285113454\n",
      "sequence:44 test finished, testing MSE=0.0004930373397655785\n",
      "sequence:25 - 45 repeat=0 training finished, training MSE=0.0006787320569856092 training asset=1\n",
      "sequence:25 - 45 repeat=1 training finished, training MSE=0.000688182185695041 training asset=1\n",
      "sequence:25 - 45 repeat=2 training finished, training MSE=0.0006802822332247161 training asset=1\n",
      "sequence:25 - 45 repeat=3 training finished, training MSE=0.0006790579398511909 training asset=1\n",
      "sequence:25 - 45 repeat=4 training finished, training MSE=0.0006768100676708855 training asset=1\n",
      "sequence:25 - 45 repeat=5 training finished, training MSE=0.000674405180325266 training asset=1\n",
      "sequence:25 - 45 repeat=6 training finished, training MSE=0.0006717803378705866 training asset=1\n",
      "sequence:25 - 45 repeat=7 training finished, training MSE=0.0006686134729534388 training asset=1\n",
      "sequence:25 - 45 repeat=8 training finished, training MSE=0.000665153180307243 training asset=1\n",
      "sequence:45 test finished, testing MSE=0.0005413430044427514\n",
      "sequence:46 test finished, testing MSE=0.0006087486399337649\n",
      "sequence:47 test finished, testing MSE=0.0006195548339746892\n",
      "sequence:48 test finished, testing MSE=0.000512980914209038\n",
      "sequence:49 test finished, testing MSE=0.0005504251457750797\n",
      "find new opt:0.0006717158510582521, n_neurons:140.0,learning_rate:0.002,num_layers:4.0,rnn_type:1.0,learning_period:20.0,prediction_period:5.0,max_repeats:9.0,beta:99.0,ema:10.0,time_input:0.0,\n",
      "n_neurons:80.0,learning_rate:0.002,num_layers:4.0,rnn_type:0.0,learning_period:20.0,prediction_period:5.0,max_repeats:3.0,beta:99.0,ema:20.0,time_input:0.0,\n",
      "original shape: \n",
      "(53, 504, 91)\n",
      "sequence:0 - 20 repeat=0 training finished, training MSE=0.011761530279181897 training asset=1\n",
      "sequence:0 - 20 repeat=1 training finished, training MSE=0.002030408530845307 training asset=1\n",
      "sequence:0 - 20 repeat=2 training finished, training MSE=0.0017907359608216212 training asset=1\n",
      "sequence:20 test finished, testing MSE=0.0008671102114021778\n",
      "sequence:21 test finished, testing MSE=0.0006922506727278233\n",
      "sequence:22 test finished, testing MSE=0.0007044057711027563\n",
      "sequence:23 test finished, testing MSE=0.0010131367016583681\n",
      "sequence:24 test finished, testing MSE=0.0009270596783608198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence:5 - 25 repeat=0 training finished, training MSE=0.0007765020578517579 training asset=1\n",
      "sequence:5 - 25 repeat=1 training finished, training MSE=0.0007376859837677329 training asset=1\n",
      "sequence:5 - 25 repeat=2 training finished, training MSE=0.0007386570199741982 training asset=1\n",
      "sequence:25 test finished, testing MSE=0.0003547748492565006\n",
      "sequence:26 test finished, testing MSE=0.0007787112845107913\n",
      "sequence:27 test finished, testing MSE=0.0008003671537153423\n",
      "sequence:28 test finished, testing MSE=0.0013665675651282072\n",
      "sequence:29 test finished, testing MSE=0.0006619772175326943\n",
      "sequence:10 - 30 repeat=0 training finished, training MSE=0.0007582401813124306 training asset=1\n",
      "sequence:10 - 30 repeat=1 training finished, training MSE=0.0007239965227199719 training asset=1\n",
      "sequence:10 - 30 repeat=2 training finished, training MSE=0.0007176086393883452 training asset=1\n",
      "sequence:30 test finished, testing MSE=0.00041071587475016713\n",
      "sequence:31 test finished, testing MSE=0.0005083691794425249\n",
      "sequence:32 test finished, testing MSE=0.0003526468644849956\n",
      "sequence:33 test finished, testing MSE=0.0005147990304976702\n",
      "sequence:34 test finished, testing MSE=0.0005300049670040607\n",
      "sequence:15 - 35 repeat=0 training finished, training MSE=0.0006429300818126648 training asset=1\n",
      "sequence:15 - 35 repeat=1 training finished, training MSE=0.0006404294981621206 training asset=1\n",
      "sequence:15 - 35 repeat=2 training finished, training MSE=0.0006327494207653217 training asset=1\n",
      "sequence:35 test finished, testing MSE=0.00047730811638757586\n",
      "sequence:36 test finished, testing MSE=0.0008094428922049701\n",
      "sequence:37 test finished, testing MSE=0.000775369699113071\n",
      "sequence:38 test finished, testing MSE=0.0008860056404955685\n",
      "sequence:39 test finished, testing MSE=0.001976086525246501\n",
      "sequence:20 - 40 repeat=0 training finished, training MSE=0.0007323647776502184 training asset=1\n",
      "sequence:20 - 40 repeat=1 training finished, training MSE=0.0007433789331116713 training asset=1\n",
      "sequence:20 - 40 repeat=2 training finished, training MSE=0.0007189596653915942 training asset=1\n",
      "sequence:40 test finished, testing MSE=0.0009038622956722975\n",
      "sequence:41 test finished, testing MSE=0.0007154832710511982\n",
      "sequence:42 test finished, testing MSE=0.001762312836945057\n",
      "sequence:43 test finished, testing MSE=0.0014434061013162136\n",
      "sequence:44 test finished, testing MSE=0.000584819761570543\n",
      "sequence:25 - 45 repeat=0 training finished, training MSE=0.000844120400142856 training asset=1\n",
      "sequence:25 - 45 repeat=1 training finished, training MSE=0.0008496830691001378 training asset=1\n",
      "sequence:25 - 45 repeat=2 training finished, training MSE=0.0008186462087905966 training asset=1\n",
      "sequence:45 test finished, testing MSE=0.0008424978004768491\n",
      "sequence:46 test finished, testing MSE=0.0007710091304033995\n",
      "sequence:47 test finished, testing MSE=0.0008434507763013244\n",
      "sequence:48 test finished, testing MSE=0.0006495826528407633\n",
      "sequence:49 test finished, testing MSE=0.0007930919528007507\n",
      "n_neurons:100.0,learning_rate:0.002,num_layers:3.0,rnn_type:1.0,learning_period:20.0,prediction_period:5.0,max_repeats:1.0,beta:99.0,ema:20.0,time_input:0.0,\n",
      "original shape: \n",
      "(53, 504, 91)\n",
      "sequence:0 - 20 repeat=0 training finished, training MSE=0.01380972113693133 training asset=1\n",
      "sequence:20 test finished, testing MSE=0.0011054807109758258\n",
      "sequence:21 test finished, testing MSE=0.0007027453975751996\n",
      "sequence:22 test finished, testing MSE=0.000808140670415014\n",
      "sequence:23 test finished, testing MSE=0.0009046262712217867\n",
      "sequence:24 test finished, testing MSE=0.001177690108306706\n",
      "sequence:5 - 25 repeat=0 training finished, training MSE=0.0009090728519367986 training asset=1\n",
      "sequence:25 test finished, testing MSE=0.00035514970659278333\n",
      "sequence:26 test finished, testing MSE=0.0006628792034462094\n",
      "sequence:27 test finished, testing MSE=0.0008672801195643842\n",
      "sequence:28 test finished, testing MSE=0.0014810863649472594\n",
      "sequence:29 test finished, testing MSE=0.0005042142583988607\n",
      "sequence:10 - 30 repeat=0 training finished, training MSE=0.0006752607034286485 training asset=1\n",
      "sequence:30 test finished, testing MSE=0.0004064117674715817\n",
      "sequence:31 test finished, testing MSE=0.00048210189561359584\n",
      "sequence:32 test finished, testing MSE=0.0003562693309504539\n",
      "sequence:33 test finished, testing MSE=0.0005197837017476559\n",
      "sequence:34 test finished, testing MSE=0.0005200949381105602\n",
      "sequence:15 - 35 repeat=0 training finished, training MSE=0.000611238504643552 training asset=1\n",
      "sequence:35 test finished, testing MSE=0.00046860650763846934\n",
      "sequence:36 test finished, testing MSE=0.0007350843516178429\n",
      "sequence:37 test finished, testing MSE=0.0007657036185264587\n",
      "sequence:38 test finished, testing MSE=0.0008485406287945807\n",
      "sequence:39 test finished, testing MSE=0.0018906586337834597\n",
      "sequence:20 - 40 repeat=0 training finished, training MSE=0.0007218403174192644 training asset=1\n",
      "sequence:40 test finished, testing MSE=0.0008988318732008338\n",
      "sequence:41 test finished, testing MSE=0.000664012273773551\n",
      "sequence:42 test finished, testing MSE=0.0017127209575846791\n",
      "sequence:43 test finished, testing MSE=0.001361355185508728\n",
      "sequence:44 test finished, testing MSE=0.0005510181072168052\n",
      "sequence:25 - 45 repeat=0 training finished, training MSE=0.000853425738750957 training asset=1\n",
      "sequence:45 test finished, testing MSE=0.001022848067805171\n",
      "sequence:46 test finished, testing MSE=0.0008747658575884998\n",
      "sequence:47 test finished, testing MSE=0.0009698222274892032\n",
      "sequence:48 test finished, testing MSE=0.0006710995803587139\n",
      "sequence:49 test finished, testing MSE=0.0009587293607182801\n",
      "n_neurons:140.0,learning_rate:0.004,num_layers:2.0,rnn_type:1.0,learning_period:10.0,prediction_period:5.0,max_repeats:7.0,beta:98.0,ema:20.0,time_input:1.0,\n",
      "original shape: \n",
      "(53, 504, 91)\n",
      "sequence:0 - 10 repeat=0 training finished, training MSE=0.025901282660197467 training asset=1\n",
      "sequence:0 - 10 repeat=1 training finished, training MSE=0.003924719471251592 training asset=1\n",
      "sequence:0 - 10 repeat=2 training finished, training MSE=0.0027603907394222913 training asset=1\n",
      "sequence:0 - 10 repeat=3 training finished, training MSE=0.0022310659784125163 training asset=1\n",
      "sequence:0 - 10 repeat=4 training finished, training MSE=0.002056916680885479 training asset=1\n",
      "sequence:0 - 10 repeat=5 training finished, training MSE=0.001992863739724271 training asset=1\n",
      "sequence:0 - 10 repeat=6 training finished, training MSE=0.00197068779671099 training asset=1\n",
      "sequence:10 test finished, testing MSE=0.00045918600517325103\n",
      "sequence:11 test finished, testing MSE=0.0003797553072217852\n",
      "sequence:12 test finished, testing MSE=0.0009982775663957\n",
      "sequence:13 test finished, testing MSE=0.0005428301519714296\n",
      "sequence:14 test finished, testing MSE=0.00096447195392102\n",
      "sequence:5 - 15 repeat=0 training finished, training MSE=0.0006703757506329566 training asset=1\n",
      "sequence:5 - 15 repeat=1 training finished, training MSE=0.0007509626302635297 training asset=1\n",
      "sequence:5 - 15 repeat=2 training finished, training MSE=0.0007536894845543429 training asset=1\n",
      "sequence:5 - 15 repeat=3 training finished, training MSE=0.000715010246494785 training asset=1\n",
      "sequence:5 - 15 repeat=4 training finished, training MSE=0.0007201360625913366 training asset=1\n",
      "sequence:5 - 15 repeat=5 training finished, training MSE=0.0007503051543608308 training asset=1\n",
      "sequence:5 - 15 repeat=6 training finished, training MSE=0.0007708164979703724 training asset=1\n",
      "sequence:15 test finished, testing MSE=0.0005026680300943553\n",
      "sequence:16 test finished, testing MSE=0.0004501740913838148\n",
      "sequence:17 test finished, testing MSE=0.0007396591827273369\n",
      "sequence:18 test finished, testing MSE=0.0005933254724368453\n",
      "sequence:19 test finished, testing MSE=0.00033901541610248387\n",
      "sequence:10 - 20 repeat=0 training finished, training MSE=0.000565656871185638 training asset=1\n",
      "sequence:10 - 20 repeat=1 training finished, training MSE=0.0006605052825761959 training asset=1\n",
      "sequence:10 - 20 repeat=2 training finished, training MSE=0.0007058699120534584 training asset=1\n",
      "sequence:10 - 20 repeat=3 training finished, training MSE=0.0006808160338550806 training asset=1\n",
      "sequence:10 - 20 repeat=4 training finished, training MSE=0.0006365765497321263 training asset=1\n",
      "sequence:10 - 20 repeat=5 training finished, training MSE=0.0006168723746668547 training asset=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence:10 - 20 repeat=6 training finished, training MSE=0.0006213719228981063 training asset=1\n",
      "sequence:20 test finished, testing MSE=0.0006295993225648999\n",
      "sequence:21 test finished, testing MSE=0.0004518504429142922\n",
      "sequence:22 test finished, testing MSE=0.0004918539780192077\n",
      "sequence:23 test finished, testing MSE=0.0007153369951993227\n",
      "sequence:24 test finished, testing MSE=0.0007415335858240724\n",
      "sequence:15 - 25 repeat=0 training finished, training MSE=0.000539449622738175 training asset=1\n",
      "sequence:15 - 25 repeat=1 training finished, training MSE=0.0005266480351565406 training asset=1\n",
      "sequence:15 - 25 repeat=2 training finished, training MSE=0.0005337941489415243 training asset=1\n",
      "sequence:15 - 25 repeat=3 training finished, training MSE=0.0005469925177749247 training asset=1\n",
      "sequence:15 - 25 repeat=4 training finished, training MSE=0.0005513897311175242 training asset=1\n",
      "sequence:15 - 25 repeat=5 training finished, training MSE=0.0005520351522136479 training asset=1\n",
      "sequence:15 - 25 repeat=6 training finished, training MSE=0.0005528123234398663 training asset=1\n",
      "sequence:25 test finished, testing MSE=0.0002861710963770747\n",
      "sequence:26 test finished, testing MSE=0.0006350695039145648\n",
      "sequence:27 test finished, testing MSE=0.0006054265541024506\n",
      "sequence:28 test finished, testing MSE=0.0010524458484724164\n",
      "sequence:29 test finished, testing MSE=0.0005824231193400919\n",
      "sequence:20 - 30 repeat=0 training finished, training MSE=0.000591980601893738 training asset=1\n",
      "sequence:20 - 30 repeat=1 training finished, training MSE=0.0005818188597913832 training asset=1\n",
      "sequence:20 - 30 repeat=2 training finished, training MSE=0.0005741919594584033 training asset=1\n",
      "sequence:20 - 30 repeat=3 training finished, training MSE=0.0005683233292074874 training asset=1\n",
      "sequence:20 - 30 repeat=4 training finished, training MSE=0.0005624682147754356 training asset=1\n",
      "sequence:20 - 30 repeat=5 training finished, training MSE=0.0005568930209847167 training asset=1\n",
      "sequence:20 - 30 repeat=6 training finished, training MSE=0.0005512864154297858 training asset=1\n",
      "sequence:30 test finished, testing MSE=0.00032311087124980986\n",
      "sequence:31 test finished, testing MSE=0.00037827767664566636\n",
      "sequence:32 test finished, testing MSE=0.0002969908819068223\n",
      "sequence:33 test finished, testing MSE=0.00043667538557201624\n",
      "sequence:34 test finished, testing MSE=0.00044040806824341416\n",
      "sequence:25 - 35 repeat=0 training finished, training MSE=0.0004678964673075825 training asset=1\n",
      "sequence:25 - 35 repeat=1 training finished, training MSE=0.0005232316383626312 training asset=1\n",
      "sequence:25 - 35 repeat=2 training finished, training MSE=0.0005252781033050269 training asset=1\n",
      "sequence:25 - 35 repeat=3 training finished, training MSE=0.0005123318260302767 training asset=1\n",
      "sequence:25 - 35 repeat=4 training finished, training MSE=0.0005027406921726651 training asset=1\n",
      "sequence:25 - 35 repeat=5 training finished, training MSE=0.0004969225512468256 training asset=1\n",
      "sequence:25 - 35 repeat=6 training finished, training MSE=0.0005003551603294909 training asset=1\n",
      "sequence:35 test finished, testing MSE=0.0003033912507817149\n",
      "sequence:36 test finished, testing MSE=0.0006321829278022051\n",
      "sequence:37 test finished, testing MSE=0.00045907325693406165\n",
      "sequence:38 test finished, testing MSE=0.0006491055246442556\n",
      "sequence:39 test finished, testing MSE=0.0012745445128530264\n",
      "sequence:30 - 40 repeat=0 training finished, training MSE=0.0005563037702813745 training asset=1\n",
      "sequence:30 - 40 repeat=1 training finished, training MSE=0.0007037969306111335 training asset=1\n",
      "sequence:30 - 40 repeat=2 training finished, training MSE=0.000681102232192643 training asset=1\n",
      "sequence:30 - 40 repeat=3 training finished, training MSE=0.000682259671157226 training asset=1\n",
      "sequence:30 - 40 repeat=4 training finished, training MSE=0.0007185556227341294 training asset=1\n",
      "sequence:30 - 40 repeat=5 training finished, training MSE=0.0009003181563457474 training asset=1\n",
      "sequence:30 - 40 repeat=6 training finished, training MSE=0.0011019971396308392 training asset=1\n",
      "sequence:40 test finished, testing MSE=0.0010394711280241609\n",
      "sequence:41 test finished, testing MSE=0.0007216756348498166\n",
      "sequence:42 test finished, testing MSE=0.0014570128405466676\n",
      "sequence:43 test finished, testing MSE=0.0013110034633427858\n",
      "sequence:44 test finished, testing MSE=0.0005430951714515686\n",
      "sequence:35 - 45 repeat=0 training finished, training MSE=0.0012053834943799302 training asset=1\n",
      "sequence:35 - 45 repeat=1 training finished, training MSE=0.0008312824473250657 training asset=1\n",
      "sequence:35 - 45 repeat=2 training finished, training MSE=0.0008515748952049762 training asset=1\n",
      "sequence:35 - 45 repeat=3 training finished, training MSE=0.0008817566966172307 training asset=1\n",
      "sequence:35 - 45 repeat=4 training finished, training MSE=0.0008435957977781072 training asset=1\n",
      "sequence:35 - 45 repeat=5 training finished, training MSE=0.0008027768810279668 training asset=1\n",
      "sequence:35 - 45 repeat=6 training finished, training MSE=0.0007859508332330734 training asset=1\n",
      "sequence:45 test finished, testing MSE=0.0005279967444948852\n",
      "sequence:46 test finished, testing MSE=0.0005535903619602323\n",
      "sequence:47 test finished, testing MSE=0.0006418179837055504\n",
      "sequence:48 test finished, testing MSE=0.00047497148625552654\n",
      "sequence:49 test finished, testing MSE=0.000730582105461508\n",
      "find new opt:0.0006339012725220527, n_neurons:140.0,learning_rate:0.004,num_layers:2.0,rnn_type:1.0,learning_period:10.0,prediction_period:5.0,max_repeats:7.0,beta:98.0,ema:20.0,time_input:1.0,\n",
      "n_neurons:60.0,learning_rate:0.004,num_layers:2.0,rnn_type:1.0,learning_period:30.0,prediction_period:5.0,max_repeats:7.0,beta:99.0,ema:10.0,time_input:1.0,\n",
      "original shape: \n",
      "(53, 504, 91)\n",
      "sequence:0 - 30 repeat=0 training finished, training MSE=0.007452055926357086 training asset=1\n",
      "sequence:0 - 30 repeat=1 training finished, training MSE=0.0010767392280589168 training asset=1\n",
      "sequence:0 - 30 repeat=2 training finished, training MSE=0.001038975644041784 training asset=1\n",
      "sequence:0 - 30 repeat=3 training finished, training MSE=0.001044513296801597 training asset=1\n",
      "sequence:0 - 30 repeat=4 training finished, training MSE=0.0010377347576043879 training asset=1\n",
      "sequence:0 - 30 repeat=5 training finished, training MSE=0.0010226069406295815 training asset=1\n",
      "sequence:0 - 30 repeat=6 training finished, training MSE=0.0010072337987367063 training asset=1\n",
      "sequence:30 test finished, testing MSE=0.0003106464573647827\n",
      "sequence:31 test finished, testing MSE=0.00039500428829342127\n",
      "sequence:32 test finished, testing MSE=0.00023979140678420663\n",
      "sequence:33 test finished, testing MSE=0.00043176423059776425\n",
      "sequence:34 test finished, testing MSE=0.0004607148002833128\n",
      "sequence:5 - 35 repeat=0 training finished, training MSE=0.0005629042148939334 training asset=1\n",
      "sequence:5 - 35 repeat=1 training finished, training MSE=0.0005538108453038149 training asset=1\n",
      "sequence:5 - 35 repeat=2 training finished, training MSE=0.0005561215075431392 training asset=1\n",
      "sequence:5 - 35 repeat=3 training finished, training MSE=0.0005585782326913128 training asset=1\n",
      "sequence:5 - 35 repeat=4 training finished, training MSE=0.0005611778246626879 training asset=1\n",
      "sequence:5 - 35 repeat=5 training finished, training MSE=0.000562983388469244 training asset=1\n",
      "sequence:5 - 35 repeat=6 training finished, training MSE=0.0005638745312656587 training asset=1\n",
      "sequence:35 test finished, testing MSE=0.0003135212464258075\n",
      "sequence:36 test finished, testing MSE=0.0005532073555514216\n",
      "sequence:37 test finished, testing MSE=0.0004998713848181069\n",
      "sequence:38 test finished, testing MSE=0.0006616126047447324\n",
      "sequence:39 test finished, testing MSE=0.0012690714793279767\n",
      "sequence:10 - 40 repeat=0 training finished, training MSE=0.0005374695028876886 training asset=1\n",
      "sequence:10 - 40 repeat=1 training finished, training MSE=0.0006054387389061352 training asset=1\n",
      "sequence:10 - 40 repeat=2 training finished, training MSE=0.000602477581317847 training asset=1\n",
      "sequence:10 - 40 repeat=3 training finished, training MSE=0.0005771584542041334 training asset=1\n",
      "sequence:10 - 40 repeat=4 training finished, training MSE=0.0005734488726981605 training asset=1\n",
      "sequence:10 - 40 repeat=5 training finished, training MSE=0.0005733912917397295 training asset=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence:10 - 40 repeat=6 training finished, training MSE=0.0005717837940513467 training asset=1\n",
      "sequence:40 test finished, testing MSE=0.0009721717797219753\n",
      "sequence:41 test finished, testing MSE=0.00045739675988443196\n",
      "sequence:42 test finished, testing MSE=0.0014525187434628606\n",
      "sequence:43 test finished, testing MSE=0.0010872086277231574\n",
      "sequence:44 test finished, testing MSE=0.0004335075500421226\n",
      "sequence:15 - 45 repeat=0 training finished, training MSE=0.0006026421692998459 training asset=1\n",
      "sequence:15 - 45 repeat=1 training finished, training MSE=0.0005936068167405514 training asset=1\n",
      "sequence:15 - 45 repeat=2 training finished, training MSE=0.0005923224564564104 training asset=1\n",
      "sequence:15 - 45 repeat=3 training finished, training MSE=0.0005916210512320201 training asset=1\n",
      "sequence:15 - 45 repeat=4 training finished, training MSE=0.0005916341120610014 training asset=1\n",
      "sequence:15 - 45 repeat=5 training finished, training MSE=0.000591343284274141 training asset=1\n",
      "sequence:15 - 45 repeat=6 training finished, training MSE=0.0005908122072772434 training asset=1\n",
      "sequence:45 test finished, testing MSE=0.0004926635301671922\n",
      "sequence:46 test finished, testing MSE=0.0005640685558319092\n",
      "sequence:47 test finished, testing MSE=0.0005466673756018281\n",
      "sequence:48 test finished, testing MSE=0.00044028658885508776\n",
      "sequence:49 test finished, testing MSE=0.0005104623851366341\n",
      "find new opt:0.0006046078575309366, n_neurons:60.0,learning_rate:0.004,num_layers:2.0,rnn_type:1.0,learning_period:30.0,prediction_period:5.0,max_repeats:7.0,beta:99.0,ema:10.0,time_input:1.0,\n",
      "n_neurons:100.0,learning_rate:0.001,num_layers:3.0,rnn_type:0.0,learning_period:20.0,prediction_period:5.0,max_repeats:7.0,beta:98.0,ema:10.0,time_input:1.0,\n",
      "original shape: \n",
      "(53, 504, 91)\n",
      "sequence:0 - 20 repeat=0 training finished, training MSE=0.00813011379505042 training asset=1\n",
      "sequence:0 - 20 repeat=1 training finished, training MSE=0.0023506779776653274 training asset=1\n",
      "sequence:0 - 20 repeat=2 training finished, training MSE=0.0015692276239860803 training asset=1\n",
      "sequence:0 - 20 repeat=3 training finished, training MSE=0.0014495380310108885 training asset=1\n",
      "sequence:0 - 20 repeat=4 training finished, training MSE=0.0014154274860629812 training asset=1\n",
      "sequence:0 - 20 repeat=5 training finished, training MSE=0.0013783193600829691 training asset=1\n",
      "sequence:0 - 20 repeat=6 training finished, training MSE=0.0013581968247308395 training asset=1\n",
      "sequence:20 test finished, testing MSE=0.0007098804344423115\n",
      "sequence:21 test finished, testing MSE=0.0004435064038261771\n",
      "sequence:22 test finished, testing MSE=0.0004850559344049543\n",
      "sequence:23 test finished, testing MSE=0.0006105384672991931\n",
      "sequence:24 test finished, testing MSE=0.0006660834769718349\n",
      "sequence:5 - 25 repeat=0 training finished, training MSE=0.0005946814620983787 training asset=1\n",
      "sequence:5 - 25 repeat=1 training finished, training MSE=0.0006681419326923788 training asset=1\n",
      "sequence:5 - 25 repeat=2 training finished, training MSE=0.0006670234302873723 training asset=1\n",
      "sequence:5 - 25 repeat=3 training finished, training MSE=0.0006164114340208471 training asset=1\n",
      "sequence:5 - 25 repeat=4 training finished, training MSE=0.000603792688343674 training asset=1\n",
      "sequence:5 - 25 repeat=5 training finished, training MSE=0.0006124049556092359 training asset=1\n",
      "sequence:5 - 25 repeat=6 training finished, training MSE=0.0006172073844936676 training asset=1\n",
      "sequence:25 test finished, testing MSE=0.0003088780795224011\n",
      "sequence:26 test finished, testing MSE=0.0006248605786822736\n",
      "sequence:27 test finished, testing MSE=0.0005751281860284507\n",
      "sequence:28 test finished, testing MSE=0.0011076033115386963\n",
      "sequence:29 test finished, testing MSE=0.000597248028498143\n",
      "sequence:10 - 30 repeat=0 training finished, training MSE=0.0005960996088106186 training asset=1\n",
      "sequence:10 - 30 repeat=1 training finished, training MSE=0.0006020022454322315 training asset=1\n",
      "sequence:10 - 30 repeat=2 training finished, training MSE=0.0005905379308387637 training asset=1\n",
      "sequence:10 - 30 repeat=3 training finished, training MSE=0.0005886895771254786 training asset=1\n",
      "sequence:10 - 30 repeat=4 training finished, training MSE=0.0005913980668992736 training asset=1\n",
      "sequence:10 - 30 repeat=5 training finished, training MSE=0.0005944276053924114 training asset=1\n",
      "sequence:10 - 30 repeat=6 training finished, training MSE=0.0005964206531643868 training asset=1\n",
      "sequence:30 test finished, testing MSE=0.00028753906372003257\n",
      "sequence:31 test finished, testing MSE=0.000415319373132661\n",
      "sequence:32 test finished, testing MSE=0.00024515431141480803\n",
      "sequence:33 test finished, testing MSE=0.000445107783889398\n",
      "sequence:34 test finished, testing MSE=0.00043770248885266483\n",
      "sequence:15 - 35 repeat=0 training finished, training MSE=0.0005231817565800156 training asset=1\n",
      "sequence:15 - 35 repeat=1 training finished, training MSE=0.000523794285254553 training asset=1\n",
      "sequence:15 - 35 repeat=2 training finished, training MSE=0.0005238724872469902 training asset=1\n",
      "sequence:15 - 35 repeat=3 training finished, training MSE=0.0005231797200394795 training asset=1\n",
      "sequence:15 - 35 repeat=4 training finished, training MSE=0.0005227812900557183 training asset=1\n"
     ]
    }
   ],
   "source": [
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing data-prep-ema10-beta99.csv\n"
     ]
    }
   ],
   "source": [
    "filename = \"data-prep-ema10-beta99.csv\"\n",
    "print(\"pre-processing {}\".format(filename))\n",
    "data = pd.read_csv(filename, parse_dates=[\"timestamp\"])\n",
    "data['dayofweek'] = data['timestamp'].apply(lambda x: x.weekday())\n",
    "groups = data.set_index('timestamp').groupby(lambda x: x.date())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'timestamp',\n",
       " 'volume_0',\n",
       " 'volume_1',\n",
       " 'volume_2',\n",
       " 'volume_3',\n",
       " 'volume_4',\n",
       " 'volume_5',\n",
       " 'volume_6',\n",
       " 'volume_7',\n",
       " 'volume_8',\n",
       " 'volume_9',\n",
       " 'volume_10',\n",
       " 'volume_11',\n",
       " 'volume_12',\n",
       " 'volume_13',\n",
       " 'volume_14',\n",
       " 'volume_15',\n",
       " 'volume_16',\n",
       " 'volume_17',\n",
       " 'volume_18',\n",
       " 'volume_19',\n",
       " 'volume_20',\n",
       " 'volume_21',\n",
       " 'volume_22',\n",
       " 'volume_23',\n",
       " 'volume_24',\n",
       " 'volume_25',\n",
       " 'volume_26',\n",
       " 'volume_27',\n",
       " 'volume_28',\n",
       " 'volume_29',\n",
       " 'last_0',\n",
       " 'last_1',\n",
       " 'last_2',\n",
       " 'last_3',\n",
       " 'last_4',\n",
       " 'last_5',\n",
       " 'last_6',\n",
       " 'last_7',\n",
       " 'last_8',\n",
       " 'last_9',\n",
       " 'last_10',\n",
       " 'last_11',\n",
       " 'last_12',\n",
       " 'last_13',\n",
       " 'last_14',\n",
       " 'last_15',\n",
       " 'last_16',\n",
       " 'last_17',\n",
       " 'last_18',\n",
       " 'last_19',\n",
       " 'last_20',\n",
       " 'last_21',\n",
       " 'last_22',\n",
       " 'last_23',\n",
       " 'last_24',\n",
       " 'last_25',\n",
       " 'last_26',\n",
       " 'last_27',\n",
       " 'last_28',\n",
       " 'last_29',\n",
       " 'diff_ema_10_0',\n",
       " 'diff_ema_10_1',\n",
       " 'diff_ema_10_2',\n",
       " 'diff_ema_10_3',\n",
       " 'diff_ema_10_4',\n",
       " 'diff_ema_10_5',\n",
       " 'diff_ema_10_6',\n",
       " 'diff_ema_10_7',\n",
       " 'diff_ema_10_8',\n",
       " 'diff_ema_10_9',\n",
       " 'diff_ema_10_10',\n",
       " 'diff_ema_10_11',\n",
       " 'diff_ema_10_12',\n",
       " 'diff_ema_10_13',\n",
       " 'diff_ema_10_14',\n",
       " 'diff_ema_10_15',\n",
       " 'diff_ema_10_16',\n",
       " 'diff_ema_10_17',\n",
       " 'diff_ema_10_18',\n",
       " 'diff_ema_10_19',\n",
       " 'diff_ema_10_20',\n",
       " 'diff_ema_10_21',\n",
       " 'diff_ema_10_22',\n",
       " 'diff_ema_10_23',\n",
       " 'diff_ema_10_24',\n",
       " 'diff_ema_10_25',\n",
       " 'diff_ema_10_26',\n",
       " 'diff_ema_10_27',\n",
       " 'diff_ema_10_28',\n",
       " 'diff_ema_10_29',\n",
       " 'value_ema_10_beta_99_0',\n",
       " 'value_ema_10_beta_99_1',\n",
       " 'value_ema_10_beta_99_2',\n",
       " 'value_ema_10_beta_99_3',\n",
       " 'value_ema_10_beta_99_4',\n",
       " 'value_ema_10_beta_99_5',\n",
       " 'value_ema_10_beta_99_6',\n",
       " 'value_ema_10_beta_99_7',\n",
       " 'value_ema_10_beta_99_8',\n",
       " 'value_ema_10_beta_99_9',\n",
       " 'value_ema_10_beta_99_10',\n",
       " 'value_ema_10_beta_99_11',\n",
       " 'value_ema_10_beta_99_12',\n",
       " 'value_ema_10_beta_99_13',\n",
       " 'value_ema_10_beta_99_14',\n",
       " 'value_ema_10_beta_99_15',\n",
       " 'value_ema_10_beta_99_16',\n",
       " 'value_ema_10_beta_99_17',\n",
       " 'value_ema_10_beta_99_18',\n",
       " 'value_ema_10_beta_99_19',\n",
       " 'value_ema_10_beta_99_20',\n",
       " 'value_ema_10_beta_99_21',\n",
       " 'value_ema_10_beta_99_22',\n",
       " 'value_ema_10_beta_99_23',\n",
       " 'value_ema_10_beta_99_24',\n",
       " 'value_ema_10_beta_99_25',\n",
       " 'value_ema_10_beta_99_26',\n",
       " 'value_ema_10_beta_99_27',\n",
       " 'value_ema_10_beta_99_28',\n",
       " 'value_ema_10_beta_99_29',\n",
       " 'dayofweek']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
