{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sma(data, window):\n",
    "    \"\"\"\n",
    "    Calculates Simple Moving Average\n",
    "    http://fxtrade.oanda.com/learn/forex-indicators/simple-moving-average\n",
    "    \"\"\"\n",
    "    if len(data) < window:\n",
    "        return None\n",
    "    return sum(data[-window:]) / float(window)\n",
    "\n",
    "def get_ema(data, window):\n",
    "    if len(data) < 2 * window:\n",
    "        raise ValueError(\"data is too short\")\n",
    "    c = 2.0 / (window + 1)\n",
    "    current_ema = sma(data[-window*2:-window], window)\n",
    "    for value in data[-window:]:\n",
    "        current_ema = (c * value) + ((1 - c) * current_ema)\n",
    "    return current_ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetAttributes:\n",
    "    def __init__(self, n_neurons = 100, \n",
    "                 learning_rate = 0.003, \n",
    "                 num_layers = 1,\n",
    "                 rnn_type = 2,\n",
    "                 n_repeats = 2):\n",
    "        self.n_neurons = n_neurons;\n",
    "        self.learning_rate = learning_rate;\n",
    "        self.num_layers = num_layers;\n",
    "        self.rnn_type = rnn_type;\n",
    "        self.n_repeats = n_repeats\n",
    "        self.n_steps = None\n",
    "        self.n_inputs = None\n",
    "        self.n_outputs = 1\n",
    "        \n",
    "    def set_input_dimension(self, n_steps, n_inputs):\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetStates:\n",
    "    def __init__(self):\n",
    "        self.prediction_states = None\n",
    "        self.training_states = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatefulLstmModel:\n",
    "    def __init__(self,\n",
    "                n_neurons=100,\n",
    "                learning_rate=0.002,\n",
    "                num_layers=2,\n",
    "                rnn_type=1,\n",
    "                n_repeats=30):\n",
    "\n",
    "        self.net_attributes = NetAttributes(n_neurons,\n",
    "                                   learning_rate,\n",
    "                                   num_layers,\n",
    "                                   rnn_type,\n",
    "                                   n_repeats)\n",
    "        self.net_states = NetStates()\n",
    "        self.model_initialized = False\n",
    "        self.sess = None\n",
    "    \n",
    "    def __del__(self):\n",
    "        if self.sess != None:\n",
    "            self.sess.close()\n",
    "    \n",
    "    def get_batch(self, seq_index, data_train_input, data_train_output):\n",
    "        X_batch = data_train_input[seq_index:seq_index+1]\n",
    "        y_batch = data_train_output[seq_index:seq_index+1]\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    \n",
    "    def initialize_layers(self):\n",
    "        layers = None\n",
    "        net_attributes = self.net_attributes\n",
    "        if net_attributes.rnn_type == 0:\n",
    "            layers = [tf.nn.rnn_cell.BasicLSTMCell(net_attributes.n_neurons) \n",
    "              for _ in range(net_attributes.num_layers)]\n",
    "        elif net_attributes.rnn_type == 1:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(net_attributes.n_neurons, use_peepholes=False) \n",
    "              for _ in range(net_attributes.num_layers)]\n",
    "        elif net_attributes.rnn_type == 2:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(net_attributes.n_neurons, use_peepholes=True) \n",
    "              for _ in range(net_attributes.num_layers)]\n",
    "        else:\n",
    "            print(\"WRONG\")\n",
    "        return layers\n",
    "    \n",
    "    def reset_graph(self, seed=42):\n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def create_model(self):\n",
    "        net_attributes = self.net_attributes\n",
    "        self.X = tf.placeholder(tf.float32, [None, net_attributes.n_steps, net_attributes.n_inputs])\n",
    "        self.y = tf.placeholder(tf.float32, [None, net_attributes.n_steps, net_attributes.n_outputs])\n",
    "        layers = self.initialize_layers()\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "        self.init_state = tf.placeholder(tf.float32, [net_attributes.num_layers, 2, 1, net_attributes.n_neurons])\n",
    "        \n",
    "        state_per_layer_list = tf.unstack(self.init_state, axis=0)\n",
    "        rnn_tuple_state = tuple(\n",
    "            [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "             for idx in range(net_attributes.num_layers)]\n",
    "        )\n",
    "        \n",
    "        rnn_outputs, self.new_states = tf.nn.dynamic_rnn(cell, self.X, dtype=tf.float32, \n",
    "                                                    initial_state=rnn_tuple_state)\n",
    "        \n",
    "        stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, net_attributes.n_neurons])\n",
    "        stacked_outputs = tf.layers.dense(stacked_rnn_outputs, net_attributes.n_outputs)\n",
    "        self.outputs = tf.reshape(stacked_outputs, [-1, net_attributes.n_steps, net_attributes.n_outputs])\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.square(self.outputs - self.y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=net_attributes.learning_rate)\n",
    "        self.training_op = optimizer.minimize(self.loss)\n",
    "\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.model_initialized = True\n",
    "    \n",
    "    # train the model, input is the training data for one cycle\n",
    "    # input is in the shape: [days, steps, features], the features are \n",
    "    # 1. diff, 2. volume. 3. timesteps.\n",
    "    def fit(self, data_train_input, data_train_output, prediction_period):\n",
    "        net_attributes = self.net_attributes\n",
    "        net_states = self.net_states\n",
    "        n_inputs = data_train_input.shape[2]\n",
    "        n_steps = data_train_input.shape[1]\n",
    "\n",
    "        net_attributes.set_input_dimension(n_steps, n_inputs)\n",
    "        batch_size = 1\n",
    "        days = data_train_input.shape[0]\n",
    "        \n",
    "        self.reset_graph()\n",
    "        self.create_model()\n",
    "        my_loss_train_list = []\n",
    "        sess = tf.Session()\n",
    "        # TODO: load from file.\n",
    "\n",
    "        self.init.run(session=sess)\n",
    "        # if this is the first time of fit?\n",
    "        if self.net_states.training_states == None:\n",
    "            init_states = np.zeros((net_attributes.num_layers, 2, 1, net_attributes.n_neurons))\n",
    "        else:\n",
    "            init_states = self.net_states.training_states\n",
    "            \n",
    "        for repeat in range(net_attributes.n_repeats):\n",
    "            rnn_states = copy.deepcopy(init_states)\n",
    "            for seq in range(days):\n",
    "                X_batch, y_batch = self.get_batch(seq, data_train_input, data_train_output)\n",
    "                feed_dict = {\n",
    "                        self.X: X_batch,\n",
    "                        self.y: y_batch,\n",
    "                        self.init_state: rnn_states}\n",
    "                my_op, rnn_states, my_loss_train, my_outputs = sess.run([self.training_op, \n",
    "                          self.new_states, \n",
    "                          self.loss, \n",
    "                          self.outputs], feed_dict=feed_dict)\n",
    "\n",
    "                my_loss_train_list.append(my_loss_train)\n",
    "                # last repeat , remember the sates\n",
    "                if seq+1 == prediction_period and repeat == net_attributes.n_repeats-1:\n",
    "                    # next training loop starts from here\n",
    "                    training_states = copy.deepcopy(rnn_states)\n",
    "                my_loss_train_avg = sum(my_loss_train_list) / len(my_loss_train_list)\n",
    "\n",
    "            print(\"{} repeat={} training finished, training MSE={}\".format(\n",
    "                datetime.datetime.now().time(),\n",
    "                repeat, my_loss_train_avg))\n",
    "        \n",
    "        self.net_states.training_states = training_states\n",
    "        self.net_states.prediction_states = rnn_states\n",
    "        self.sess = sess\n",
    "        return\n",
    "    \n",
    "    def predict_base(self, data_test_input, data_test_output=None):\n",
    "        net_attributes = self.net_attributes\n",
    "        net_states = self.net_states\n",
    "        days = data_test_input.shape[0]\n",
    "        \n",
    "        rnn_states = copy.deepcopy(net_states.prediction_states)\n",
    "        #X, y, init_state, init, training_op, new_states, loss, outputs = self.create_model()\n",
    "        sess = self.sess\n",
    "        \n",
    "        my_loss_test_list = []\n",
    "        input_shape = data_test_input.shape\n",
    "        outputs_all_days = np.zeros((input_shape[0], input_shape[1], 1))\n",
    "        for seq in range(days):\n",
    "            if data_test_output is None:\n",
    "                feed_dict = {\n",
    "                    self.X: data_test_input[seq:seq+1],\n",
    "                    self.init_state: rnn_states,\n",
    "                }\n",
    "\n",
    "                rnn_states, my_outputs = sess.run([self.new_states, self.outputs], feed_dict=feed_dict)\n",
    "            else:\n",
    "                feed_dict = {\n",
    "                    self.X: data_test_input[seq:seq+1],\n",
    "                    self.y: data_test_output[seq:seq+1],\n",
    "                    self.init_state: rnn_states,\n",
    "                }\n",
    "\n",
    "                rnn_states, my_outputs, my_loss_test = sess.run([self.new_states, \n",
    "                                                                 self.outputs, self.loss], feed_dict=feed_dict)\n",
    "                print(\"Predicting seq:{} testing MSE: {}\".format(seq, my_loss_test))\n",
    "            outputs_all_days[seq] = my_outputs\n",
    "            \n",
    "        \n",
    "        return outputs_all_days\n",
    "    \n",
    "    def predict(self, data_test_input):\n",
    "        return self.predict_base(data_test_input)\n",
    "        \n",
    "    def predict_and_verify(self, data_test_input, data_test_output):\n",
    "        return self.predict_base(data_test_input, data_test_output)\n",
    "      \n",
    "    def get_attributes_filename(self, path):\n",
    "        if path[-1] != '/':\n",
    "            path += '/'\n",
    "        return path + 'net_attributes.pkl'\n",
    "    \n",
    "    def get_path(self, path, date):\n",
    "        if path[-1] != '/':\n",
    "            path += '/'\n",
    "        return path + date + '/'\n",
    "    \n",
    "    def get_states_filename(self, path, date):\n",
    "        return self.get_path(path, date) + 'net_states.pkl'\n",
    "    \n",
    "    def get_model_filename(self, path, date):\n",
    "        return self.get_path(path, date) + '/tf_session.ckpt'\n",
    "    \n",
    "    def save(self, path, date):\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(self.sess, self.get_model_filename(path, date))\n",
    "        with open(self.get_attributes_filename(path), 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.net_attributes, f, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.get_states_filename(path, date), 'wb') as f:\n",
    "            pickle.dump(self.net_states, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"Model saved in path: %s\" % path)\n",
    "        \n",
    "            \n",
    "    def load(self, path, date):\n",
    "        # TODO: if date is none, load the latest.\n",
    "        \n",
    "        # restore hyper-params\n",
    "        with open(self.get_attributes_filename(path), 'rb') as f:\n",
    "            self.net_attributes = pickle.load(f)\n",
    "\n",
    "        # restore states\n",
    "        with open(self.get_states_filename(path), 'rb') as f:\n",
    "            self.net_states = pickle.load(f)\n",
    "        \n",
    "        # 2. restore graph\n",
    "        if self.model_initialized == False:\n",
    "            self.reset_graph()\n",
    "            self.create_model()\n",
    "        \n",
    "        # 3. restore session\n",
    "        saver = tf.train.Saver()\n",
    "        self.sess = tf.Session()\n",
    "        saver.restore(self.sess, self.get_model_filename(path))\n",
    "        print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFormat:\n",
    "    NONE = 0\n",
    "    DAY = 1\n",
    "    WEEK = 2\n",
    "\n",
    "class DataManipulator:\n",
    "    def __init__(self, beta, ema, time_format, volume_input, use_centralized_bid, \n",
    "                split_daily_data, n_training_days):\n",
    "        self.beta = beta\n",
    "        self.ema = ema\n",
    "        self.time_format = time_format\n",
    "        self.volume_input = volume_input\n",
    "        self.use_centralized_bid = use_centralized_bid\n",
    "        self.split_daily_data = split_daily_data\n",
    "        self.n_training_days = n_training_days\n",
    "        self.scaler_input = None\n",
    "        self.scaler_output = None\n",
    "        \n",
    "    def volume_transform(self, volume_series):\n",
    "        # all the volumes must bigger than 0\n",
    "        assert(np.all(volume_series>=0))\n",
    "        return  np.log(volume_series.astype('float')+1)\n",
    "\n",
    "    def inverse_transform_output(self, scaled_outputs):\n",
    "        ori_shape = scaled_outputs.shape\n",
    "        outputs_reshaped = scaled_outputs.reshape((ori_shape[0]*ori_shape[1], \n",
    "                                                   ori_shape[2]))\n",
    "        #outputs = np.exp(self.scaler_output.inverse_transform(outputs_reshaped)) - 1\n",
    "        outputs = self.scaler_output.inverse_transform(outputs_reshaped)\n",
    "        return outputs.reshape(ori_shape)\n",
    "    \n",
    "    \n",
    "    def transform(self, data_all, n_inputs, n_outputs):\n",
    "        orig_shape = data_all.shape\n",
    "        data_train_reshape = data_all.astype('float').reshape((orig_shape[0] * orig_shape[1], orig_shape[2]))\n",
    "        \n",
    "        self.scaler_input = preprocessing.MinMaxScaler().fit(data_train_reshape[:,:n_inputs])\n",
    "        data_train_input_scaled = self.scaler_input.transform(data_train_reshape[:,:n_inputs])\n",
    "        \n",
    "        # the invalid step, we change it to zero!\n",
    "        data_train_input_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "        data_train_input = data_train_input_scaled.reshape(orig_shape[0], orig_shape[1], n_inputs)\n",
    "        \n",
    "        self.scaler_output = preprocessing.MinMaxScaler().fit(data_train_reshape[:,-n_outputs:])\n",
    "        data_train_output_scaled = self.scaler_output.transform(data_train_reshape[:,-n_outputs:])\n",
    "        # the invalid step, we change it to zero!\n",
    "        data_train_output_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "        data_train_output = data_train_output_scaled.reshape(orig_shape[0], orig_shape[1], n_outputs)\n",
    "        \n",
    "        return data_train_input, data_train_output\n",
    "\n",
    "    def prep_test_data(self, input_path):\n",
    "        return\n",
    "    \n",
    "    def prep_training_data(self, input_path, stock_index):\n",
    "        # load numpy file\n",
    "        npy_file_name = input_path + \"/ema{}_beta{}_{}.npy\".format(self.ema, self.beta, stock_index)\n",
    "        input_np_data = np.load(npy_file_name, allow_pickle=True)\n",
    "        \n",
    "        # date list\n",
    "        date_list = []\n",
    "        for i in range(self.n_training_days):    \n",
    "            date = input_np_data[i][0][5].date().strftime(\"%y%m%d\")\n",
    "            date_list.append(date_list)\n",
    "        \n",
    "        \n",
    "        # check if we have days more than training period\n",
    "        assert(input_np_data.shape[0] >= self.n_training_days)\n",
    "        # the diff is the mandatory\n",
    "        input_columns = [2]\n",
    "        \n",
    "        time_format = self.time_format\n",
    "        \n",
    "        if time_format == TimeFormat.DAY:\n",
    "            input_columns += [0]\n",
    "        elif time_format == TimeFormat.WEEK:\n",
    "            input_columns += [1]\n",
    "        \n",
    "        if self.volume_input == 1:\n",
    "            input_columns += [3]\n",
    "        \n",
    "        output_columns = [4]\n",
    "        timestamp_column = [5]\n",
    "        price_column = [6]\n",
    "        input_np_data = input_np_data[:,:,input_columns + output_columns + timestamp_column + price_column]\n",
    "        \n",
    "        # we must tranform the volume for it is too big.\n",
    "        if self.volume_input == 1:\n",
    "            input_np_data[:,:,-4] = self.volume_transform(input_np_data[:,:,-4])\n",
    "        \n",
    "        if self.use_centralized_bid == 0:\n",
    "            # remove all the rows for centralized bid. it should be from 9.01 to 17.24, which is 516-12=504 steps\n",
    "            input_np_data = input_np_data[:,7:-5,:]\n",
    "            \n",
    "        shape = input_np_data.shape\n",
    "        n_training_sequences = self.n_training_days\n",
    "        if self.split_daily_data == 1:\n",
    "            assert(shape[1] % 2 == 0)\n",
    "            input_np_data = input_np_data.reshape((shape[0]*2, \n",
    "                                                  int(shape[1]/2), \n",
    "                                                  shape[2]))\n",
    "            # get the first date and last date\n",
    "            n_training_sequences *= 2\n",
    "            \n",
    "        # to scale the data, but not the timestamp and price\n",
    "        data_train_input, data_train_output = self.transform(input_np_data[:n_training_sequences,:,:-2], len(input_columns), 1)\n",
    "        return data_train_input, data_train_output, input_np_data[:n_training_sequences,:,-2], input_np_data[:n_training_sequences,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyDesc:\n",
    "    def __init__(self, \n",
    "                 buy_threshold,\n",
    "                 sell_threshold,\n",
    "                 stop_loss,\n",
    "                 stop_gain,\n",
    "                 min_hold_steps):\n",
    "        self.buy_threshold = buy_threshold\n",
    "        self.sell_threshold = sell_threshold\n",
    "        self.stop_loss = stop_loss\n",
    "        self.stop_gain = stop_gain\n",
    "        self.min_hold_steps = min_hold_steps\n",
    "        \n",
    "    def get_parameter_str(self):\n",
    "        s = \"buy_threshold:{} sell_threshold:{} stop_loss:{} \\\n",
    "            stop_gain:{} min_hold_steps:{}\".format(self.buy_threshold,\n",
    "                                                  self.sell_threshold,\n",
    "                                                  self.stop_loss,\n",
    "                                                  self.stop_gain,\n",
    "                                                  self.min_hold_steps)\n",
    "        return s\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import GPy\n",
    "import GPyOpt\n",
    "\n",
    "class ValueModel:\n",
    "    mixed_domain = [{'name': 'n_neurons', 'type': 'discrete', 'domain': tuple(range(20,160,20))},\n",
    "          {'name': 'learning_rate', 'type': 'discrete', 'domain': (0.001,0.002,0.003,0.004)},\n",
    "          {'name': 'num_layers', 'type': 'discrete', 'domain': (1,2,3,4)},\n",
    "          {'name': 'rnn_type', 'type': 'discrete', 'domain': (0,1,2)},\n",
    "          {'name': 'learning_period', 'type': 'discrete', 'domain': (10,20,30,40)},\n",
    "          {'name': 'prediction_period', 'type': 'discrete', 'domain': (1,2,5,10)},\n",
    "          {'name': 'n_repeats', 'type': 'discrete', 'domain': (3,5,10,20,30,40)},\n",
    "          {'name': 'beta', 'type': 'discrete', 'domain': (99, 98)},\n",
    "          {'name': 'ema', 'type': 'discrete', 'domain': (1,5,10,20)},\n",
    "          {'name': 'time_format', 'type': 'discrete', 'domain': (0,1,2)}, #1 for stepofday, 2 for stepofweek\n",
    "          {'name': 'volume_input', 'type': 'discrete', 'domain': (0,1)},\n",
    "          {'name': 'use_centralized_bid', 'type': 'discrete', 'domain': (0,1)},\n",
    "          {'name': 'split_daily_data', 'type': 'discrete', 'domain': (0,1)}\n",
    "         ]\n",
    "    \n",
    "    mixed_domain_test = [{'name': 'n_neurons', 'type': 'discrete', 'domain': tuple(range(20,160,20))},\n",
    "          {'name': 'learning_rate', 'type': 'discrete', 'domain': (0.001,0.002,0.003,0.004)},\n",
    "          {'name': 'num_layers', 'type': 'discrete', 'domain': (1,2,3,4)},\n",
    "          {'name': 'rnn_type', 'type': 'discrete', 'domain': (0,1,2)},\n",
    "          {'name': 'learning_period', 'type': 'discrete', 'domain': (10,20)},\n",
    "          {'name': 'prediction_period', 'type': 'discrete', 'domain': (5,10)},\n",
    "          {'name': 'n_repeats', 'type': 'discrete', 'domain': (3,5)},\n",
    "          {'name': 'beta', 'type': 'discrete', 'domain': (99, 98)},\n",
    "          {'name': 'ema', 'type': 'discrete', 'domain': (1,5,10,20)},\n",
    "          {'name': 'time_format', 'type': 'discrete', 'domain': (0,1,2)}, #1 for stepofday, 2 for stepofweek\n",
    "          {'name': 'volume_input', 'type': 'discrete', 'domain': (0,1)},\n",
    "          {'name': 'use_centralized_bid', 'type': 'discrete', 'domain': (0,1)},\n",
    "          {'name': 'split_daily_data', 'type': 'discrete', 'domain': (0,1)}\n",
    "         ]\n",
    "    \n",
    "    \n",
    "    def __init__(self, stock_name, stock_index, n_training_days):\n",
    "        self.stock_name = stock_name\n",
    "        self.stock_index = stock_index\n",
    "        self.n_training_days = n_training_days\n",
    "        self.save_path = \"model_{}_{}\".format(stock_name, n_training_days)\n",
    "        self.last_training_date = None\n",
    "        self.model = None\n",
    "        self.max_profit = -999.0\n",
    "        return\n",
    "    \n",
    "    def get_parameter_str(self, X):\n",
    "        parameter_str = \"\"\n",
    "        for i in range(len(self.mixed_domain)):\n",
    "            parameter_str += self.mixed_domain[i][\"name\"]\n",
    "            parameter_str += ':'\n",
    "            parameter_str += str(X[i])\n",
    "            parameter_str += ','\n",
    "        return parameter_str\n",
    "    \n",
    "    def get_max_steps(self, groups):\n",
    "        max_steps = 0\n",
    "        for index, df in groups:\n",
    "            df_len = len(df)\n",
    "            if df_len > max_steps:\n",
    "                max_steps = df_len\n",
    "        return max_steps\n",
    "\n",
    "    \n",
    "    def get_data_prep_desc_filename(self, path):\n",
    "        return path + '/data_prep_desc.pkl'\n",
    "    \n",
    "    def optimize(self, input_csv_path, max_iter=300, is_test=False):\n",
    "        if is_test == True:\n",
    "            mixed_domain = self.mixed_domain_test\n",
    "        else:\n",
    "            mixed_domain = self.mixed_domain\n",
    "        \n",
    "        opt_handler = GPyOpt.methods.BayesianOptimization(f=self.opt_func,  # Objective function       \n",
    "                                     domain=mixed_domain,          # Box-constraints of the problem\n",
    "                                     initial_design_numdata = 20,   # Number data initial design\n",
    "                                     acquisition_type='EI',        # Expected Improvement\n",
    "                                     exact_feval = True)           # True evaluations, no sample noise\n",
    "        opt_handler.run_optimization(max_iter, eps=0)\n",
    "    \n",
    "    def save(self):\n",
    "        self.model.save(self.save_path, self.last_training_date)\n",
    "        \n",
    "    def load(self):\n",
    "        save_path = self.save_path\n",
    "        \n",
    "        # iterate the path, and find out the latest date\n",
    "        \n",
    "    \n",
    "    def opt_func(self, X_list):\n",
    "        assert(len(X_list)==1)\n",
    "        answer = np.zeros((X_list.shape[0], 1))\n",
    "        for i in range(len(X_list)):\n",
    "            print(self.get_parameter_str(X_list[i]))\n",
    "            features = X_list[i]\n",
    "            error, model, value_price = self.get_value_result(features)\n",
    "            \n",
    "            strategy_model = StrategyModel()\n",
    "            strategy_model.optimize(value_price)\n",
    "            profit, is_hold = strategy_model.get_best_result()\n",
    "            print(\"total profit={},  error={}\".format(profit, error))\n",
    "            #self.draw_step_profit_graph(self.step_profit_list, \"step_profit_{}\".format(answer[i][0]))\n",
    "            #self.step_profit_list = []\n",
    "            if profit > self.max_profit:\n",
    "                strategy_desc = strategy_model.get_strategy_desc()\n",
    "                \n",
    "                print(\"find new opt:{}, {}, {}\".format(profit, \n",
    "                                                   self.get_parameter_str(X_list[i]),\n",
    "                                                   strategy_desc.get_parameter_str()))\n",
    "                self.model = model\n",
    "                self.save()\n",
    "                self.max_profit = profit\n",
    "                \n",
    "                strategy_model.save(self.save_path)\n",
    "                \n",
    "                \n",
    "                # save the data into file for further analysis\n",
    "                np_data_to_save = np.concatenate((value_price, is_hold), axis=2)\n",
    "                print(\"np_data_to_save\")\n",
    "                print(np_data_to_save.shape)\n",
    "                np.save(self.save_path + '/best_policy_data.npy', np_data_to_save)\n",
    "                \n",
    "                # check the optimized strategy for this model\n",
    "            answer[i][0] = -profit\n",
    "        return answer\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_value_result(self, features):\n",
    "        n_neurons = int(features[0])\n",
    "        learning_rate = features[1]\n",
    "        num_layers = int(features[2])\n",
    "        rnn_type = int(features[3])\n",
    "        learning_period = int(features[4])\n",
    "        prediction_period = int(features[5])\n",
    "        n_repeats = int(features[6])\n",
    "        beta = int(features[7])\n",
    "        ema = int(features[8])\n",
    "        time_format = int(features[9])\n",
    "        volume_input = int(features[10])\n",
    "        use_centralized_bid = int(features[11])\n",
    "        split_daily_data = int(features[12])\n",
    "        \n",
    "        assert((self.n_training_days - learning_period) % prediction_period == 0)\n",
    "        data_manipulator = DataManipulator(beta, ema, \n",
    "                                           time_format, \n",
    "                                           volume_input, \n",
    "                                           use_centralized_bid, \n",
    "                                           split_daily_data, \n",
    "                                           self.n_training_days)\n",
    "        npy_path = 'npy_files'\n",
    "        data_training_input, data_training_output, timestamps, price \\\n",
    "            = data_manipulator.prep_training_data(npy_path, self.stock_index)\n",
    "        \n",
    "        # get the date list.\n",
    "        date_list = []\n",
    "        for i in range(len(timestamps)):\n",
    "            date = timestamps[i][0].strftime(\"%y%m%d\")\n",
    "            date_list.append(date)\n",
    "        \n",
    "\n",
    "        \n",
    "        # now define the network\n",
    "        model = StatefulLstmModel(n_neurons, learning_rate, num_layers, rnn_type, n_repeats)\n",
    "        \n",
    "        assert(self.n_training_days % prediction_period == 0)\n",
    "        \n",
    "        n_training_seq = self.n_training_days\n",
    "        n_learning_seq = learning_period\n",
    "        n_prediction_seq = prediction_period\n",
    "        if split_daily_data == 1:\n",
    "            n_training_seq *= 2\n",
    "            n_learning_seq *= 2\n",
    "            n_prediction_seq *= 2\n",
    "            \n",
    "        self.last_training_date = date_list[-1]\n",
    "        daily_errors = []\n",
    "        all_outputs = []\n",
    "        print(\"start training: training_seq:{}, learning_seq:{}, prediction_seq:{} last_training_date:{}\".format(n_training_seq, \n",
    "                                                                                           n_learning_seq, \n",
    "                                                                                           n_prediction_seq,\n",
    "                                                                                           self.last_training_date))\n",
    "        for i in range(0, n_training_seq-n_learning_seq+1, n_prediction_seq):\n",
    "            learning_end = i + n_learning_seq\n",
    "            print(\"start training from seq:{}({}) - seq:{}({})\".format(i, date_list[i], learning_end-1, date_list[learning_end-1]))\n",
    "            model.fit(data_training_input[i:learning_end], data_training_output[:learning_end], n_prediction_seq)\n",
    "            prediction_end = learning_end + n_prediction_seq\n",
    "            if prediction_end > n_training_seq:\n",
    "                break\n",
    "            \n",
    "            print(\"start predicting from seq:{}({}) - seq:{}({})\".format(learning_end, date_list[learning_end], \n",
    "                                                                       prediction_end-1, date_list[prediction_end-1]))\n",
    "            \n",
    "            outputs = model.predict_and_verify(data_training_input[learning_end:prediction_end], \n",
    "                                     data_training_output[learning_end:prediction_end])\n",
    "            print(\"output.shape\")\n",
    "            print(outputs.shape)\n",
    "            all_outputs.append(outputs)\n",
    "            # calculate the error for every day\n",
    "            y = data_training_output[learning_end:prediction_end]\n",
    "            # error is a 1-D array for the every day error\n",
    "            error = np.mean(np.square(outputs-y), axis=(1,2))\n",
    "        \n",
    "            daily_errors += error.tolist()\n",
    "            \n",
    "        np_all_outputs = np.array(all_outputs)\n",
    "        print(\"np_all_outputs.shape\")\n",
    "        print(np_all_outputs.shape)\n",
    "        shape = np_all_outputs.shape\n",
    "        \n",
    "        n_predicted_days = self.n_training_days - learning_period\n",
    "        if split_daily_data == 1:\n",
    "            steps_per_day = data_training_input.shape[1] * 2\n",
    "        else:\n",
    "            steps_per_day = data_training_input.shape[1]\n",
    "        \n",
    "        \n",
    "        np_all_outputs = np_all_outputs.reshape((n_predicted_days, steps_per_day,1))\n",
    "        np_all_outputs = data_manipulator.inverse_transform_output(np_all_outputs)\n",
    "        \n",
    "        print(\"np_all_outputs.shape\")\n",
    "        print(np_all_outputs.shape)\n",
    "        shape = timestamps.shape\n",
    "        timestamps = timestamps.reshape((self.n_training_days, steps_per_day, 1))\n",
    "        price = price.reshape((self.n_training_days, steps_per_day, 1))\n",
    "        \n",
    "        print(\"timestamps.shape\")\n",
    "        print(timestamps.shape)\n",
    "        value_with_timestamp_price = np.concatenate((timestamps[learning_period:],\n",
    "                                               np_all_outputs,\n",
    "                                               price[learning_period:]), axis=2)\n",
    "        print(\"value_with_timestamp_price\")\n",
    "        print(value_with_timestamp_price.shape)\n",
    "        ema = get_ema(daily_errors, int(len(daily_errors)/2))\n",
    "        print(\"test finished, the ema of testing error:{}\".format(ema))\n",
    "        \n",
    "        return ema, model, value_with_timestamp_price\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyModel:\n",
    "    mixed_domain = [{'name': 'buy_threshold', 'type': 'continuous', 'domain': (0.0, 0.005)},\n",
    "                 {'name': 'sell_threshold', 'type': 'continuous', 'domain': (-0.005, 0.0)},\n",
    "                 {'name': 'stop_loss', 'type': 'continuous', 'domain': (-0.01,-0.003)},\n",
    "                 {'name': 'stop_gain', 'type': 'continuous', 'domain': (0.002, 0.01)},\n",
    "                 {'name': 'min_hold_steps', 'type': 'discrete', 'domain': range(10,100)},\n",
    "         ]\n",
    "    def __init__(self):\n",
    "        self.max_profit = -999.0\n",
    "        self.strategy_desc = None\n",
    "        return\n",
    "\n",
    "    def optimize(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        \n",
    "        myBopt = GPyOpt.methods.BayesianOptimization(self.get_profit,  # Objective function       \n",
    "                                             domain=self.mixed_domain,          # Box-constraints of the problem\n",
    "                                             initial_design_numdata = 30,   # Number data initial design\n",
    "                                             acquisition_type='EI',        # Expected Improvement\n",
    "                                             exact_feval = True,\n",
    "                                             maximize = True)           # True evaluations, no sample noise\n",
    "\n",
    "        myBopt.run_optimization(300,eps=0)\n",
    "        return 0\n",
    "        \n",
    "    # the input data is in shape (days, steps, [timestamp, value, price])\n",
    "    def get_profit(self, X_list):\n",
    "        assert(len(X_list)==1)\n",
    "        buy_threshold = X_list[0][0]\n",
    "        sell_threshold = X_list[0][1]\n",
    "        stop_loss = X_list[0][2]\n",
    "        stop_gain = X_list[0][3]\n",
    "        min_hold_steps = int(X_list[0][4])\n",
    "        tot_profit = 1\n",
    "        tot_stock_profit = 1\n",
    "        buy_step = None\n",
    "        max_trades = 3\n",
    "        cost = 0.00015\n",
    "        n_tot_trades = 0\n",
    "        \n",
    "        # to prepare the result data\n",
    "        shape = self.input_data.shape\n",
    "        is_hold = np.zeros((shape[0], shape[1], 1))\n",
    "        daily_profit_list = []\n",
    "        for day_idx in range(len(self.input_data)):\n",
    "            #print(\"starting day {}\".format(day_idx))\n",
    "            n_trades = 0\n",
    "            daily_profit = 1\n",
    "            state = 0\n",
    "            daily_data = self.input_data[day_idx]\n",
    "            for step in range(len(daily_data)):\n",
    "                value = daily_data[step][1]\n",
    "                price = daily_data[step][2]\n",
    "                time = daily_data[step][0]\n",
    "                \n",
    "                if state == 0 and time.time().hour >= 9 and \\\n",
    "                    n_trades < max_trades and step < len(daily_data)-min_hold_steps:\n",
    "                    if value > buy_threshold:\n",
    "                        buy_price = price\n",
    "                        buy_step = step\n",
    "                        #print(\"buy at step {} price:{}\".format(step, price))\n",
    "                        state = 1\n",
    "\n",
    "                elif state == 1:\n",
    "                    profit = (price - buy_price)/buy_price\n",
    "                    if (value < sell_threshold and \n",
    "                        step - buy_step > min_hold_steps) or step == len(daily_data)-1 or \\\n",
    "                        profit < stop_loss or \\\n",
    "                        profit > stop_gain:\n",
    "                        \n",
    "                        if profit < stop_loss:\n",
    "                            n_trades = max_trades\n",
    "                        \n",
    "                        #print(\"sell at step {} price:{}\".format(step, price))\n",
    "                        profit -= cost\n",
    "                        tot_profit *= (1+profit)\n",
    "                        daily_profit *= (1 + profit)\n",
    "                        state = 0\n",
    "                        n_trades += 1\n",
    "                \n",
    "                if state == 1:\n",
    "                    is_hold[day_idx][step] = 1\n",
    "                else:\n",
    "                    is_hold[day_idx][step] = 0\n",
    "            daily_profit_list.append(daily_profit - 1)\n",
    "            n_tot_trades += n_trades\n",
    "            last = daily_data[-1][2]\n",
    "            open = daily_data[0][2]\n",
    "            stock_profit = (last - open) / open\n",
    "            tot_stock_profit *= (1+stock_profit)\n",
    "        \n",
    "            #print(\"finishing day {}, daily_profit:{}\".format(day_idx, daily_profit))\n",
    "        #print(\"{}, n_tot_trades:{} profit:{}\".format(X_list, n_tot_trades, tot_profit))\n",
    "        window = int(len(daily_profit_list)/2)\n",
    "        profit_ema = get_ema(daily_profit_list, window)\n",
    "        if profit_ema > self.max_profit:\n",
    "            print(\"find best profit ema:{} tot_profit:{} in days:{}\".format(profit_ema, \n",
    "                                                                            tot_profit,\n",
    "                                                                            window*2))\n",
    "            \n",
    "            self.max_profit = profit_ema\n",
    "            self.is_hold = is_hold\n",
    "            self.strategy_desc = StrategyDesc(buy_threshold,\n",
    "                                             sell_threshold,\n",
    "                                             stop_loss,\n",
    "                                             stop_gain,\n",
    "                                             min_hold_steps)\n",
    "        \n",
    "        return np.array(profit_ema).reshape((1,1))\n",
    "    \n",
    "    def get_best_result(self):\n",
    "        return self.max_profit, self.is_hold\n",
    "    \n",
    "    \n",
    "    def get_strategy_desc(self):\n",
    "        return self.strategy_desc\n",
    "    \n",
    "    def get_save_filename(self, path):\n",
    "        if path[-1] != '/':\n",
    "            path += '/'\n",
    "        \n",
    "        return path + 'strategy_desc.pkl'\n",
    "        \n",
    "    \n",
    "    def save(self, save_path):\n",
    "        assert(self.strategy_desc != None)\n",
    "        with open(self.get_save_filename(save_path), 'wb') as f:\n",
    "            pickle.dump(self.strategy_desc, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neurons:120.0,learning_rate:0.002,num_layers:4.0,rnn_type:1.0,learning_period:10.0,prediction_period:5.0,n_repeats:3.0,beta:99.0,ema:1.0,time_format:2.0,volume_input:0.0,use_centralized_bid:0.0,split_daily_data:1.0,\n",
      "start training: training_seq:60, learning_seq:20, prediction_seq:10 last_training_date:190308\n",
      "start training from seq:0(190128) - seq:19(190208)\n",
      "22:10:12.358964 repeat=0 training finished, training MSE=0.20414396623382344\n",
      "22:10:15.351312 repeat=1 training finished, training MSE=0.1132542722611106\n",
      "22:10:18.339396 repeat=2 training finished, training MSE=0.07635200858009436\n",
      "start predicting from seq:20(190211) - seq:29(190215)\n",
      "Predicting seq:0 testing MSE: 0.0009470332297496498\n",
      "Predicting seq:1 testing MSE: 0.00045540256542153656\n",
      "Predicting seq:2 testing MSE: 0.0006093474803492427\n",
      "Predicting seq:3 testing MSE: 0.0005696616717614233\n",
      "Predicting seq:4 testing MSE: 0.0005797714693471789\n",
      "Predicting seq:5 testing MSE: 0.0003437161212787032\n",
      "Predicting seq:6 testing MSE: 0.0006000444409437478\n",
      "Predicting seq:7 testing MSE: 0.0005858668591827154\n",
      "Predicting seq:8 testing MSE: 0.002016538055613637\n",
      "Predicting seq:9 testing MSE: 0.0017277366714552045\n",
      "output.shape\n",
      "(10, 252, 1)\n",
      "start training from seq:10(190204) - seq:29(190215)\n",
      "22:10:22.676826 repeat=0 training finished, training MSE=0.2141365319257602\n",
      "22:10:25.651543 repeat=1 training finished, training MSE=0.11830267912737327\n",
      "22:10:28.613945 repeat=2 training finished, training MSE=0.07962784921692219\n",
      "start predicting from seq:30(190218) - seq:39(190222)\n",
      "Predicting seq:0 testing MSE: 0.0008465439896099269\n",
      "Predicting seq:1 testing MSE: 0.0005936879897490144\n",
      "Predicting seq:2 testing MSE: 0.0026312570553272963\n",
      "Predicting seq:3 testing MSE: 0.0006638287450186908\n",
      "Predicting seq:4 testing MSE: 0.004888970870524645\n",
      "Predicting seq:5 testing MSE: 0.001166570815257728\n",
      "Predicting seq:6 testing MSE: 0.005686007905751467\n",
      "Predicting seq:7 testing MSE: 0.0030546635389328003\n",
      "Predicting seq:8 testing MSE: 0.005329447332769632\n",
      "Predicting seq:9 testing MSE: 0.0014749511610716581\n",
      "output.shape\n",
      "(10, 252, 1)\n",
      "start training from seq:20(190211) - seq:39(190222)\n",
      "22:10:32.813844 repeat=0 training finished, training MSE=0.21643651018384844\n",
      "22:10:35.792455 repeat=1 training finished, training MSE=0.12028959438321181\n",
      "22:10:38.758240 repeat=2 training finished, training MSE=0.08094775984548809\n",
      "start predicting from seq:40(190225) - seq:49(190301)\n",
      "Predicting seq:0 testing MSE: 0.0008370514260604978\n",
      "Predicting seq:1 testing MSE: 0.0006135026924312115\n",
      "Predicting seq:2 testing MSE: 0.000951734371483326\n",
      "Predicting seq:3 testing MSE: 0.0010859605390578508\n",
      "Predicting seq:4 testing MSE: 0.0014676073333248496\n",
      "Predicting seq:5 testing MSE: 0.000911308394279331\n",
      "Predicting seq:6 testing MSE: 0.0013555241748690605\n",
      "Predicting seq:7 testing MSE: 0.0009775884682312608\n",
      "Predicting seq:8 testing MSE: 0.0007509264978580177\n",
      "Predicting seq:9 testing MSE: 0.0010847569210454822\n",
      "output.shape\n",
      "(10, 252, 1)\n",
      "start training from seq:30(190218) - seq:49(190301)\n",
      "22:10:43.148975 repeat=0 training finished, training MSE=0.21602439793059602\n",
      "22:10:46.495030 repeat=1 training finished, training MSE=0.11960527395276585\n",
      "22:10:50.209731 repeat=2 training finished, training MSE=0.08060457832082951\n",
      "start predicting from seq:50(190304) - seq:59(190308)\n",
      "Predicting seq:0 testing MSE: 0.015533440746366978\n",
      "Predicting seq:1 testing MSE: 0.010520393960177898\n",
      "Predicting seq:2 testing MSE: 0.0015873783268034458\n",
      "Predicting seq:3 testing MSE: 0.0013020181795582175\n",
      "Predicting seq:4 testing MSE: 0.0005534908850677311\n",
      "Predicting seq:5 testing MSE: 0.0014956045197322965\n",
      "Predicting seq:6 testing MSE: 0.0008037271909415722\n",
      "Predicting seq:7 testing MSE: 0.002771577797830105\n",
      "Predicting seq:8 testing MSE: 0.0005504025612026453\n",
      "Predicting seq:9 testing MSE: 0.0006215393077582121\n",
      "output.shape\n",
      "(10, 252, 1)\n",
      "start training from seq:40(190225) - seq:59(190308)\n",
      "22:10:54.861463 repeat=0 training finished, training MSE=0.212054114905186\n",
      "22:10:58.153832 repeat=1 training finished, training MSE=0.1173753395822132\n",
      "22:11:01.912989 repeat=2 training finished, training MSE=0.07898968164663529\n",
      "np_all_outputs.shape\n",
      "(4, 10, 252, 1)\n",
      "np_all_outputs.shape\n",
      "(20, 504, 1)\n",
      "timestamps.shape\n",
      "(30, 504, 1)\n",
      "value_with_timestamp_price\n",
      "(20, 504, 3)\n",
      "test finished, the ema of testing error:0.002172038262219936\n",
      "find best profit ema:0.0011149330645557026 tot_profit:1.0190542564283014 in days:20\n",
      "find best profit ema:0.0011758555456124616 tot_profit:1.020811124627609 in days:20\n",
      "find best profit ema:0.0012255264853486007 tot_profit:1.0221190613045539 in days:20\n"
     ]
    }
   ],
   "source": [
    "value_model = ValueModel('Nordea', 5, 30)\n",
    "value_model.optimize('.', is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
