{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetAttributes:\n",
    "    def __init__(self, n_neurons = 100, \n",
    "                 learning_rate = 0.003, \n",
    "                 num_layers = 1,\n",
    "                 rnn_type = 2,\n",
    "                 n_repeats = 2):\n",
    "        self.n_neurons = n_neurons;\n",
    "        self.learning_rate = learning_rate;\n",
    "        self.num_layers = num_layers;\n",
    "        self.rnn_type = rnn_type;\n",
    "        self.n_repeats = n_repeats\n",
    "        self.n_steps = None\n",
    "        self.n_inputs = None\n",
    "        self.n_outputs = 1\n",
    "        \n",
    "    def set_input_dimension(self, n_steps, n_inputs):\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetStates:\n",
    "    def __init__(self):\n",
    "        self.prediction_states = None\n",
    "        self.training_states = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatefulLstmModel:\n",
    "    def __init__(self,\n",
    "                n_neurons=100,\n",
    "                learning_rate=0.002,\n",
    "                num_layers=2,\n",
    "                rnn_type=1,\n",
    "                n_repeats=30):\n",
    "\n",
    "        self.net_attributes = NetAttributes(n_neurons,\n",
    "                                   learning_rate,\n",
    "                                   num_layers,\n",
    "                                   rnn_type,\n",
    "                                   n_repeats)\n",
    "        self.net_states = NetStates()\n",
    "        self.model_initialized = False\n",
    "    \n",
    "    def __del__(self):\n",
    "        if self.sess != None:\n",
    "            self.sess.close()\n",
    "    \n",
    "    def get_batch(self, seq_index, data_train_input, data_train_output):\n",
    "        X_batch = data_train_input[seq_index:seq_index+1]\n",
    "        y_batch = data_train_output[seq_index:seq_index+1]\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    \n",
    "    def initialize_layers(self):\n",
    "        layers = None\n",
    "        net_attributes = self.net_attributes\n",
    "        if net_attributes.rnn_type == 0:\n",
    "            layers = [tf.nn.rnn_cell.BasicLSTMCell(net_attributes.n_neurons) \n",
    "              for _ in range(net_attributes.num_layers)]\n",
    "        elif net_attributes.rnn_type == 1:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(net_attributes.n_neurons, use_peepholes=False) \n",
    "              for _ in range(net_attributes.num_layers)]\n",
    "        elif net_attributes.rnn_type == 2:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(net_attributes.n_neurons, use_peepholes=True) \n",
    "              for _ in range(net_attributes.num_layers)]\n",
    "        else:\n",
    "            print(\"WRONG\")\n",
    "        return layers\n",
    "    \n",
    "    def reset_graph(self, seed=42):\n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def create_model(self):\n",
    "        net_attributes = self.net_attributes\n",
    "        self.X = tf.placeholder(tf.float32, [None, net_attributes.n_steps, net_attributes.n_inputs])\n",
    "        self.y = tf.placeholder(tf.float32, [None, net_attributes.n_steps, net_attributes.n_outputs])\n",
    "        layers = self.initialize_layers()\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "        self.init_state = tf.placeholder(tf.float32, [net_attributes.num_layers, 2, 1, net_attributes.n_neurons])\n",
    "        \n",
    "        state_per_layer_list = tf.unstack(self.init_state, axis=0)\n",
    "        rnn_tuple_state = tuple(\n",
    "            [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "             for idx in range(net_attributes.num_layers)]\n",
    "        )\n",
    "        \n",
    "        rnn_outputs, self.new_states = tf.nn.dynamic_rnn(cell, self.X, dtype=tf.float32, \n",
    "                                                    initial_state=rnn_tuple_state)\n",
    "        \n",
    "        stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, net_attributes.n_neurons])\n",
    "        stacked_outputs = tf.layers.dense(stacked_rnn_outputs, net_attributes.n_outputs)\n",
    "        self.outputs = tf.reshape(stacked_outputs, [-1, net_attributes.n_steps, net_attributes.n_outputs])\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.square(self.outputs - self.y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=net_attributes.learning_rate)\n",
    "        self.training_op = optimizer.minimize(self.loss)\n",
    "\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.model_initialized = True\n",
    "    \n",
    "    # train the model, input is the training data for one cycle\n",
    "    # input is in the shape: [days, steps, features], the features are \n",
    "    # 1. diff, 2. volume. 3. timesteps.\n",
    "    def fit(self, data_train_input, data_train_output, prediction_period):\n",
    "        net_attributes = self.net_attributes\n",
    "        net_states = self.net_states\n",
    "        n_inputs = data_train_input.shape[2]\n",
    "        n_steps = data_train_input.shape[1]\n",
    "        print(\"net_attributes\")\n",
    "        print(net_attributes)\n",
    "        net_attributes.set_input_dimension(n_steps, n_inputs)\n",
    "        batch_size = 1\n",
    "        days = data_train_input.shape[0]\n",
    "        \n",
    "        self.reset_graph()\n",
    "        self.create_model()\n",
    "        my_loss_train_list = []\n",
    "        sess = tf.Session()\n",
    "        # TODO: load from file.\n",
    "\n",
    "        self.init.run(session=sess)\n",
    "        # if this is the first time of fit?\n",
    "        if self.net_states.training_states == None:\n",
    "            init_states = np.zeros((net_attributes.num_layers, 2, 1, net_attributes.n_neurons))\n",
    "        else:\n",
    "            init_states = self.net_states.training_states\n",
    "            \n",
    "        for repeat in range(net_attributes.n_repeats):\n",
    "            rnn_states = copy.deepcopy(init_states)\n",
    "            for seq in range(days):\n",
    "                X_batch, y_batch = self.get_batch(seq, data_train_input, data_train_output)\n",
    "                feed_dict = {\n",
    "                        self.X: X_batch,\n",
    "                        self.y: y_batch,\n",
    "                        self.init_state: rnn_states}\n",
    "                my_op, rnn_states, my_loss_train, my_outputs = sess.run([self.training_op, \n",
    "                          self.new_states, \n",
    "                          self.loss, \n",
    "                          self.outputs], feed_dict=feed_dict)\n",
    "\n",
    "                my_loss_train_list.append(my_loss_train)\n",
    "                # last repeat , remember the sates\n",
    "                if seq+1 == prediction_period and repeat == net_attributes.n_repeats-1:\n",
    "                    # next training loop starts from here\n",
    "                    training_states = copy.deepcopy(rnn_states)\n",
    "                my_loss_train_avg = sum(my_loss_train_list) / len(my_loss_train_list)\n",
    "\n",
    "            print(\"{} repeat={} training finished, training MSE={}\".format(\n",
    "                datetime.datetime.now().time(),\n",
    "                repeat, my_loss_train_avg))\n",
    "        \n",
    "        self.net_states.training_states = training_states\n",
    "        self.net_states.prediction_states = rnn_states\n",
    "        self.sess = sess\n",
    "        return\n",
    "    \n",
    "    def predict_base(self, data_test_input, data_test_output=None):\n",
    "        net_attributes = self.net_attributes\n",
    "        net_states = self.net_states\n",
    "        days = data_test_input.shape[0]\n",
    "        \n",
    "        rnn_states = copy.deepcopy(net_states.prediction_states)\n",
    "        #X, y, init_state, init, training_op, new_states, loss, outputs = self.create_model()\n",
    "        sess = self.sess\n",
    "        \n",
    "        my_loss_test_list = []\n",
    "        input_shape = data_test_input.shape\n",
    "        outputs_all_days = np.zeros((input_shape[0], input_shape[1], 1))\n",
    "        for seq in range(days):\n",
    "            if data_test_output is None:\n",
    "                feed_dict = {\n",
    "                    self.X: data_test_input[seq:seq+1],\n",
    "                    self.init_state: rnn_states,\n",
    "                }\n",
    "\n",
    "                rnn_states, my_outputs = sess.run([self.new_states, self.outputs], feed_dict=feed_dict)\n",
    "            else:\n",
    "                feed_dict = {\n",
    "                    self.X: data_test_input[seq:seq+1],\n",
    "                    self.y: data_test_output[seq:seq+1],\n",
    "                    self.init_state: rnn_states,\n",
    "                }\n",
    "\n",
    "                rnn_states, my_outputs, my_loss_test = sess.run([self.new_states, \n",
    "                                                                 self.outputs, self.loss], feed_dict=feed_dict)\n",
    "                print(\"Predicting day:{} testing MSE: {}\".format(seq, my_loss_test))\n",
    "            outputs_all_days[seq] = my_outputs\n",
    "            \n",
    "        \n",
    "        return outputs_all_days\n",
    "    \n",
    "    def predict(self, data_test_input):\n",
    "        return self.predict_base(data_test_input)\n",
    "        \n",
    "    \n",
    "    def predict_and_verify(self, data_test_input, data_test_output):\n",
    "        return self.predict_base(data_test_input, data_test_output)\n",
    "    \n",
    "    \n",
    "    def get_attributes_filename(self, path):\n",
    "        return path + '/net_attributes.pkl'\n",
    "    \n",
    "    def get_states_filename(self, path, date):\n",
    "        return path + '/net_states.pkl'\n",
    "    \n",
    "    def get_model_filename(self, path, date):\n",
    "        return path + '/tf_session.ckpt'\n",
    "    \n",
    "    def save(self, path, date):\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(self.sess, self.get_model_filename(path))\n",
    "        with open(self.get_attributes_filename(path), 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.net_attributes, f, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.get_states_filename(path), 'wb') as f:\n",
    "            pickle.dump(self.net_states, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"Model saved in path: %s\" % path)\n",
    "        \n",
    "            \n",
    "    def load(self, path, date=None):\n",
    "        # TODO: if date is none, load the latest.\n",
    "        # restore hyper-params\n",
    "        with open(self.get_attributes_filename(path), 'rb') as f:\n",
    "            self.net_attributes = pickle.load(f)\n",
    "\n",
    "        # restore states\n",
    "        with open(self.get_states_filename(path), 'rb') as f:\n",
    "            self.net_states = pickle.load(f)\n",
    "        \n",
    "        # 2. restore graph\n",
    "        if self.model_initialized == False:\n",
    "            self.reset_graph()\n",
    "            self.create_model()\n",
    "        \n",
    "        # 3. restore session\n",
    "        saver = tf.train.Saver()\n",
    "        self.sess = tf.Session()\n",
    "        saver.restore(self.sess, self.get_model_filename(path))\n",
    "        print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFormat:\n",
    "    NONE = 0\n",
    "    DAY = 1\n",
    "    WEEK = 2\n",
    "\n",
    "class DataManipulator:\n",
    "    def __init__(self, beta, ema, time_format, volume_input, use_centralized_bid, \n",
    "                split_daily_data, n_training_days):\n",
    "        self.beta = beta\n",
    "        self.ema = ema\n",
    "        self.time_format = time_format\n",
    "        self.volume_input = volume_input\n",
    "        self.use_centralized_bid = use_centralized_bid\n",
    "        self.split_daily_data = split_daily_data\n",
    "        self.n_training_days = n_training_days\n",
    "        self.scaler_input = None\n",
    "        self.scaler_output = None\n",
    "        \n",
    "    def volume_transform(self, volume_series):\n",
    "        return np.log(volume_series+1)\n",
    "    \n",
    "    def transform(self, data_all, n_inputs, n_outputs):\n",
    "        orig_shape = data_all.shape\n",
    "        data_train_reshape = data_all.reshape((orig_shape[0] * orig_shape[1], orig_shape[2]))\n",
    "        \n",
    "        self.scaler_input = preprocessing.MinMaxScaler().fit(data_train_reshape[:,:n_inputs])\n",
    "        data_train_input_scaled = self.scaler_input.transform(data_train_reshape[:,:n_inputs])\n",
    "        \n",
    "        # the invalid step, we change it to zero!\n",
    "        data_train_input_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "        data_train_input = data_train_input_scaled.reshape(orig_shape[0], orig_shape[1], n_inputs)\n",
    "        \n",
    "        self.scaler_output = preprocessing.MinMaxScaler().fit(data_train_reshape[:,-n_outputs:])\n",
    "        data_train_output_scaled = self.scaler_output.transform(data_train_reshape[:,-n_outputs:])\n",
    "        # the invalid step, we change it to zero!\n",
    "        data_train_output_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "        data_train_output = data_train_output_scaled.reshape(orig_shape[0], orig_shape[1], n_outputs)\n",
    "        \n",
    "        return data_train_input, data_train_output\n",
    "\n",
    "    def prep_training_data(self, input_path):\n",
    "        # load numpy file\n",
    "        npy_file_name = input_path + \"/ema{}_beta{}.npy\".format(self.ema, self.beta)\n",
    "        input_np_data = np.load(npy_file_name)\n",
    "        # check if we have days more than training period\n",
    "        assert(input_np_data.shape[0] >= self.n_training_days)\n",
    "        # the diff is the mandatory\n",
    "        input_columns = [2]\n",
    "        \n",
    "        time_format = self.time_format\n",
    "        \n",
    "        print(\"TimeFormat.DAY\")\n",
    "        print(TimeFormat.DAY)\n",
    "        if time_format == TimeFormat.DAY:\n",
    "            input_columns += [0]\n",
    "        elif time_format == TimeFormat.WEEK:\n",
    "            input_columns += [1]\n",
    "        \n",
    "        if self.volume_input == 1:\n",
    "            input_columns += [3]\n",
    "        \n",
    "        output_columns = [4]\n",
    "        input_np_data = input_np_data[:,:,input_columns + output_columns]\n",
    "        \n",
    "        # we must tranform the volume for it is too big.\n",
    "        if self.volume_input == 1:\n",
    "            input_np_data[:,:,-2] = self.volume_transform(input_np_data[:,:,-2])\n",
    "        \n",
    "        if self.use_centralized_bid == 0:\n",
    "            # remove all the rows for centralized bid. it should be from 9.01 to 17.24, which is 516-12=504 steps\n",
    "            input_np_data = input_np_data[:,7:-5,:]\n",
    "            \n",
    "        shape = input_np_data.shape\n",
    "        n_training_sequences = self.n_training_days\n",
    "        if self.split_daily_data == 1:\n",
    "            assert(shape[1] % 2 == 0)\n",
    "            print(\"split_daily!\")\n",
    "            input_np_data = input_np_data.reshape((shape[0]*2, \n",
    "                                                  int(shape[1]/2), \n",
    "                                                  shape[2]))\n",
    "            n_training_sequences *= 2\n",
    "            \n",
    "        print(\"n_inputs:\")\n",
    "        print(len(input_columns))\n",
    "        return self.transform(input_np_data[:n_training_sequences], len(input_columns), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import GPy\n",
    "import GPyOpt\n",
    "\n",
    "class ValueModel:\n",
    "    mixed_domain = [{'name': 'n_neurons', 'type': 'discrete', 'domain': tuple(range(20,160,20))},\n",
    "          {'name': 'learning_rate', 'type': 'discrete', 'domain': (0.001,0.002,0.003,0.004)},\n",
    "          {'name': 'num_layers', 'type': 'discrete', 'domain': (1,2,3,4)},\n",
    "          {'name': 'rnn_type', 'type': 'discrete', 'domain': (0,1,2)},\n",
    "          {'name': 'learning_period', 'type': 'discrete', 'domain': (10,20)},\n",
    "          {'name': 'prediction_period', 'type': 'discrete', 'domain': (1,2,3,5,6)},\n",
    "          {'name': 'n_repeats', 'type': 'discrete', 'domain': (1,2,3)},\n",
    "          {'name': 'beta', 'type': 'discrete', 'domain': (99, 98)},\n",
    "          {'name': 'ema', 'type': 'discrete', 'domain': (10,20)},\n",
    "          {'name': 'time_format', 'type': 'discrete', 'domain': (0,1,2)}, #1 for stepofday, 2 for stepofweek\n",
    "          {'name': 'volume_input', 'type': 'discrete', 'domain': (0,1)},\n",
    "          {'name': 'use_centralized_bid', 'type': 'discrete', 'domain': (0,1)},\n",
    "          {'name': 'split_daily_data', 'type': 'discrete', 'domain': (0,1)}\n",
    "         ]\n",
    "    \n",
    "    def __init__(self, stock_name, stock_index, n_training_days):\n",
    "        self.stock_name = stock_name\n",
    "        self.stock_index = stock_index\n",
    "        self.n_training_days = n_training_days\n",
    "        self.save_path = \"model_{}_{}\".format(stock_name, n_training_days)\n",
    "        return\n",
    "    \n",
    "    def get_parameter_str(self, X):\n",
    "        parameter_str = \"\"\n",
    "        for i in range(len(self.mixed_domain)):\n",
    "            parameter_str += self.mixed_domain[i][\"name\"]\n",
    "            parameter_str += ':'\n",
    "            parameter_str += str(X[i])\n",
    "            parameter_str += ','\n",
    "        return parameter_str\n",
    "    \n",
    "    def get_max_steps(self, groups):\n",
    "        max_steps = 0\n",
    "        for index, df in groups:\n",
    "            df_len = len(df)\n",
    "            if df_len > max_steps:\n",
    "                max_steps = df_len\n",
    "        return max_steps\n",
    "    \n",
    "    def prep_data(self, input_csv_path):\n",
    "        Path(self.save_path).mkdir(exist_ok=True)\n",
    "        for ema in (10, 20):\n",
    "            for beta in (99, 98):\n",
    "                npy_filename = self.save_path + \"/ema{}_beta{}.npy\".format(ema, beta)\n",
    "                config = Path(npy_filename)\n",
    "                if config.is_file():\n",
    "                    print(\"file: {} exists, ignore...\".format(npy_filename))\n",
    "                    continue\n",
    "                    \n",
    "                input_filename = input_csv_path + \"/data-prep-ema{}-beta{}.csv\".format(ema, beta)\n",
    "                if not Path(input_filename).is_file():\n",
    "                    print(\"cannot find file: {}, aborting...\".format(input_filename))\n",
    "                    return\n",
    "                \n",
    "                print(\"pre-processing {}\".format(input_filename))\n",
    "                data = pd.read_csv(input_filename, parse_dates=[\"timestamp\"])\n",
    "                groups = data.set_index('timestamp').groupby(lambda x: x.date())\n",
    "                n_steps = self.get_max_steps(groups)\n",
    "                np_data = np.zeros((len(groups), n_steps, 5))\n",
    "                index = self.stock_index\n",
    "                column_list = ['step_of_day',\n",
    "                               'step_of_week',\n",
    "                               'diff_ema_{}_{}'.format(ema, index), \n",
    "                               'volume_{}'.format(index),\n",
    "                               'value_ema_{}_beta_{}_{}'.format(ema, beta, index)]\n",
    "                i = 0\n",
    "                for index, df in groups:\n",
    "                    np_data[i] = df[column_list]\n",
    "\n",
    "                    i+=1\n",
    "                np.save(npy_filename, np_data)\n",
    "    \n",
    "    def get_data_prep_desc_filename(self, path):\n",
    "        return path + '/data_prep_desc.pkl'\n",
    "    \n",
    "    def fit(self, input_csv_path, max_iter=300):\n",
    "        self.prep_data(input_csv_path)\n",
    "        self.min_result = 0\n",
    "        print(self.mixed_domain)\n",
    "        opt_handler = GPyOpt.methods.BayesianOptimization(f=self.opt_func,  # Objective function       \n",
    "                                     domain=self.mixed_domain,          # Box-constraints of the problem\n",
    "                                     initial_design_numdata = 20,   # Number data initial design\n",
    "                                     acquisition_type='EI',        # Expected Improvement\n",
    "                                     exact_feval = True)           # True evaluations, no sample noise\n",
    "        opt_handler.run_optimization(max_iter, eps=0)\n",
    "    \n",
    "    def opt_func(self, X_list):\n",
    "        answer = np.zeros((X_list.shape[0], 1))\n",
    "        for i in range(len(X_list)):\n",
    "            print(self.get_parameter_str(X_list[i]))\n",
    "            features = X_list[i]\n",
    "            answer[i][0], results_list = self.get_result(features)\n",
    "            #self.draw_step_profit_graph(self.step_profit_list, \"step_profit_{}\".format(answer[i][0]))\n",
    "            #self.step_profit_list = []\n",
    "            if answer[i][0] < self.min_result:\n",
    "                print(\"find new opt:{}, {}\".format(answer[i][0], self.get_parameter_str(X_list[i])))\n",
    "                self.min_answer = answer[i][0]\n",
    "            else:\n",
    "                print(\"find result:{}, {}\".format(answer[i][0], self.get_parameter_str(X_list[i])))\n",
    "        return answer\n",
    "\n",
    "    def sma(self, data, window):\n",
    "        \"\"\"\n",
    "        Calculates Simple Moving Average\n",
    "        http://fxtrade.oanda.com/learn/forex-indicators/simple-moving-average\n",
    "        \"\"\"\n",
    "        if len(data) < window:\n",
    "            return None\n",
    "        return sum(data[-window:]) / float(window)\n",
    "    \n",
    "    def ema(self, data, window):\n",
    "        if len(data) < 2 * window:\n",
    "            raise ValueError(\"data is too short\")\n",
    "        c = 2.0 / (window + 1)\n",
    "        current_ema = self.sma(data[-window*2:-window], window)\n",
    "        for value in data[-window:]:\n",
    "            current_ema = (c * value) + ((1 - c) * current_ema)\n",
    "        return current_ema\n",
    "    \n",
    "    \n",
    "    def get_result(self, features):\n",
    "        n_neurons = int(features[0])\n",
    "        learning_rate = features[1]\n",
    "        num_layers = int(features[2])\n",
    "        rnn_type = int(features[3])\n",
    "        learning_period = int(features[4])\n",
    "        prediction_period = int(features[5])\n",
    "        n_repeats = int(features[6])\n",
    "        beta = int(features[7])\n",
    "        ema = int(features[8])\n",
    "        time_format = int(features[9])\n",
    "        volume_input = int(features[10])\n",
    "        use_centralized_bid = int(features[11])\n",
    "        split_daily_data = int(features[12])\n",
    "        \n",
    "        data_manipulator = DataManipulator(beta, ema, \n",
    "                                           time_format, \n",
    "                                           volume_input, \n",
    "                                           use_centralized_bid, \n",
    "                                           split_daily_data, \n",
    "                                           self.n_training_days)\n",
    "        \n",
    "        data_training_input, data_training_output = data_manipulator.prep_training_data(self.save_path)\n",
    "        print(\"data_training_input.shape\")\n",
    "        print(data_training_input.shape)\n",
    "        print(data_training_output.shape)\n",
    "        \n",
    "        # now define the network\n",
    "        model = StatefulLstmModel(n_neurons, learning_rate, num_layers, rnn_type, n_repeats)\n",
    "        \n",
    "        assert(self.n_training_days % prediction_period == 0)\n",
    "        \n",
    "        n_training_seq = self.n_training_days\n",
    "        n_learning_seq = learning_period\n",
    "        n_prediction_seq = prediction_period\n",
    "        if split_daily_data == 1:\n",
    "            n_training_seq *= 2\n",
    "            n_learning_seq *= 2\n",
    "            n_prediction_seq *= 2\n",
    "        \n",
    "        daily_errors = []\n",
    "        \n",
    "        print(\"start training: training_seq:{}, learning_seq:{}, prediction_seq:{}\".format(n_training_seq, \n",
    "                                                                                           n_learning_seq, \n",
    "                                                                                           n_prediction_seq))\n",
    "        for i in range(0, n_training_seq-n_prediction_seq-n_learning_seq+1, prediction_period):\n",
    "            learning_end = i + n_learning_seq\n",
    "            print(\"start training from day:{} - day:{}\".format(i, learning_end-1))\n",
    "            model.fit(data_training_input[i:learning_end], data_training_output[:learning_end], n_prediction_seq)\n",
    "            prediction_end = learning_end + n_prediction_seq\n",
    "            print(\"start predicting from day:{} - day:{}\".format(learning_end, prediction_end))\n",
    "            outputs = model.predict_and_verify(data_training_input[learning_end:prediction_end], \n",
    "                                     data_training_output[learning_end:prediction_end])\n",
    "            \n",
    "            # calculate the error for every day\n",
    "            y = data_training_output[learning_end:prediction_end]\n",
    "            # error is a 1-D array for the every day error\n",
    "            error = np.mean(np.square(outputs-y), axis=(1,2))\n",
    "            print(\"The prediction error is: {}\".format(error))\n",
    "            daily_errors += error.tolist()\n",
    "            \n",
    "        print(\"finished\")\n",
    "        print(daily_errors)\n",
    "        ema = self.ema(daily_errors, int(len(daily_errors)/2))\n",
    "        print(ema)\n",
    "       \n",
    "        return ema, []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: model_Nordea_30/ema10_beta99.npy exists, ignore...\n",
      "file: model_Nordea_30/ema10_beta98.npy exists, ignore...\n",
      "file: model_Nordea_30/ema20_beta99.npy exists, ignore...\n",
      "file: model_Nordea_30/ema20_beta98.npy exists, ignore...\n",
      "[{'name': 'n_neurons', 'type': 'discrete', 'domain': (20, 40, 60, 80, 100, 120, 140)}, {'name': 'learning_rate', 'type': 'discrete', 'domain': (0.001, 0.002, 0.003, 0.004)}, {'name': 'num_layers', 'type': 'discrete', 'domain': (1, 2, 3, 4)}, {'name': 'rnn_type', 'type': 'discrete', 'domain': (0, 1, 2)}, {'name': 'learning_period', 'type': 'discrete', 'domain': (10, 20)}, {'name': 'prediction_period', 'type': 'discrete', 'domain': (1, 2, 3, 5, 6)}, {'name': 'n_repeats', 'type': 'discrete', 'domain': (1, 2, 3)}, {'name': 'beta', 'type': 'discrete', 'domain': (99, 98)}, {'name': 'ema', 'type': 'discrete', 'domain': (10, 20)}, {'name': 'time_format', 'type': 'discrete', 'domain': (0, 1, 2)}, {'name': 'volume_input', 'type': 'discrete', 'domain': (0, 1)}, {'name': 'use_centralized_bid', 'type': 'discrete', 'domain': (0, 1)}, {'name': 'split_daily_data', 'type': 'discrete', 'domain': (0, 1)}]\n",
      "n_neurons:140.0,learning_rate:0.002,num_layers:4.0,rnn_type:1.0,learning_period:20.0,prediction_period:5.0,n_repeats:3.0,beta:98.0,ema:10.0,time_format:2.0,volume_input:0.0,use_centralized_bid:1.0,split_daily_data:0.0,\n",
      "TimeFormat.DAY\n",
      "1\n",
      "n_inputs:\n",
      "2\n",
      "data_training_input.shape\n",
      "(30, 516, 2)\n",
      "(30, 516, 1)\n",
      "start training: training_seq:30, learning_seq:20, prediction_seq:5\n",
      "start training from day:0 - day:19\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec588>\n",
      "12:37:12.184656 repeat=0 training finished, training MSE=0.5595343426917679\n",
      "12:37:21.465889 repeat=1 training finished, training MSE=0.2882209294504719\n",
      "12:37:30.155979 repeat=2 training finished, training MSE=0.1930632467827915\n",
      "start predicting from day:20 - day:25\n",
      "Predicting day:0 testing MSE: 0.0011884048581123352\n",
      "Predicting day:1 testing MSE: 0.0015342856058850884\n",
      "Predicting day:2 testing MSE: 0.0015762154944241047\n",
      "Predicting day:3 testing MSE: 0.0010457038879394531\n",
      "Predicting day:4 testing MSE: 0.0007646779995411634\n",
      "The prediction error is: [0.0011884  0.00153429 0.00157622 0.0010457  0.00076468]\n",
      "start training from day:5 - day:24\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec588>\n",
      "12:37:40.194590 repeat=0 training finished, training MSE=0.5553459284827114\n",
      "12:37:49.141193 repeat=1 training finished, training MSE=0.2889035285566933\n",
      "12:37:57.727877 repeat=2 training finished, training MSE=0.19358307236883168\n",
      "start predicting from day:25 - day:30\n",
      "Predicting day:0 testing MSE: 0.018811367452144623\n",
      "Predicting day:1 testing MSE: 0.003057420952245593\n",
      "Predicting day:2 testing MSE: 0.0012613823637366295\n",
      "Predicting day:3 testing MSE: 0.0017046837601810694\n",
      "Predicting day:4 testing MSE: 0.0010641850531101227\n",
      "The prediction error is: [0.01881137 0.00305742 0.00126138 0.00170468 0.00106418]\n",
      "finished\n",
      "[0.0011884047849730585, 0.0015342855262212261, 0.0015762155064122428, 0.001045703933154354, 0.0007646778882278543, 0.018811368799297366, 0.003057421079216454, 0.001261382244156352, 0.0017046838148662487, 0.001064184993122836]\n",
      "0.0026218976082915085\n",
      "find result:0.0, n_neurons:140.0,learning_rate:0.002,num_layers:4.0,rnn_type:1.0,learning_period:20.0,prediction_period:5.0,n_repeats:3.0,beta:98.0,ema:10.0,time_format:2.0,volume_input:0.0,use_centralized_bid:1.0,split_daily_data:0.0,\n",
      "n_neurons:80.0,learning_rate:0.002,num_layers:4.0,rnn_type:0.0,learning_period:20.0,prediction_period:1.0,n_repeats:3.0,beta:99.0,ema:10.0,time_format:2.0,volume_input:1.0,use_centralized_bid:0.0,split_daily_data:1.0,\n",
      "TimeFormat.DAY\n",
      "1\n",
      "split_daily!\n",
      "n_inputs:\n",
      "3\n",
      "data_training_input.shape\n",
      "(60, 252, 3)\n",
      "(60, 252, 1)\n",
      "start training: training_seq:60, learning_seq:40, prediction_seq:2\n",
      "start training from day:0 - day:39\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:38:02.253382 repeat=0 training finished, training MSE=0.028397558681899682\n",
      "12:38:05.378884 repeat=1 training finished, training MSE=0.015568964608246461\n",
      "12:38:08.478362 repeat=2 training finished, training MSE=0.010928528926645717\n",
      "start predicting from day:40 - day:42\n",
      "Predicting day:0 testing MSE: 0.0007519272621721029\n",
      "Predicting day:1 testing MSE: 0.0002980028511956334\n",
      "The prediction error is: [0.00075193 0.000298  ]\n",
      "start training from day:1 - day:40\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:38:12.766782 repeat=0 training finished, training MSE=0.05226160208694637\n",
      "12:38:15.855379 repeat=1 training finished, training MSE=0.02698872333385225\n",
      "12:38:19.099993 repeat=2 training finished, training MSE=0.0183867003795361\n",
      "start predicting from day:41 - day:43\n",
      "Predicting day:0 testing MSE: 0.0006975175347179174\n",
      "Predicting day:1 testing MSE: 0.0014803980011492968\n",
      "The prediction error is: [0.00069752 0.0014804 ]\n",
      "start training from day:2 - day:41\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:38:23.539171 repeat=0 training finished, training MSE=0.0528502953624411\n",
      "12:38:26.569541 repeat=1 training finished, training MSE=0.027157818039268023\n",
      "12:38:29.837847 repeat=2 training finished, training MSE=0.01849923622661057\n",
      "start predicting from day:42 - day:44\n",
      "Predicting day:0 testing MSE: 0.0014975093072280288\n",
      "Predicting day:1 testing MSE: 0.0011734209256246686\n",
      "The prediction error is: [0.00149751 0.00117342]\n",
      "start training from day:3 - day:42\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:38:33.977573 repeat=0 training finished, training MSE=0.0528829436043452\n",
      "12:38:37.053678 repeat=1 training finished, training MSE=0.027099553093285066\n",
      "12:38:40.137389 repeat=2 training finished, training MSE=0.01845747977216282\n",
      "start predicting from day:43 - day:45\n",
      "Predicting day:0 testing MSE: 0.0011992118088528514\n",
      "Predicting day:1 testing MSE: 0.0024049102794378996\n",
      "The prediction error is: [0.00119921 0.00240491]\n",
      "start training from day:4 - day:43\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:38:44.485283 repeat=0 training finished, training MSE=0.053977622498496206\n",
      "12:38:47.702399 repeat=1 training finished, training MSE=0.027677900746675733\n",
      "12:38:51.375671 repeat=2 training finished, training MSE=0.01885209989862536\n",
      "start predicting from day:44 - day:46\n",
      "Predicting day:0 testing MSE: 0.002390753012150526\n",
      "Predicting day:1 testing MSE: 0.0013079626951366663\n",
      "The prediction error is: [0.00239075 0.00130796]\n",
      "start training from day:5 - day:44\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:39:02.473915 repeat=0 training finished, training MSE=0.05613634528563125\n",
      "12:39:05.475487 repeat=1 training finished, training MSE=0.028775162691636068\n",
      "12:39:08.441783 repeat=2 training finished, training MSE=0.01958269605602254\n",
      "start predicting from day:45 - day:47\n",
      "Predicting day:0 testing MSE: 0.0013595556374639273\n",
      "Predicting day:1 testing MSE: 0.00123446190264076\n",
      "The prediction error is: [0.00135956 0.00123446]\n",
      "start training from day:6 - day:45\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:39:12.669504 repeat=0 training finished, training MSE=0.056363808653259184\n",
      "12:39:15.615949 repeat=1 training finished, training MSE=0.028888164284580853\n",
      "12:39:18.780184 repeat=2 training finished, training MSE=0.01966076700737176\n",
      "start predicting from day:46 - day:48\n",
      "Predicting day:0 testing MSE: 0.001282906043343246\n",
      "Predicting day:1 testing MSE: 0.0016729324124753475\n",
      "The prediction error is: [0.00128291 0.00167293]\n",
      "start training from day:7 - day:46\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:39:23.076295 repeat=0 training finished, training MSE=0.04596040848118719\n",
      "12:39:26.221923 repeat=1 training finished, training MSE=0.023637871879691373\n",
      "12:39:29.256297 repeat=2 training finished, training MSE=0.016188141718885163\n",
      "start predicting from day:47 - day:49\n",
      "Predicting day:0 testing MSE: 0.0020258028525859118\n",
      "Predicting day:1 testing MSE: 0.001490205293521285\n",
      "The prediction error is: [0.0020258  0.00149021]\n",
      "start training from day:8 - day:47\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:39:40.531125 repeat=0 training finished, training MSE=0.03986651154991705\n",
      "12:39:43.530379 repeat=1 training finished, training MSE=0.02093268428998272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:39:46.547239 repeat=2 training finished, training MSE=0.014365676915743582\n",
      "start predicting from day:48 - day:50\n",
      "Predicting day:0 testing MSE: 0.0012482479214668274\n",
      "Predicting day:1 testing MSE: 0.0013432762352749705\n",
      "The prediction error is: [0.00124825 0.00134328]\n",
      "start training from day:9 - day:48\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:39:50.787112 repeat=0 training finished, training MSE=0.03510788586863782\n",
      "12:39:54.235473 repeat=1 training finished, training MSE=0.018160416282626102\n",
      "12:39:57.441149 repeat=2 training finished, training MSE=0.012670128164124132\n",
      "start predicting from day:49 - day:51\n",
      "Predicting day:0 testing MSE: 0.0013392241671681404\n",
      "Predicting day:1 testing MSE: 0.02197883464396\n",
      "The prediction error is: [0.00133922 0.02197883]\n",
      "start training from day:10 - day:49\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:40:01.591103 repeat=0 training finished, training MSE=0.039941501469002105\n",
      "12:40:04.609148 repeat=1 training finished, training MSE=0.020645913285625282\n",
      "12:40:07.728329 repeat=2 training finished, training MSE=0.014180697080640433\n",
      "start predicting from day:50 - day:52\n",
      "Predicting day:0 testing MSE: 0.02135160006582737\n",
      "Predicting day:1 testing MSE: 0.0064145224168896675\n",
      "The prediction error is: [0.0213516  0.00641452]\n",
      "start training from day:11 - day:50\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:40:12.139541 repeat=0 training finished, training MSE=0.04967450959957205\n",
      "12:40:15.262585 repeat=1 training finished, training MSE=0.025753051910942303\n",
      "12:40:18.496322 repeat=2 training finished, training MSE=0.017570850245344143\n",
      "start predicting from day:51 - day:53\n",
      "Predicting day:0 testing MSE: 0.006759093143045902\n",
      "Predicting day:1 testing MSE: 0.0015078609576448798\n",
      "The prediction error is: [0.00675909 0.00150786]\n",
      "start training from day:12 - day:51\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:40:24.062328 repeat=0 training finished, training MSE=0.05470358388083696\n",
      "12:40:27.484699 repeat=1 training finished, training MSE=0.028053797962638783\n",
      "12:40:30.740449 repeat=2 training finished, training MSE=0.019098244479027925\n",
      "start predicting from day:52 - day:54\n",
      "Predicting day:0 testing MSE: 0.0015610380796715617\n",
      "Predicting day:1 testing MSE: 0.001304814824834466\n",
      "The prediction error is: [0.00156104 0.00130481]\n",
      "start training from day:13 - day:52\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:40:35.760627 repeat=0 training finished, training MSE=0.05303950548550347\n",
      "12:40:39.490451 repeat=1 training finished, training MSE=0.027143913167856228\n",
      "12:40:43.069910 repeat=2 training finished, training MSE=0.018490975050857134\n",
      "start predicting from day:53 - day:55\n",
      "Predicting day:0 testing MSE: 0.0013332176022231579\n",
      "Predicting day:1 testing MSE: 0.000619731901679188\n",
      "The prediction error is: [0.00133322 0.00061973]\n",
      "start training from day:14 - day:53\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:40:47.883733 repeat=0 training finished, training MSE=0.05329658934424515\n",
      "12:40:50.948425 repeat=1 training finished, training MSE=0.02730005474095378\n",
      "12:40:54.162161 repeat=2 training finished, training MSE=0.018601945928336742\n",
      "start predicting from day:54 - day:56\n",
      "Predicting day:0 testing MSE: 0.0006058376748114824\n",
      "Predicting day:1 testing MSE: 0.0010316642001271248\n",
      "The prediction error is: [0.00060584 0.00103166]\n",
      "start training from day:15 - day:54\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:40:59.236747 repeat=0 training finished, training MSE=0.058100412930798484\n",
      "12:41:02.549189 repeat=1 training finished, training MSE=0.029734709642616507\n",
      "12:41:05.946172 repeat=2 training finished, training MSE=0.02022179944591092\n",
      "start predicting from day:55 - day:57\n",
      "Predicting day:0 testing MSE: 0.001048132311552763\n",
      "Predicting day:1 testing MSE: 0.0011605140753090382\n",
      "The prediction error is: [0.00104813 0.00116051]\n",
      "start training from day:16 - day:55\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:41:11.038089 repeat=0 training finished, training MSE=0.05828483004370355\n",
      "12:41:21.673120 repeat=1 training finished, training MSE=0.029823695017148565\n",
      "12:41:24.719180 repeat=2 training finished, training MSE=0.02028395137725359\n",
      "start predicting from day:56 - day:58\n",
      "Predicting day:0 testing MSE: 0.0011840439401566982\n",
      "Predicting day:1 testing MSE: 0.002421426819637418\n",
      "The prediction error is: [0.00118404 0.00242143]\n",
      "start training from day:17 - day:56\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:41:29.236677 repeat=0 training finished, training MSE=0.046750047852401624\n",
      "12:41:32.350174 repeat=1 training finished, training MSE=0.024023756860515277\n",
      "12:41:35.430215 repeat=2 training finished, training MSE=0.0164395084479717\n",
      "start predicting from day:57 - day:59\n",
      "Predicting day:0 testing MSE: 0.0026078529190272093\n",
      "Predicting day:1 testing MSE: 0.001574649941176176\n",
      "The prediction error is: [0.00260785 0.00157465]\n",
      "start training from day:18 - day:57\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91fdec9b0>\n",
      "12:41:39.702194 repeat=0 training finished, training MSE=0.03958020959107671\n",
      "12:41:42.866721 repeat=1 training finished, training MSE=0.020747841886077367\n",
      "12:41:46.018169 repeat=2 training finished, training MSE=0.014244356548442739\n",
      "start predicting from day:58 - day:60\n",
      "Predicting day:0 testing MSE: 0.0012602097121998668\n",
      "Predicting day:1 testing MSE: 0.0012491731904447079\n",
      "The prediction error is: [0.00126021 0.00124917]\n",
      "finished\n",
      "[0.0007519271339554202, 0.00029800289312231776, 0.0006975176058328605, 0.0014803978416204015, 0.001497509420417579, 0.0011734208440820303, 0.0011992118335677354, 0.00240491030973928, 0.002390753117681545, 0.0013079624451516052, 0.001359555574844067, 0.0012344620921553645, 0.0012829061393589865, 0.001672932419464511, 0.0020258029949366953, 0.0014902052741790526, 0.0012482479736186213, 0.0013432764662666711, 0.0013392242262834685, 0.021978834148056885, 0.021351598300330857, 0.006414522758322481, 0.0067590934118237, 0.001507861101642906, 0.001561038233897761, 0.001304814777491819, 0.0013332175507331807, 0.0006197318588112009, 0.0006058376471180526, 0.0010316641525287245, 0.001048132291914972, 0.001160514104094869, 0.0011840438171074074, 0.002421426904690015, 0.0026078527338956395, 0.001574649991348394, 0.0012602099479479835, 0.0012491731341470465]\n",
      "0.002269205924119578\n",
      "find result:0.0, n_neurons:80.0,learning_rate:0.002,num_layers:4.0,rnn_type:0.0,learning_period:20.0,prediction_period:1.0,n_repeats:3.0,beta:99.0,ema:10.0,time_format:2.0,volume_input:1.0,use_centralized_bid:0.0,split_daily_data:1.0,\n",
      "n_neurons:100.0,learning_rate:0.002,num_layers:3.0,rnn_type:1.0,learning_period:20.0,prediction_period:6.0,n_repeats:3.0,beta:99.0,ema:10.0,time_format:0.0,volume_input:1.0,use_centralized_bid:0.0,split_daily_data:1.0,\n",
      "TimeFormat.DAY\n",
      "1\n",
      "split_daily!\n",
      "n_inputs:\n",
      "2\n",
      "data_training_input.shape\n",
      "(60, 252, 2)\n",
      "(60, 252, 1)\n",
      "start training: training_seq:60, learning_seq:40, prediction_seq:12\n",
      "start training from day:0 - day:39\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91e14bcc0>\n",
      "12:41:50.397473 repeat=0 training finished, training MSE=0.03327123553899582\n",
      "12:41:53.642694 repeat=1 training finished, training MSE=0.01748383482117788\n",
      "12:41:56.967600 repeat=2 training finished, training MSE=0.012162476251493597\n",
      "start predicting from day:40 - day:52\n",
      "Predicting day:0 testing MSE: 0.0014694439014419913\n",
      "Predicting day:1 testing MSE: 0.0009490977390669286\n",
      "Predicting day:2 testing MSE: 0.0016215067589655519\n",
      "Predicting day:3 testing MSE: 0.0014247674262151122\n",
      "Predicting day:4 testing MSE: 0.0026140545960515738\n",
      "Predicting day:5 testing MSE: 0.0014431651216000319\n",
      "Predicting day:6 testing MSE: 0.0014505040599033237\n",
      "Predicting day:7 testing MSE: 0.0018544425256550312\n",
      "Predicting day:8 testing MSE: 0.0013507477706298232\n",
      "Predicting day:9 testing MSE: 0.0013492655707523227\n",
      "Predicting day:10 testing MSE: 0.019268423318862915\n",
      "Predicting day:11 testing MSE: 0.006413782946765423\n",
      "The prediction error is: [0.00146944 0.0009491  0.00162151 0.00142477 0.00261405 0.00144317\n",
      " 0.0014505  0.00185444 0.00135075 0.00134927 0.01926842 0.00641378]\n",
      "start training from day:6 - day:45\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa91e14bcc0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:42:02.140571 repeat=0 training finished, training MSE=0.03434453340232722\n",
      "12:42:05.743170 repeat=1 training finished, training MSE=0.017923059529493912\n",
      "12:42:09.083570 repeat=2 training finished, training MSE=0.012457007540312285\n",
      "start predicting from day:46 - day:58\n",
      "Predicting day:0 testing MSE: 0.0010918335756286979\n",
      "Predicting day:1 testing MSE: 0.0010941672371700406\n",
      "Predicting day:2 testing MSE: 0.0007888751570135355\n",
      "Predicting day:3 testing MSE: 0.0008057831437326968\n",
      "Predicting day:4 testing MSE: 0.01960388943552971\n",
      "Predicting day:5 testing MSE: 0.0062289112247526646\n",
      "Predicting day:6 testing MSE: 0.0009428272023797035\n",
      "Predicting day:7 testing MSE: 0.0007605247665196657\n",
      "Predicting day:8 testing MSE: 0.0003801152342930436\n",
      "Predicting day:9 testing MSE: 0.0008257267181761563\n",
      "Predicting day:10 testing MSE: 0.000928998866584152\n",
      "Predicting day:11 testing MSE: 0.002030081581324339\n",
      "The prediction error is: [0.00109183 0.00109417 0.00078888 0.00080578 0.01960389 0.00622891\n",
      " 0.00094283 0.00076052 0.00038012 0.00082573 0.000929   0.00203008]\n",
      "finished\n",
      "[0.0014694438194664432, 0.00094909781780327, 0.0016215065470228114, 0.0014247673095666691, 0.0026140545375303837, 0.0014431650093496117, 0.0014505041749548672, 0.0018544426813348182, 0.0013507479675764014, 0.0013492655770991752, 0.01926842144529052, 0.006413782960011533, 0.0010918337430258522, 0.0010941671921783677, 0.0007888751632660685, 0.0008057831771446087, 0.019603889420092724, 0.00622891133749057, 0.0009428273828627655, 0.0007605245715008761, 0.000380115233558336, 0.0008257266482937444, 0.0009289988278767499, 0.002030081327468868]\n",
      "0.00255146803218911\n",
      "find result:0.0, n_neurons:100.0,learning_rate:0.002,num_layers:3.0,rnn_type:1.0,learning_period:20.0,prediction_period:6.0,n_repeats:3.0,beta:99.0,ema:10.0,time_format:0.0,volume_input:1.0,use_centralized_bid:0.0,split_daily_data:1.0,\n",
      "n_neurons:140.0,learning_rate:0.004,num_layers:2.0,rnn_type:1.0,learning_period:20.0,prediction_period:6.0,n_repeats:1.0,beta:98.0,ema:10.0,time_format:2.0,volume_input:0.0,use_centralized_bid:1.0,split_daily_data:1.0,\n",
      "TimeFormat.DAY\n",
      "1\n",
      "split_daily!\n",
      "n_inputs:\n",
      "2\n",
      "data_training_input.shape\n",
      "(60, 258, 2)\n",
      "(60, 258, 1)\n",
      "start training: training_seq:60, learning_seq:40, prediction_seq:12\n",
      "start training from day:0 - day:39\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa94068f710>\n",
      "12:42:14.442193 repeat=0 training finished, training MSE=0.04487990199268097\n",
      "start predicting from day:40 - day:52\n",
      "Predicting day:0 testing MSE: 0.003935940098017454\n",
      "Predicting day:1 testing MSE: 0.003099121619015932\n",
      "Predicting day:2 testing MSE: 0.003680897643789649\n",
      "Predicting day:3 testing MSE: 0.0018909623613581061\n",
      "Predicting day:4 testing MSE: 0.0012530704261735082\n",
      "Predicting day:5 testing MSE: 0.001184379681944847\n",
      "Predicting day:6 testing MSE: 0.0018547086510807276\n",
      "Predicting day:7 testing MSE: 0.0005927960737608373\n",
      "Predicting day:8 testing MSE: 0.0008603169117122889\n",
      "Predicting day:9 testing MSE: 0.0005510445334948599\n",
      "Predicting day:10 testing MSE: 0.020935622975230217\n",
      "Predicting day:11 testing MSE: 0.007336373440921307\n",
      "The prediction error is: [0.00393594 0.00309912 0.0036809  0.00189096 0.00125307 0.00118438\n",
      " 0.00185471 0.0005928  0.00086032 0.00055104 0.02093562 0.00733637]\n",
      "start training from day:6 - day:45\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa94068f710>\n",
      "12:42:20.270837 repeat=0 training finished, training MSE=0.06629670639231336\n",
      "start predicting from day:46 - day:58\n",
      "Predicting day:0 testing MSE: 0.0013861641054973006\n",
      "Predicting day:1 testing MSE: 0.0008462703553959727\n",
      "Predicting day:2 testing MSE: 0.0017374245217069983\n",
      "Predicting day:3 testing MSE: 0.0023868116550147533\n",
      "Predicting day:4 testing MSE: 0.02204987034201622\n",
      "Predicting day:5 testing MSE: 0.006240996066480875\n",
      "Predicting day:6 testing MSE: 0.002709974767640233\n",
      "Predicting day:7 testing MSE: 0.000801011745352298\n",
      "Predicting day:8 testing MSE: 0.0002971574431285262\n",
      "Predicting day:9 testing MSE: 0.0007889462285675108\n",
      "Predicting day:10 testing MSE: 0.0007806587382219732\n",
      "Predicting day:11 testing MSE: 0.002040149411186576\n",
      "The prediction error is: [0.00138616 0.00084627 0.00173742 0.00238681 0.02204987 0.006241\n",
      " 0.00270997 0.00080101 0.00029716 0.00078895 0.00078066 0.00204015]\n",
      "finished\n",
      "[0.003935940147323815, 0.0030991218054601567, 0.003680897714246204, 0.0018909625922858794, 0.0012530703560968276, 0.001184379516560041, 0.0018547085440684342, 0.0005927960499987836, 0.0008603168594643651, 0.0005510444782458415, 0.02093562308471343, 0.007336373851664534, 0.001386164036510441, 0.0008462702500303692, 0.0017374245664713267, 0.0023868116867435366, 0.02204986779046262, 0.006240996658099667, 0.002709974735050506, 0.0008010118114845443, 0.00029715746410385673, 0.0007889461386276149, 0.0007806589350508528, 0.002040149673492343]\n",
      "0.002923960346728193\n",
      "find result:0.0, n_neurons:140.0,learning_rate:0.004,num_layers:2.0,rnn_type:1.0,learning_period:20.0,prediction_period:6.0,n_repeats:1.0,beta:98.0,ema:10.0,time_format:2.0,volume_input:0.0,use_centralized_bid:1.0,split_daily_data:1.0,\n",
      "n_neurons:60.0,learning_rate:0.004,num_layers:2.0,rnn_type:1.0,learning_period:10.0,prediction_period:2.0,n_repeats:3.0,beta:98.0,ema:10.0,time_format:2.0,volume_input:1.0,use_centralized_bid:0.0,split_daily_data:1.0,\n",
      "TimeFormat.DAY\n",
      "1\n",
      "split_daily!\n",
      "n_inputs:\n",
      "3\n",
      "data_training_input.shape\n",
      "(60, 252, 3)\n",
      "(60, 252, 1)\n",
      "start training: training_seq:60, learning_seq:20, prediction_seq:4\n",
      "start training from day:0 - day:19\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa9761a7cc0>\n",
      "12:42:22.158352 repeat=0 training finished, training MSE=0.050565129438473376\n",
      "12:42:22.965034 repeat=1 training finished, training MSE=0.032062526921072275\n",
      "12:42:23.797610 repeat=2 training finished, training MSE=0.022516810665547383\n",
      "start predicting from day:20 - day:24\n",
      "Predicting day:0 testing MSE: 0.002521890215575695\n",
      "Predicting day:1 testing MSE: 0.0017757948953658342\n",
      "Predicting day:2 testing MSE: 0.0034897339064627886\n",
      "Predicting day:3 testing MSE: 0.003005768870934844\n",
      "The prediction error is: [0.00252189 0.00177579 0.00348973 0.00300577]\n",
      "start training from day:2 - day:21\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa9761a7cc0>\n",
      "12:42:25.600677 repeat=0 training finished, training MSE=0.06803331261617132\n",
      "12:42:26.455017 repeat=1 training finished, training MSE=0.03864803196847788\n",
      "12:42:27.350480 repeat=2 training finished, training MSE=0.026245322284133486\n",
      "start predicting from day:22 - day:26\n",
      "Predicting day:0 testing MSE: 0.0005166429909877479\n",
      "Predicting day:1 testing MSE: 0.00033247514511458576\n",
      "Predicting day:2 testing MSE: 0.0006957745063118637\n",
      "Predicting day:3 testing MSE: 0.00031940682674758136\n",
      "The prediction error is: [0.00051664 0.00033248 0.00069577 0.00031941]\n",
      "start training from day:4 - day:23\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa9761a7cc0>\n",
      "12:42:29.083015 repeat=0 training finished, training MSE=0.06609543618396856\n",
      "12:42:29.961427 repeat=1 training finished, training MSE=0.03532460499700392\n",
      "12:42:30.779715 repeat=2 training finished, training MSE=0.024070215108804405\n",
      "start predicting from day:24 - day:28\n",
      "Predicting day:0 testing MSE: 0.00045750997378490865\n",
      "Predicting day:1 testing MSE: 0.0004921338986605406\n",
      "Predicting day:2 testing MSE: 0.0005655285203829408\n",
      "Predicting day:3 testing MSE: 0.00030127359787002206\n",
      "The prediction error is: [0.00045751 0.00049213 0.00056553 0.00030127]\n",
      "start training from day:6 - day:25\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa9761a7cc0>\n",
      "12:42:32.428702 repeat=0 training finished, training MSE=0.060594981696340255\n",
      "12:42:33.342294 repeat=1 training finished, training MSE=0.03163628743350273\n",
      "12:42:34.170184 repeat=2 training finished, training MSE=0.021853072249602215\n",
      "start predicting from day:26 - day:30\n",
      "Predicting day:0 testing MSE: 0.0013102833181619644\n",
      "Predicting day:1 testing MSE: 0.0012665429385378957\n",
      "Predicting day:2 testing MSE: 0.001851731212809682\n",
      "Predicting day:3 testing MSE: 0.0014740186743438244\n",
      "The prediction error is: [0.00131028 0.00126654 0.00185173 0.00147402]\n",
      "start training from day:8 - day:27\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa9761a7cc0>\n",
      "12:42:36.459765 repeat=0 training finished, training MSE=0.11051885675406084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:42:37.402921 repeat=1 training finished, training MSE=0.07129393513023388\n",
      "12:42:38.320855 repeat=2 training finished, training MSE=0.04940074855306496\n",
      "start predicting from day:28 - day:32\n",
      "Predicting day:0 testing MSE: 0.006604355294257402\n",
      "Predicting day:1 testing MSE: 0.006304363254457712\n",
      "Predicting day:2 testing MSE: 0.001741852262057364\n",
      "Predicting day:3 testing MSE: 0.0011977459071204066\n",
      "The prediction error is: [0.00660436 0.00630436 0.00174185 0.00119775]\n",
      "start training from day:10 - day:29\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa9761a7cc0>\n",
      "12:42:40.073078 repeat=0 training finished, training MSE=0.04666938913869671\n",
      "12:42:40.937535 repeat=1 training finished, training MSE=0.024560829065740107\n",
      "12:42:41.809643 repeat=2 training finished, training MSE=0.01708407151066543\n",
      "start predicting from day:30 - day:34\n",
      "Predicting day:0 testing MSE: 0.0014694237615913153\n",
      "Predicting day:1 testing MSE: 0.0009797598468139768\n",
      "Predicting day:2 testing MSE: 0.0015553911216557026\n",
      "Predicting day:3 testing MSE: 0.0008262062328867614\n",
      "The prediction error is: [0.00146942 0.00097976 0.00155539 0.00082621]\n",
      "start training from day:12 - day:31\n",
      "net_attributes\n",
      "<__main__.NetAttributes object at 0x7fa9761a7cc0>\n",
      "12:42:43.568509 repeat=0 training finished, training MSE=0.05714992341818288\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-81ed7b2ddd9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvalue_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValueModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Nordea'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalue_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-13fc29921268>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, input_csv_path, max_iter)\u001b[0m\n\u001b[1;32m     89\u001b[0m                                      \u001b[0minitial_design_numdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# Number data initial design\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                                      \u001b[0macquisition_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m# Expected Improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                                      exact_feval = True)           # True evaluations, no sample noise\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mopt_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/methods/bayesian_optimization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, domain, constraints, cost_withGradients, model_type, X, Y, initial_design_numdata, initial_design_type, acquisition_type, normalize_Y, exact_feval, acquisition_optimizer_type, model_update_interval, evaluator_type, batch_size, num_cores, verbosity, verbosity_model, maximize, de_duplication, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_type\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minitial_design_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_numdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_design_numdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_design_chooser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# --- CHOOSE the model type. If an instance of a GPyOpt model is passed (possibly user defined), it is used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/methods/bayesian_optimization.py\u001b[0m in \u001b[0;36m_init_design_chooser\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_design\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_numdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;31m# Case 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/core/task/objective.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_procs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/core/task/objective.py\u001b[0m in \u001b[0;36m_eval_func\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mst_time\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mrlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mf_evals\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrlt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mcost_evals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-13fc29921268>\u001b[0m in \u001b[0;36mopt_func\u001b[0;34m(self, X_list)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameter_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;31m#self.draw_step_profit_graph(self.step_profit_list, \"step_profit_{}\".format(answer[i][0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;31m#self.step_profit_list = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-13fc29921268>\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mlearning_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_learning_seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start training from day:{} - day:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_end\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_training_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlearning_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_training_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlearning_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_prediction_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mprediction_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_end\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_prediction_seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start predicting from day:{} - day:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6eba108925f8>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data_train_input, data_train_output, prediction_period)\u001b[0m\n\u001b[1;32m    112\u001b[0m                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                           self.outputs], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mmy_loss_train_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_loss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "value_model = ValueModel('Nordea', 5, 30)\n",
    "value_model.fit('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_neurons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-733-df15de6d9642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStatefulLstmModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-719-57413d4fa7db>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, net_attributes)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             self.net_attributes = NetAttributes(n_neurons,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                        \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                        \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_neurons' is not defined"
     ]
    }
   ],
   "source": [
    "# test\n",
    "model = StatefulLstmModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"np_ema{}_beta{}.npz\".format(20, 99)\n",
    "data_all = np.load(file_name)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 504, 1)\n",
      "(65, 504, 1)\n",
      "[0.05327712]\n",
      "06:07:37.764473 repeat=0 training finished, training MSE=0.05920288419074495\n",
      "06:07:40.034253 repeat=1 training finished, training MSE=0.030061603643116542\n"
     ]
    }
   ],
   "source": [
    "def transform(data_all, n_inputs, n_outputs):\n",
    "    orig_shape = data_all.shape\n",
    "    data_train_reshape = data_all.reshape((orig_shape[0] * orig_shape[1], orig_shape[2]))\n",
    "\n",
    "    scaler_input = preprocessing.MinMaxScaler().fit(data_train_reshape[:,:n_inputs])\n",
    "    data_train_input_scaled = scaler_input.transform(data_train_reshape[:,:n_inputs])\n",
    "\n",
    "    # the invalid step, we change it to zero!\n",
    "    data_train_input_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "    data_train_input = data_train_input_scaled.reshape(orig_shape[0], orig_shape[1], n_inputs)\n",
    "\n",
    "    scaler_output = preprocessing.MinMaxScaler().fit(data_train_reshape[:,-n_outputs:])\n",
    "    data_train_output_scaled = scaler_output.transform(data_train_reshape[:,-n_outputs:])\n",
    "    # the invalid step, we change it to zero!\n",
    "    data_train_output_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "    data_train_output = data_train_output_scaled.reshape(orig_shape[0], orig_shape[1], n_outputs)\n",
    "    return data_train_input, data_train_output, scaler_output\n",
    "\n",
    "stock_index = 5\n",
    "input_column_list = [30+stock_index]\n",
    "output_column_list = [60+stock_index]\n",
    "all_data = data_all[:,7:-5,input_column_list+output_column_list]\n",
    "data_train_input, data_train_output, scaler_output = transform(all_data, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "print(data_train_input.shape)\n",
    "print(data_train_output.shape)\n",
    "print(scaler_output.data_range_)\n",
    "\n",
    "# TODO: do the scaling outside here!\n",
    "model.fit(data_train_input[:30,:,:],data_train_output[:30,:,:],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[0.00023405 0.00021665]\n",
      "sequence:0 test finished, testing MSE=0.00023405496904160827\n",
      "sequence:1 test finished, testing MSE=0.00021665381791535765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.85862219],\n",
       "        [0.86148429],\n",
       "        [0.86303729],\n",
       "        ...,\n",
       "        [0.84564275],\n",
       "        [0.84523499],\n",
       "        [0.84493393]],\n",
       "\n",
       "       [[0.84995419],\n",
       "        [0.85443217],\n",
       "        [0.85830563],\n",
       "        ...,\n",
       "        [0.84940988],\n",
       "        [0.8482694 ],\n",
       "        [0.84642345]]])"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.predict(data_train_input[30:32,:,:])\n",
    "y = data_train_output[30:32,:,:]\n",
    "print(np.mean(np.square(outputs-y), axis=(1,2)))\n",
    "model.predict_and_verify(data_train_input[30:32,:,:],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: save\n"
     ]
    }
   ],
   "source": [
    "model.save('save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/tf_session.ckpt\n",
      "Model restored.\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.85862219],\n",
       "        [0.86148429],\n",
       "        [0.86303729],\n",
       "        ...,\n",
       "        [0.84564275],\n",
       "        [0.84523499],\n",
       "        [0.84493393]],\n",
       "\n",
       "       [[0.84995419],\n",
       "        [0.85443217],\n",
       "        [0.85830563],\n",
       "        ...,\n",
       "        [0.84940988],\n",
       "        [0.8482694 ],\n",
       "        [0.84642345]]])"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load('save')\n",
    "model.predict(data_train_input[30:32,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/tf_session.ckpt\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "new_m = StatefulLstmModel()\n",
    "new_m.load('save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[0.00023405 0.00021665]\n"
     ]
    }
   ],
   "source": [
    "outputs = new_m.predict(data_train_input[30:32,:,:])\n",
    "y = data_train_output[30:32,:,:]\n",
    "print(np.mean(np.square(outputs-y), axis=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
