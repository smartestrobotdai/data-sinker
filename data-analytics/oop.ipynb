{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatefulLstmModel:\n",
    "    def __init__(self,\n",
    "                 tf_model_filename = None, \n",
    "                 n_neurons = 100, \n",
    "                 learning_rate = 0.003, \n",
    "                 num_layers = 1,\n",
    "                 rnn_type = 2,\n",
    "                 prediction_period = 1,\n",
    "                 n_repeats = 4,\n",
    "                ):\n",
    "        self.tf_model_filename = tf_model_filename\n",
    "        self.n_neurons = n_neurons;\n",
    "        self.learning_rate = learning_rate;\n",
    "        self.num_layers = num_layers;\n",
    "        self.rnn_type = rnn_type;\n",
    "        self.prediction_period = prediction_period;\n",
    "        self.n_repeats = n_repeats\n",
    "        self.model_initialized = False\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def __del__(self):\n",
    "        if self.sess != None:\n",
    "            self.sess.close()\n",
    "    \n",
    "    def get_batch(self, seq_index, data_train_input, data_train_output):\n",
    "        X_batch = data_train_input[seq_index:seq_index+1]\n",
    "        y_batch = data_train_output[seq_index:seq_index+1]\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    \n",
    "    def initialize_layers(self):\n",
    "        layers = None\n",
    "        if self.rnn_type == 0:\n",
    "            layers = [tf.nn.rnn_cell.BasicLSTMCell(self.n_neurons) \n",
    "              for _ in range(self.num_layers)]\n",
    "        elif self.rnn_type == 1:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(self.n_neurons, use_peepholes=False) \n",
    "              for _ in range(self.num_layers)]\n",
    "        elif self.rnn_type == 2:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(self.n_neurons, use_peepholes=True) \n",
    "              for _ in range(self.num_layers)]\n",
    "        else:\n",
    "            print(\"WRONG\")\n",
    "        return layers\n",
    "    \n",
    "    def reset_graph(self, seed=42):\n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def create_model(self):\n",
    "        self.X = tf.placeholder(tf.float32, [None, self.steps, self.n_inputs])\n",
    "        self.y = tf.placeholder(tf.float32, [None, self.steps, self.n_outputs])\n",
    "        layers = self.initialize_layers()\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "        self.init_state = tf.placeholder(tf.float32, [self.num_layers, 2, 1, self.n_neurons])\n",
    "        \n",
    "        state_per_layer_list = tf.unstack(self.init_state, axis=0)\n",
    "        rnn_tuple_state = tuple(\n",
    "            [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "             for idx in range(self.num_layers)]\n",
    "        )\n",
    "        \n",
    "        rnn_outputs, self.new_states = tf.nn.dynamic_rnn(cell, self.X, dtype=tf.float32, \n",
    "                                                    initial_state=rnn_tuple_state)\n",
    "        \n",
    "        stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, self.n_neurons])\n",
    "        stacked_outputs = tf.layers.dense(stacked_rnn_outputs, self.n_outputs)\n",
    "        self.outputs = tf.reshape(stacked_outputs, [-1, self.steps, self.n_outputs])\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.square(self.outputs - self.y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        self.training_op = optimizer.minimize(self.loss)\n",
    "\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.model_initialized = True\n",
    "        return self.X, self.y, self.init_state, self.init, self.training_op, \\\n",
    "            self.new_states, self.loss, self.outputs\n",
    "    \n",
    "    # train the model, input is the training data for one cycle\n",
    "    # input is in the shape: [days, steps, features], the features are \n",
    "    # 1. diff, 2. volume. 3. timesteps.\n",
    "    def fit(self,data_train_input, data_train_output):\n",
    "        n_outputs = 1\n",
    "        n_inputs = data_train_input.shape[2]\n",
    "        batch_size = 1\n",
    "        days = data_train_input.shape[0]\n",
    "        steps = data_train_input.shape[1]\n",
    "        self.steps = steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.reset_graph()\n",
    "        X, y, init_state, init, training_op, new_states, loss, outputs = self.create_model()\n",
    "        my_loss_train_list = []\n",
    "        sess = tf.Session()\n",
    "        # TODO: load from file.\n",
    "        if (self.tf_model_filename == None):\n",
    "            init.run(session=sess)\n",
    "            # batch size is 1\n",
    "            rnn_states_before_training = np.zeros((self.num_layers, 2, 1, self.n_neurons))\n",
    "        else:\n",
    "            print(\"load from file, Not implemented\")\n",
    "\n",
    "        for repeat in range(self.n_repeats):\n",
    "            rnn_states = copy.deepcopy(rnn_states_before_training)\n",
    "            for seq in range(days):\n",
    "                X_batch, y_batch = self.get_batch(seq, data_train_input, data_train_output)\n",
    "                feed_dict = {\n",
    "                        X: X_batch,\n",
    "                        y: y_batch,\n",
    "                        init_state: rnn_states}\n",
    "                my_op, rnn_states, my_loss_train, my_outputs = sess.run([training_op, \n",
    "                          new_states, \n",
    "                          loss, \n",
    "                          outputs], feed_dict=feed_dict)\n",
    "\n",
    "                my_loss_train_list.append(my_loss_train)\n",
    "                # last repeat , remember the sates\n",
    "                if seq+1 == self.prediction_period and repeat == self.n_repeats-1:\n",
    "                    # next training loop starts from here\n",
    "                    tmp_states = copy.deepcopy(rnn_states)\n",
    "                my_loss_train_avg = sum(my_loss_train_list) / len(my_loss_train_list)\n",
    "\n",
    "            print(\"{} repeat={} training finished, training MSE={}\".format(\n",
    "                datetime.datetime.now().time(),\n",
    "                repeat, my_loss_train_avg))\n",
    "            # backup the states after training.\n",
    "        rnn_states_before_training = copy.deepcopy(tmp_states)\n",
    "        \n",
    "        self.rnn_states = rnn_states\n",
    "        self.sess = sess\n",
    "        return\n",
    "    \n",
    "    def predict(self, data_test_input, data_test_output):\n",
    "        days = data_test_input.shape[0]\n",
    "        rnn_states = copy.deepcopy(self.rnn_states)\n",
    "        #X, y, init_state, init, training_op, new_states, loss, outputs = self.create_model()\n",
    "        sess = self.sess\n",
    "        \n",
    "        my_loss_test_list = []\n",
    "        for seq in range(days):\n",
    "            feed_dict = {\n",
    "                self.X: data_test_input[seq:seq+1],\n",
    "                self.y: data_test_output[seq:seq+1],\n",
    "                self.init_state: rnn_states,\n",
    "            }\n",
    "            rnn_states, my_loss_test, my_outputs = sess.run([self.new_states, self.loss, self.outputs], feed_dict=feed_dict)\n",
    "            my_loss_test_list.append(my_loss_test)\n",
    "            print(\"sequence:{} test finished, testing MSE={}\".format(seq, my_loss_test))\n",
    "    \n",
    "    def get_nodes(self):\n",
    "        return self.sess, self.X, self.y, self.init_state, self.new_states, self.loss, self.outputs\n",
    "    \n",
    "    def clear_nodes(self):\n",
    "        self.sess = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.init_state = None\n",
    "        self.new_states = None\n",
    "        self.loss = None\n",
    "        self.outputs = None\n",
    "    \n",
    "    def set_nodes(self, sess, X, y, init_state, new_states, loss, outputs):\n",
    "        self.sess = sess\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.init_state = init_state\n",
    "        self.new_states = new_states\n",
    "        self.loss = loss\n",
    "        self.outputs = outputs\n",
    "    \n",
    "    def set_hyper_params_and_states(self, hyper_params_and_states):\n",
    "        self.__dict__.update(hyper_params_and_states)\n",
    "\n",
    "    \n",
    "    def get_hyper_params_and_states(self):\n",
    "        return {\n",
    "            'n_neurons': self.n_neurons,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'num_layers': self.num_layers,\n",
    "            'rnn_type': self.rnn_type,\n",
    "            'n_repeats': self.n_repeats,\n",
    "            'rnn_states': self.rnn_states,\n",
    "            'steps': self.steps,\n",
    "            'n_inputs': self.n_inputs,\n",
    "            'n_outputs': self.n_outputs\n",
    "        }\n",
    "    \n",
    "    def save(self, filename_no_suffix):\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(self.sess, filename_no_suffix + '.ckpt')\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "        hyper_params_and_states = self.get_hyper_params_and_states()\n",
    "        with open(filename_no_suffix + '.pkl', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(hyper_params_and_states, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "            \n",
    "    def load(self, filename_no_suffix):\n",
    "        # 1. restore hyper-params\n",
    "        with open(filename_no_suffix + '.pkl', 'rb') as f:\n",
    "            hyper_params_and_states = pickle.load(f)\n",
    "            print(hyper_params_and_states)\n",
    "        self.set_hyper_params_and_states(hyper_params_and_states)\n",
    "        \n",
    "        # 2. restore graph\n",
    "        if self.model_initialized == False:\n",
    "            self.reset_graph()\n",
    "            self.create_model()\n",
    "        \n",
    "        # 3. restore session\n",
    "        saver = tf.train.Saver()\n",
    "        self.sess = tf.Session()\n",
    "        saver.restore(self.sess, filename_no_suffix + '.ckpt')\n",
    "        print(\"Model restored.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "model = StatefulLstmModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"np_ema{}_beta{}.npz\".format(20, 99)\n",
    "data_all = np.load(file_name)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 504, 1)\n",
      "(65, 504, 1)\n",
      "[0.05327712]\n",
      "05:12:49.548395 repeat=0 training finished, training MSE=0.05920288419074495\n",
      "05:12:55.881972 repeat=1 training finished, training MSE=0.030061603643116542\n",
      "05:13:02.442431 repeat=2 training finished, training MSE=0.020167609837517374\n",
      "05:13:08.370142 repeat=3 training finished, training MSE=0.015214760272829152\n"
     ]
    }
   ],
   "source": [
    "def transform(data_all, n_inputs, n_outputs):\n",
    "    orig_shape = data_all.shape\n",
    "    data_train_reshape = data_all.reshape((orig_shape[0] * orig_shape[1], orig_shape[2]))\n",
    "\n",
    "    scaler_input = preprocessing.MinMaxScaler().fit(data_train_reshape[:,:n_inputs])\n",
    "    data_train_input_scaled = scaler_input.transform(data_train_reshape[:,:n_inputs])\n",
    "\n",
    "    # the invalid step, we change it to zero!\n",
    "    data_train_input_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "    data_train_input = data_train_input_scaled.reshape(orig_shape[0], orig_shape[1], n_inputs)\n",
    "\n",
    "    scaler_output = preprocessing.MinMaxScaler().fit(data_train_reshape[:,-n_outputs:])\n",
    "    data_train_output_scaled = scaler_output.transform(data_train_reshape[:,-n_outputs:])\n",
    "    # the invalid step, we change it to zero!\n",
    "    data_train_output_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "    data_train_output = data_train_output_scaled.reshape(orig_shape[0], orig_shape[1], n_outputs)\n",
    "    return data_train_input, data_train_output, scaler_output\n",
    "\n",
    "\n",
    "\n",
    "stock_index = 5\n",
    "input_column_list = [30+stock_index]\n",
    "output_column_list = [60+stock_index]\n",
    "all_data = data_all[:,7:-5,input_column_list+output_column_list]\n",
    "data_train_input, data_train_output, scaler_output = transform(all_data, 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "print(data_train_input.shape)\n",
    "print(data_train_output.shape)\n",
    "print(scaler_output.data_range_)\n",
    "\n",
    "# TODO: do the scaling outside here!\n",
    "model.fit(data_train_input[:30,:,:],data_train_output[:30,:,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence:0 test finished, testing MSE=7.825874490663409e-05\n",
      "sequence:1 test finished, testing MSE=0.00013719226990360767\n"
     ]
    }
   ],
   "source": [
    "model.predict(data_train_input[30:32,:,:],data_train_output[30:32,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: save.ckpt\n"
     ]
    }
   ],
   "source": [
    "model.save('save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neurons': 100, 'learning_rate': 0.003, 'num_layers': 1, 'rnn_type': 2, 'n_repeats': 4, 'rnn_states': (LSTMStateTuple(c=array([[ 0.14004055, -0.12276338,  0.1360079 ,  0.0773332 , -0.22763984,\n",
      "        -0.01303453,  0.05920409, -0.03322243,  0.00050975,  0.00637852,\n",
      "        -0.2481907 , -0.01804037,  0.10121535,  0.24544367, -0.09096131,\n",
      "        -0.14827758,  0.2746837 , -0.09316803, -0.33776656, -0.39537546,\n",
      "        -0.14279257, -0.17128304,  0.23614636,  0.06018716,  0.25628114,\n",
      "         0.09274361,  0.13785239,  0.13119625,  0.0721456 ,  0.04170251,\n",
      "         0.14618814, -0.00350116,  0.02993896, -0.1152178 , -0.05495078,\n",
      "        -0.00412621, -0.41165295,  0.33623067,  0.10702051, -0.02188108,\n",
      "        -0.1752245 , -0.07821145, -0.16271316,  0.00938086, -0.28486693,\n",
      "         0.15096101, -0.22611402, -0.0671767 , -0.01272984, -0.07623836,\n",
      "         0.27866238,  0.10276368,  0.1338001 , -0.20315565,  0.1383292 ,\n",
      "        -0.15351345,  0.00588265,  0.02938608, -0.23711422, -0.07224143,\n",
      "         0.1234675 ,  0.11959596, -0.0625322 , -0.04754499,  0.02348813,\n",
      "        -0.3249935 ,  0.28997865,  0.16721499, -0.02547655,  0.04709225,\n",
      "         0.14547187, -0.20485473, -0.00353449,  0.13095585, -0.21697865,\n",
      "        -0.06331421,  0.18953495,  0.09063664,  0.00107288,  0.19733246,\n",
      "         0.27799678, -0.01091732, -0.09564914, -0.07188103, -0.07799322,\n",
      "        -0.03848634, -0.3801308 , -0.22662337, -0.4840209 , -0.09777458,\n",
      "        -0.08056402, -0.25326425,  0.0884755 , -0.26696578,  0.04524313,\n",
      "         0.01053251, -0.09301431,  0.12923056, -0.05600581,  0.09402796]],\n",
      "      dtype=float32), h=array([[ 0.06877927, -0.06161946,  0.07065511,  0.03513755, -0.11359236,\n",
      "        -0.00547646,  0.02439872, -0.01367245,  0.00024539,  0.00316237,\n",
      "        -0.120912  , -0.00849465,  0.04087214,  0.12276006, -0.04463464,\n",
      "        -0.06324196,  0.14040059, -0.04316343, -0.1664865 , -0.1769836 ,\n",
      "        -0.06701538, -0.07453831,  0.11076599,  0.02708101,  0.10831755,\n",
      "         0.04641492,  0.06496394,  0.06795945,  0.03560679,  0.02002943,\n",
      "         0.0705848 , -0.00174621,  0.01369542, -0.05389632, -0.02567749,\n",
      "        -0.00209832, -0.19717334,  0.15661626,  0.04778676, -0.01110564,\n",
      "        -0.08846096, -0.03754984, -0.07545076,  0.00421569, -0.13785025,\n",
      "         0.07629013, -0.10936496, -0.03377837, -0.00605204, -0.0394997 ,\n",
      "         0.13323356,  0.05416679,  0.06408365, -0.09779393,  0.06416471,\n",
      "        -0.06742606,  0.00279072,  0.01492245, -0.11226543, -0.03254378,\n",
      "         0.0579584 ,  0.06252164, -0.03182694, -0.02206892,  0.0108414 ,\n",
      "        -0.15394072,  0.12835084,  0.08270621, -0.01240995,  0.02228066,\n",
      "         0.07330853, -0.1029202 , -0.00153722,  0.06613467, -0.10239404,\n",
      "        -0.03272752,  0.09107487,  0.04388464,  0.00052822,  0.1003034 ,\n",
      "         0.13109055, -0.00550856, -0.04118495, -0.03497997, -0.03499897,\n",
      "        -0.01916397, -0.17473085, -0.10852467, -0.23738949, -0.04441092,\n",
      "        -0.04156413, -0.11916214,  0.04346179, -0.1298951 ,  0.02207405,\n",
      "         0.0045853 , -0.04356034,  0.06201519, -0.02768317,  0.04727127]],\n",
      "      dtype=float32)),), 'steps': 504, 'n_inputs': 1, 'n_outputs': 1}\n",
      "INFO:tensorflow:Restoring parameters from save.ckpt\n",
      "Model restored.\n",
      "sequence:0 test finished, testing MSE=7.825874490663409e-05\n",
      "sequence:1 test finished, testing MSE=0.00013719226990360767\n"
     ]
    }
   ],
   "source": [
    "model.load('save')\n",
    "model.predict(data_train_input[30:32,:,:],data_train_output[30:32,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neurons': 100, 'learning_rate': 0.003, 'num_layers': 1, 'rnn_type': 2, 'n_repeats': 4, 'rnn_states': (LSTMStateTuple(c=array([[ 0.14004055, -0.12276338,  0.1360079 ,  0.0773332 , -0.22763984,\n",
      "        -0.01303453,  0.05920409, -0.03322243,  0.00050975,  0.00637852,\n",
      "        -0.2481907 , -0.01804037,  0.10121535,  0.24544367, -0.09096131,\n",
      "        -0.14827758,  0.2746837 , -0.09316803, -0.33776656, -0.39537546,\n",
      "        -0.14279257, -0.17128304,  0.23614636,  0.06018716,  0.25628114,\n",
      "         0.09274361,  0.13785239,  0.13119625,  0.0721456 ,  0.04170251,\n",
      "         0.14618814, -0.00350116,  0.02993896, -0.1152178 , -0.05495078,\n",
      "        -0.00412621, -0.41165295,  0.33623067,  0.10702051, -0.02188108,\n",
      "        -0.1752245 , -0.07821145, -0.16271316,  0.00938086, -0.28486693,\n",
      "         0.15096101, -0.22611402, -0.0671767 , -0.01272984, -0.07623836,\n",
      "         0.27866238,  0.10276368,  0.1338001 , -0.20315565,  0.1383292 ,\n",
      "        -0.15351345,  0.00588265,  0.02938608, -0.23711422, -0.07224143,\n",
      "         0.1234675 ,  0.11959596, -0.0625322 , -0.04754499,  0.02348813,\n",
      "        -0.3249935 ,  0.28997865,  0.16721499, -0.02547655,  0.04709225,\n",
      "         0.14547187, -0.20485473, -0.00353449,  0.13095585, -0.21697865,\n",
      "        -0.06331421,  0.18953495,  0.09063664,  0.00107288,  0.19733246,\n",
      "         0.27799678, -0.01091732, -0.09564914, -0.07188103, -0.07799322,\n",
      "        -0.03848634, -0.3801308 , -0.22662337, -0.4840209 , -0.09777458,\n",
      "        -0.08056402, -0.25326425,  0.0884755 , -0.26696578,  0.04524313,\n",
      "         0.01053251, -0.09301431,  0.12923056, -0.05600581,  0.09402796]],\n",
      "      dtype=float32), h=array([[ 0.06877927, -0.06161946,  0.07065511,  0.03513755, -0.11359236,\n",
      "        -0.00547646,  0.02439872, -0.01367245,  0.00024539,  0.00316237,\n",
      "        -0.120912  , -0.00849465,  0.04087214,  0.12276006, -0.04463464,\n",
      "        -0.06324196,  0.14040059, -0.04316343, -0.1664865 , -0.1769836 ,\n",
      "        -0.06701538, -0.07453831,  0.11076599,  0.02708101,  0.10831755,\n",
      "         0.04641492,  0.06496394,  0.06795945,  0.03560679,  0.02002943,\n",
      "         0.0705848 , -0.00174621,  0.01369542, -0.05389632, -0.02567749,\n",
      "        -0.00209832, -0.19717334,  0.15661626,  0.04778676, -0.01110564,\n",
      "        -0.08846096, -0.03754984, -0.07545076,  0.00421569, -0.13785025,\n",
      "         0.07629013, -0.10936496, -0.03377837, -0.00605204, -0.0394997 ,\n",
      "         0.13323356,  0.05416679,  0.06408365, -0.09779393,  0.06416471,\n",
      "        -0.06742606,  0.00279072,  0.01492245, -0.11226543, -0.03254378,\n",
      "         0.0579584 ,  0.06252164, -0.03182694, -0.02206892,  0.0108414 ,\n",
      "        -0.15394072,  0.12835084,  0.08270621, -0.01240995,  0.02228066,\n",
      "         0.07330853, -0.1029202 , -0.00153722,  0.06613467, -0.10239404,\n",
      "        -0.03272752,  0.09107487,  0.04388464,  0.00052822,  0.1003034 ,\n",
      "         0.13109055, -0.00550856, -0.04118495, -0.03497997, -0.03499897,\n",
      "        -0.01916397, -0.17473085, -0.10852467, -0.23738949, -0.04441092,\n",
      "        -0.04156413, -0.11916214,  0.04346179, -0.1298951 ,  0.02207405,\n",
      "         0.0045853 , -0.04356034,  0.06201519, -0.02768317,  0.04727127]],\n",
      "      dtype=float32)),), 'steps': 504, 'n_inputs': 1, 'n_outputs': 1}\n",
      "INFO:tensorflow:Restoring parameters from save.ckpt\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "new_m = StatefulLstmModel()\n",
    "new_m.load('save')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence:0 test finished, testing MSE=7.825874490663409e-05\n",
      "sequence:1 test finished, testing MSE=0.00013719226990360767\n"
     ]
    }
   ],
   "source": [
    "new_m.predict(data_train_input[30:32,:,:],data_train_output[30:32,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
