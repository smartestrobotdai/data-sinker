{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import pickle\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sma(data, window):\n",
    "    \"\"\"\n",
    "    Calculates Simple Moving Average\n",
    "    http://fxtrade.oanda.com/learn/forex-indicators/simple-moving-average\n",
    "    \"\"\"\n",
    "    if len(data) < window:\n",
    "        return None\n",
    "    return sum(data[-window:]) / float(window)\n",
    "\n",
    "def get_ema(data, window):\n",
    "    if len(data) < 2 * window:\n",
    "        raise ValueError(\"data is too short\")\n",
    "    c = 2.0 / (window + 1)\n",
    "    current_ema = sma(data[-window*2:-window], window)\n",
    "    for value in data[-window:]:\n",
    "        current_ema = (c * value) + ((1 - c) * current_ema)\n",
    "    return current_ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetAttributes:\n",
    "    def __init__(self, n_neurons = 100, \n",
    "                 learning_rate = 0.003, \n",
    "                 num_layers = 1,\n",
    "                 rnn_type = 2,\n",
    "                 n_repeats = 2):\n",
    "        self.n_neurons = n_neurons;\n",
    "        self.learning_rate = learning_rate;\n",
    "        self.num_layers = num_layers;\n",
    "        self.rnn_type = rnn_type;\n",
    "        self.n_repeats = n_repeats\n",
    "        self.n_steps = None\n",
    "        self.n_inputs = None\n",
    "        self.n_outputs = 1\n",
    "        \n",
    "    def set_input_dimension(self, n_steps, n_inputs):\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetStates:\n",
    "    def __init__(self):\n",
    "        self.prediction_states = None\n",
    "        self.training_states = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatefulLstmModel:\n",
    "    def __init__(self,\n",
    "                n_neurons=100,\n",
    "                learning_rate=0.002,\n",
    "                num_layers=2,\n",
    "                rnn_type=1,\n",
    "                n_repeats=30):\n",
    "\n",
    "        self.net_attributes = NetAttributes(n_neurons,\n",
    "                                   learning_rate,\n",
    "                                   num_layers,\n",
    "                                   rnn_type,\n",
    "                                   n_repeats)\n",
    "        self.net_states = NetStates()\n",
    "        self.model_initialized = False\n",
    "        self.sess = None\n",
    "    \n",
    "    def __del__(self):\n",
    "        if self.sess != None:\n",
    "            self.sess.close()\n",
    "    \n",
    "    def get_batch(self, seq_index, data_train_input, data_train_output):\n",
    "        X_batch = data_train_input[seq_index:seq_index+1]\n",
    "        y_batch = data_train_output[seq_index:seq_index+1]\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    \n",
    "    def initialize_layers(self):\n",
    "        layers = None\n",
    "        net_attributes = self.net_attributes\n",
    "        if net_attributes.rnn_type == 0:\n",
    "            layers = [tf.nn.rnn_cell.BasicLSTMCell(net_attributes.n_neurons) \n",
    "              for _ in range(net_attributes.num_layers)]\n",
    "        elif net_attributes.rnn_type == 1:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(net_attributes.n_neurons, use_peepholes=False) \n",
    "              for _ in range(net_attributes.num_layers)]\n",
    "        elif net_attributes.rnn_type == 2:\n",
    "            layers = [tf.nn.rnn_cell.LSTMCell(net_attributes.n_neurons, use_peepholes=True) \n",
    "              for _ in range(net_attributes.num_layers)]\n",
    "        else:\n",
    "            print(\"WRONG\")\n",
    "        return layers\n",
    "    \n",
    "    def reset_graph(self, seed=42):\n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def create_model(self):\n",
    "        net_attributes = self.net_attributes\n",
    "        self.X = tf.placeholder(tf.float32, [None, net_attributes.n_steps, net_attributes.n_inputs])\n",
    "        self.y = tf.placeholder(tf.float32, [None, net_attributes.n_steps, net_attributes.n_outputs])\n",
    "        layers = self.initialize_layers()\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "        self.init_state = tf.placeholder(tf.float32, [net_attributes.num_layers, 2, 1, net_attributes.n_neurons])\n",
    "        \n",
    "        state_per_layer_list = tf.unstack(self.init_state, axis=0)\n",
    "        rnn_tuple_state = tuple(\n",
    "            [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "             for idx in range(net_attributes.num_layers)]\n",
    "        )\n",
    "        \n",
    "        rnn_outputs, self.new_states = tf.nn.dynamic_rnn(cell, self.X, dtype=tf.float32, \n",
    "                                                    initial_state=rnn_tuple_state)\n",
    "        \n",
    "        stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, net_attributes.n_neurons])\n",
    "        stacked_outputs = tf.layers.dense(stacked_rnn_outputs, net_attributes.n_outputs)\n",
    "        self.outputs = tf.reshape(stacked_outputs, [-1, net_attributes.n_steps, net_attributes.n_outputs])\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.square(self.outputs - self.y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=net_attributes.learning_rate)\n",
    "        self.training_op = optimizer.minimize(self.loss)\n",
    "\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.model_initialized = True\n",
    "    \n",
    "    # train the model, input is the training data for one cycle\n",
    "    # input is in the shape: [days, steps, features], the features are \n",
    "    # 1. diff, 2. volume. 3. timesteps.\n",
    "    def fit(self, data_train_input, data_train_output, prediction_period):\n",
    "        net_attributes = self.net_attributes\n",
    "        net_states = self.net_states\n",
    "        n_inputs = data_train_input.shape[2]\n",
    "        n_steps = data_train_input.shape[1]\n",
    "\n",
    "        net_attributes.set_input_dimension(n_steps, n_inputs)\n",
    "        batch_size = 1\n",
    "        days = data_train_input.shape[0]\n",
    "        \n",
    "        self.reset_graph()\n",
    "        self.create_model()\n",
    "        my_loss_train_list = []\n",
    "        sess = tf.Session()\n",
    "        # TODO: load from file.\n",
    "\n",
    "        self.init.run(session=sess)\n",
    "        # if this is the first time of fit?\n",
    "        if self.net_states.training_states == None:\n",
    "            init_states = np.zeros((net_attributes.num_layers, 2, 1, net_attributes.n_neurons))\n",
    "        else:\n",
    "            init_states = self.net_states.training_states\n",
    "            \n",
    "        for repeat in range(net_attributes.n_repeats):\n",
    "            rnn_states = copy.deepcopy(init_states)\n",
    "            for seq in range(days):\n",
    "                X_batch, y_batch = self.get_batch(seq, data_train_input, data_train_output)\n",
    "                feed_dict = {\n",
    "                        self.X: X_batch,\n",
    "                        self.y: y_batch,\n",
    "                        self.init_state: rnn_states}\n",
    "                my_op, rnn_states, my_loss_train, my_outputs = sess.run([self.training_op, \n",
    "                          self.new_states, \n",
    "                          self.loss, \n",
    "                          self.outputs], feed_dict=feed_dict)\n",
    "\n",
    "                my_loss_train_list.append(my_loss_train)\n",
    "                # last repeat , remember the sates\n",
    "                if seq+1 == prediction_period and repeat == net_attributes.n_repeats-1:\n",
    "                    # next training loop starts from here\n",
    "                    training_states = copy.deepcopy(rnn_states)\n",
    "                my_loss_train_avg = sum(my_loss_train_list) / len(my_loss_train_list)\n",
    "\n",
    "            print(\"{} repeat={} training finished, training MSE={}\".format(\n",
    "                datetime.datetime.now().time(),\n",
    "                repeat, my_loss_train_avg))\n",
    "        \n",
    "        self.net_states.training_states = training_states\n",
    "        self.net_states.prediction_states = rnn_states\n",
    "        self.sess = sess\n",
    "        return\n",
    "    \n",
    "    def predict_base(self, data_test_input, data_test_output=None):\n",
    "        net_attributes = self.net_attributes\n",
    "        net_states = self.net_states\n",
    "        days = data_test_input.shape[0]\n",
    "        \n",
    "        rnn_states = copy.deepcopy(net_states.prediction_states)\n",
    "        #X, y, init_state, init, training_op, new_states, loss, outputs = self.create_model()\n",
    "        sess = self.sess\n",
    "        \n",
    "        my_loss_test_list = []\n",
    "        input_shape = data_test_input.shape\n",
    "        outputs_all_days = np.zeros((input_shape[0], input_shape[1], 1))\n",
    "        for seq in range(days):\n",
    "            if data_test_output is None:\n",
    "                feed_dict = {\n",
    "                    self.X: data_test_input[seq:seq+1],\n",
    "                    self.init_state: rnn_states,\n",
    "                }\n",
    "\n",
    "                rnn_states, my_outputs = sess.run([self.new_states, self.outputs], feed_dict=feed_dict)\n",
    "            else:\n",
    "                feed_dict = {\n",
    "                    self.X: data_test_input[seq:seq+1],\n",
    "                    self.y: data_test_output[seq:seq+1],\n",
    "                    self.init_state: rnn_states,\n",
    "                }\n",
    "\n",
    "                rnn_states, my_outputs, my_loss_test = sess.run([self.new_states, \n",
    "                                                                 self.outputs, self.loss], feed_dict=feed_dict)\n",
    "                print(\"Predicting seq:{} testing MSE: {}\".format(seq, my_loss_test))\n",
    "            outputs_all_days[seq] = my_outputs\n",
    "            \n",
    "        \n",
    "        return outputs_all_days\n",
    "    \n",
    "    def predict(self, data_test_input):\n",
    "        return self.predict_base(data_test_input)\n",
    "        \n",
    "    def predict_and_verify(self, data_test_input, data_test_output):\n",
    "        return self.predict_base(data_test_input, data_test_output)\n",
    "      \n",
    "    def get_attributes_filename(self, path):\n",
    "        if path[-1] != '/':\n",
    "            path += '/'\n",
    "        return path + 'net_attributes.pkl'\n",
    "    \n",
    "    def get_path(self, path, date):\n",
    "        return os.path.join(path, date)\n",
    "\n",
    "    \n",
    "    def get_states_filename(self, path, date):\n",
    "        return os.path.join(self.get_path(path, date), 'net_states.pkl')\n",
    "    \n",
    "    def get_model_filename(self, path, date):\n",
    "        return os.path.join(self.get_path(path, date),'tf_session.ckpt')\n",
    "    \n",
    "    def save(self, path, date):\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(self.sess, self.get_model_filename(path, date))\n",
    "        with open(self.get_attributes_filename(path), 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump(self.net_attributes, f, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.get_states_filename(path, date), 'wb') as f:\n",
    "            pickle.dump(self.net_states, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"Model saved in path: %s\" % path)\n",
    "        \n",
    "            \n",
    "    def load(self, path, date):\n",
    "        # TODO: if date is none, load the latest.\n",
    "        \n",
    "        # restore hyper-params\n",
    "        with open(self.get_attributes_filename(path), 'rb') as f:\n",
    "            self.net_attributes = pickle.load(f)\n",
    "\n",
    "        # restore states\n",
    "        with open(self.get_states_filename(path, date), 'rb') as f:\n",
    "            self.net_states = pickle.load(f)\n",
    "        \n",
    "        # 2. restore graph\n",
    "        if self.model_initialized == False:\n",
    "            self.reset_graph()\n",
    "            self.create_model()\n",
    "        \n",
    "        # 3. restore session\n",
    "        saver = tf.train.Saver()\n",
    "        self.sess = tf.Session()\n",
    "        saver.restore(self.sess, self.get_model_filename(path, date))\n",
    "        print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFormat:\n",
    "    NONE = 0\n",
    "    DAY = 1\n",
    "    WEEK = 2\n",
    "\n",
    "class DataManipulator:\n",
    "    def __init__(self,  n_learning_days,\n",
    "                n_prediction_days, beta, ema, time_format, volume_input, use_centralized_bid, \n",
    "                split_daily_data, n_training_days):\n",
    "        self.n_learning_days = n_learning_days\n",
    "        self.n_prediction_days = n_prediction_days\n",
    "        self.beta = beta\n",
    "        self.ema = ema\n",
    "        self.time_format = time_format\n",
    "        self.volume_input = volume_input\n",
    "        self.use_centralized_bid = use_centralized_bid\n",
    "        self.split_daily_data = split_daily_data\n",
    "        self.n_training_days = n_training_days\n",
    "        self.last_learning_date = None\n",
    "        self.next_prediction_seq = None\n",
    "        self.next_learning_seq = None\n",
    "        \n",
    "        if split_daily_data == True:\n",
    "            self.n_learning_seqs = self.n_learning_days * 2\n",
    "            self.n_prediction_seqs = self.n_prediction_days * 2\n",
    "        else:\n",
    "            self.n_learning_seqs = self.n_learning_days\n",
    "            self.n_prediction_seqs = self.n_prediction_days\n",
    "        \n",
    "        self.scaler_input = None\n",
    "        self.scaler_output = None\n",
    "    \n",
    "    def update(self, next_prediction_seq, last_learning_date):\n",
    "        assert(last_learning_date != None)\n",
    "        print(\"updating, next_prediction_seq={}, last_learning_date={}\".format(next_prediction_seq, last_learning_date))\n",
    "        self.next_prediction_seq = next_prediction_seq\n",
    "        self.next_learning_seq = next_prediction_seq - self.n_learning_seqs\n",
    "        self.last_learning_date = last_learning_date\n",
    "    \n",
    "    def volume_transform(self, volume_series):\n",
    "        # all the volumes must bigger than 0\n",
    "        assert(np.all(volume_series>=0))\n",
    "        return  np.log(volume_series.astype('float')+1)\n",
    "\n",
    "    def inverse_transform_output(self, scaled_outputs):\n",
    "        ori_shape = scaled_outputs.shape\n",
    "        outputs_reshaped = scaled_outputs.reshape((ori_shape[0]*ori_shape[1], \n",
    "                                                   1))\n",
    "        #outputs = np.exp(self.scaler_output.inverse_transform(outputs_reshaped)) - 1\n",
    "        outputs = self.scaler_output.inverse_transform(outputs_reshaped)\n",
    "        return outputs.reshape(ori_shape)\n",
    "    \n",
    "    def transform(self, data, n_inputs, n_outputs):\n",
    "        input_scaled = self.transform_input(data[:,:,:n_inputs])\n",
    "        output_scaled = self.transform_output(data[:,:,-n_outputs:])\n",
    "        return input_scaled, output_scaled\n",
    "    \n",
    "    def transform_input(self, data_input):\n",
    "        return self.transform_helper(self.scaler_input, data_input)\n",
    "    \n",
    "    def transform_output(self, data_output):\n",
    "        return self.transform_helper(self.scaler_output, data_output)\n",
    "        \n",
    "    def transform_helper(self, scaler, data):\n",
    "        shape = data.shape\n",
    "        data = data.reshape(shape[0]*shape[1],shape[2])\n",
    "        data_scaled = scaler.transform(data)\n",
    "        return data_scaled.reshape(shape)\n",
    "    \n",
    "    # do fit and transform at same time\n",
    "    def fit_transform(self, data_all, n_inputs, n_outputs):\n",
    "        orig_shape = data_all.shape\n",
    "        data_train_reshape = data_all.astype('float').reshape((orig_shape[0] * orig_shape[1], orig_shape[2]))\n",
    "        \n",
    "        self.scaler_input = preprocessing.MinMaxScaler().fit(data_train_reshape[:,:n_inputs])\n",
    "        data_train_input_scaled = self.scaler_input.transform(data_train_reshape[:,:n_inputs])\n",
    "        \n",
    "        # the invalid step, we change it to zero!\n",
    "        data_train_input_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "        data_train_input = data_train_input_scaled.reshape(orig_shape[0], orig_shape[1], n_inputs)\n",
    "        \n",
    "        self.scaler_output = preprocessing.MinMaxScaler().fit(data_train_reshape[:,-n_outputs:])\n",
    "        data_train_output_scaled = self.scaler_output.transform(data_train_reshape[:,-n_outputs:])\n",
    "        # the invalid step, we change it to zero!\n",
    "        data_train_output_scaled[~np.any(data_train_reshape, axis=1)] = 0\n",
    "        data_train_output = data_train_output_scaled.reshape(orig_shape[0], orig_shape[1], n_outputs)\n",
    "        \n",
    "        return data_train_input, data_train_output\n",
    "\n",
    "    # to purge data based on parameters like time_input, split_daily_data, etc.\n",
    "    def purge_data(self, input_path, stock_index):\n",
    "        # load numpy file\n",
    "        npy_file_name = input_path + \"/ema{}_beta{}_{}.npy\".format(self.ema, self.beta, stock_index)\n",
    "        input_np_data = np.load(npy_file_name, allow_pickle=True)\n",
    "        \n",
    "        # date list\n",
    "        date_list = []\n",
    "        for i in range(self.n_training_days):    \n",
    "            date = input_np_data[i][0][5].date().strftime(\"%y%m%d\")\n",
    "            date_list.append(date_list)\n",
    "        \n",
    "        \n",
    "        # check if we have days more than training period\n",
    "        assert(input_np_data.shape[0] >= self.n_training_days)\n",
    "        # the diff is the mandatory\n",
    "        input_columns = [2]\n",
    "        \n",
    "        time_format = self.time_format\n",
    "        \n",
    "        if time_format == TimeFormat.DAY:\n",
    "            input_columns += [0]\n",
    "        elif time_format == TimeFormat.WEEK:\n",
    "            input_columns += [1]\n",
    "        \n",
    "        if self.volume_input == 1:\n",
    "            input_columns += [3]\n",
    "        \n",
    "        output_columns = [4]\n",
    "        timestamp_column = [5]\n",
    "        price_column = [6]\n",
    "        input_np_data = input_np_data[:,:,input_columns + output_columns + timestamp_column + price_column]\n",
    "        \n",
    "        # we must tranform the volume for it is too big.\n",
    "        if self.volume_input == 1:\n",
    "            input_np_data[:,:,-4] = self.volume_transform(input_np_data[:,:,-4])\n",
    "        \n",
    "        if self.use_centralized_bid == 0:\n",
    "            # remove all the rows for centralized bid. it should be from 9.01 to 17.24, which is 516-12=504 steps\n",
    "            input_np_data = input_np_data[:,7:-5,:]\n",
    "            \n",
    "        shape = input_np_data.shape\n",
    "        n_training_sequences = self.n_training_days\n",
    "        if self.split_daily_data == 1:\n",
    "            assert(shape[1] % 2 == 0)\n",
    "            input_np_data = input_np_data.reshape((shape[0]*2, \n",
    "                                                  int(shape[1]/2), \n",
    "                                                  shape[2]))\n",
    "            # get the first date and last date\n",
    "            n_training_sequences *= 2\n",
    "        \n",
    "        return input_np_data, n_training_sequences, input_columns\n",
    "    \n",
    "    def prep_training_data(self, input_path, stock_index):\n",
    "        input_np_data, n_training_sequences, input_columns = self.purge_data(input_path, stock_index)\n",
    "        # to scale the data, but not the timestamp and price\n",
    "        data_train_input, data_train_output = self.fit_transform(input_np_data[:n_training_sequences,:,:-2], len(input_columns), 1)\n",
    "        return data_train_input, data_train_output, input_np_data[:n_training_sequences,:,-2], input_np_data[:n_training_sequences,:,-1]\n",
    "    \n",
    "    def prep_testing_data(self, input_path, stock_index):\n",
    "        input_np_data, n_training_sequences, input_columns = self.purge_data(input_path, stock_index)\n",
    "        test_start_seq = self.next_prediction_seq - self.n_learning_seqs\n",
    "        data_test_input, data_test_output = self.transform(input_np_data[test_start_seq:,:,:-2], len(input_columns), 1)\n",
    "        return data_test_input, data_test_output, input_np_data[test_start_seq:,:,-2], input_np_data[test_start_seq:,:,-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import GPy\n",
    "import GPyOpt\n",
    "\n",
    "class ValueModel:\n",
    "    mixed_domain = [{'name': 'n_neurons', 'type': 'discrete', 'domain': tuple(range(20,160,20))},\n",
    "          {'name': 'learning_rate', 'type': 'discrete', 'domain': (0.001,0.002,0.003,0.004)},\n",
    "          {'name': 'num_layers', 'type': 'discrete', 'domain': (1,2,3,4)},\n",
    "          {'name': 'rnn_type', 'type': 'discrete', 'domain': (0,1,2)},\n",
    "          {'name': 'learning_period', 'type': 'discrete', 'domain': (10,20,30,40)},\n",
    "          {'name': 'prediction_period', 'type': 'discrete', 'domain': (1,2,5,10)},\n",
    "          {'name': 'n_repeats', 'type': 'discrete', 'domain': (3,5,10,20,30,40)},\n",
    "          {'name': 'beta', 'type': 'discrete', 'domain': (99, 98)},\n",
    "          {'name': 'ema', 'type': 'discrete', 'domain': (1,5,10,20)},\n",
    "          {'name': 'time_format', 'type': 'discrete', 'domain': (0,1,2)}, #1 for stepofday, 2 for stepofweek\n",
    "          {'name': 'volume_input', 'type': 'discrete', 'domain': (0,1)},\n",
    "          {'name': 'use_centralized_bid', 'type': 'discrete', 'domain': (0,1)},\n",
    "          {'name': 'split_daily_data', 'type': 'discrete', 'domain': (0,1)}\n",
    "         ]\n",
    "    \n",
    "    mixed_domain_test = [{'name': 'n_neurons', 'type': 'discrete', 'domain': tuple(range(20,160,20))},\n",
    "          {'name': 'learning_rate', 'type': 'discrete', 'domain': (0.001,0.002,0.003,0.004)},\n",
    "          {'name': 'num_layers', 'type': 'discrete', 'domain': (1,2,3,4)},\n",
    "          {'name': 'rnn_type', 'type': 'discrete', 'domain': (0,1,2)},\n",
    "          {'name': 'learning_period', 'type': 'discrete', 'domain': (10,20)},\n",
    "          {'name': 'prediction_period', 'type': 'discrete', 'domain': (5,10)},\n",
    "          {'name': 'n_repeats', 'type': 'discrete', 'domain': (3,5)},\n",
    "          {'name': 'beta', 'type': 'discrete', 'domain': (99, 98)},\n",
    "          {'name': 'ema', 'type': 'discrete', 'domain': (1,5,10,20)},\n",
    "          {'name': 'time_format', 'type': 'discrete', 'domain': (0,1,2)}, #1 for stepofday, 2 for stepofweek\n",
    "          {'name': 'volume_input', 'type': 'discrete', 'domain': (0,1)},\n",
    "          {'name': 'use_centralized_bid', 'type': 'discrete', 'domain': (0,1)},\n",
    "          {'name': 'split_daily_data', 'type': 'discrete', 'domain': (0,1)}\n",
    "         ]\n",
    "    \n",
    "    \n",
    "    def __init__(self, stock_name, stock_index, n_training_days):\n",
    "        self.stock_name = stock_name\n",
    "        self.stock_index = stock_index\n",
    "        self.n_training_days = n_training_days\n",
    "        self.save_path = \"model_{}_{}\".format(stock_name, n_training_days)\n",
    "        self.last_training_date = None\n",
    "        self.model = None\n",
    "        self.max_profit = -999.0\n",
    "        return\n",
    "    \n",
    "    def get_parameter_str(self, X):\n",
    "        parameter_str = \"\"\n",
    "        for i in range(len(self.mixed_domain)):\n",
    "            parameter_str += self.mixed_domain[i][\"name\"]\n",
    "            parameter_str += ':'\n",
    "            parameter_str += str(X[i])\n",
    "            parameter_str += ','\n",
    "        return parameter_str\n",
    "    \n",
    "    def get_max_steps(self, groups):\n",
    "        max_steps = 0\n",
    "        for index, df in groups:\n",
    "            df_len = len(df)\n",
    "            if df_len > max_steps:\n",
    "                max_steps = df_len\n",
    "        return max_steps\n",
    "\n",
    "    \n",
    "    def get_data_prep_desc_filename(self, path):\n",
    "        return path + '/data_prep_desc.pkl'\n",
    "    \n",
    "\n",
    "    \n",
    "    def optimize(self, max_iter=300, is_test=False):\n",
    "        if is_test == True:\n",
    "            mixed_domain = self.mixed_domain_test\n",
    "        else:\n",
    "            mixed_domain = self.mixed_domain\n",
    "        \n",
    "        opt_handler = GPyOpt.methods.BayesianOptimization(f=self.opt_func,  # Objective function       \n",
    "                                     domain=mixed_domain,          # Box-constraints of the problem\n",
    "                                     initial_design_numdata = 30,   # Number data initial design\n",
    "                                     acquisition_type='EI',        # Expected Improvement\n",
    "                                     exact_feval = True, \n",
    "                                     maximize = True)           # True evaluations, no sample noise\n",
    "        opt_handler.run_optimization(max_iter, eps=0)\n",
    "    \n",
    "    def get_data_manipulator_filename(self):\n",
    "        return os.path.join(self.save_path, 'data_manipulator.pkl')\n",
    "    \n",
    "\n",
    "    \n",
    "    def save(self):\n",
    "        # what is the last training date?\n",
    "        self.model.save(self.save_path, self.data_manipulator.last_learning_date)\n",
    "        \n",
    "        # save the data_manipulator\n",
    "        filename = self.get_data_manipulator_filename()\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.data_manipulator, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        # save the strategy model\n",
    "        self.strategy_model.save(self.save_path)\n",
    "    \n",
    "    \n",
    "    def get_latest_dir(self, save_path):\n",
    "        all_subdirs = [d for d in os.listdir(save_path) if os.path.isdir(os.path.join(save_path, d))]\n",
    "        max_time = 0\n",
    "        for dirname in all_subdirs:\n",
    "            fullname = os.path.join(save_path, dirname)\n",
    "            time = os.path.getmtime(fullname)\n",
    "            if time > max_time:\n",
    "                max_time = time\n",
    "                result = dirname\n",
    "        return result\n",
    "\n",
    "        \n",
    "    def load(self, load_date=None):\n",
    "        save_path = self.save_path\n",
    "        # iterate the path, and find out the latest date as last_training_date\n",
    "        self.model = StatefulLstmModel()\n",
    "        \n",
    "        # get the latest directory\n",
    "        if load_date == None:\n",
    "            load_date = self.get_latest_dir(self.save_path)\n",
    "        \n",
    "        print(\"Loading model for date: {}\".format(load_date))\n",
    "        self.model.load(self.save_path, load_date)\n",
    "        \n",
    "        # load data manipulator\n",
    "        with open(self.get_data_manipulator_filename(), 'rb') as f:\n",
    "            self.data_manipulator = pickle.load(f)\n",
    "        \n",
    "        # load strategy\n",
    "        self.strategy_model = StrategyModel()\n",
    "        self.strategy_model.load(self.save_path)\n",
    "        print(\"Model loaded!\")\n",
    "        \n",
    "    def get_avg_profit_per_day(self, profit_list, split_daily_data):\n",
    "        profit_per_seq = sum(profit_list)/len(profit_list)\n",
    "        if split_daily_data == True:\n",
    "            return ((1+profit_per_seq)**2) - 1 \n",
    "        else:\n",
    "            return profit_per_seq\n",
    "        \n",
    "    def get_ema_profit_per_day(self, profit_list, split_daily_data):\n",
    "        window = int(len(profit_list)/2)\n",
    "        ema_profit_per_seq = get_ema(profit_list, window)\n",
    "        \n",
    "        if split_daily_data == True:\n",
    "            return ((1+ema_profit_per_seq)**2) - 1 \n",
    "        else:\n",
    "            return ema_profit_per_seq\n",
    "    \n",
    "    def opt_func(self, X_list):\n",
    "        assert(len(X_list)==1)\n",
    "        X_list = X_list[0]\n",
    "        print(self.get_parameter_str(X_list))\n",
    "        \n",
    "        # do 2-layer optimizations.\n",
    "        error_ema, error_mean, model, data_manipulator, strategy_model = \\\n",
    "            self.get_profit(X_list)\n",
    "\n",
    "        max_profit_list = strategy_model.get_max_profit_list()\n",
    "        \n",
    "        # get profit for the training period.\n",
    "        avg_profit_per_day = self.get_avg_profit_per_day(max_profit_list, data_manipulator.split_daily_data)\n",
    "        profit_ema_per_day = self.get_ema_profit_per_day(max_profit_list, data_manipulator.split_daily_data)\n",
    "        \n",
    "        # get the overall profit for the testing period.\n",
    "        test_profit = self.test(model, data_manipulator, strategy_model)\n",
    "        \n",
    "        print(\"FINAL RESULT: {},{},{},{},{}\".format(profit_ema_per_day, avg_profit_per_day,\n",
    "                                                 error_ema, error_mean , test_profit))\n",
    "        \n",
    "        if profit_ema_per_day > self.max_profit and profit_ema_per_day > 0:\n",
    "            #print(\"find the new best profit:{}, error:{}\".format(profit_ema_per_day, error_ema))\n",
    "            self.max_profit = profit_ema_per_day\n",
    "            self.model = model\n",
    "            self.data_manipulator = data_manipulator\n",
    "            self.strategy_model = strategy_model\n",
    "            #self.test()\n",
    "            self.save()\n",
    " \n",
    "            \n",
    "        return np.array(profit_ema_per_day).reshape((1,1))\n",
    "\n",
    "    def test(self, model, data_manipulator, strategy_model):        \n",
    "        data_testing_input, data_testing_output, timestamps, price \\\n",
    "            = data_manipulator.prep_testing_data('npy_files', self.stock_index)\n",
    "        \n",
    "        # first make a prediction, then do training.\n",
    "        n_learning_seqs = data_manipulator.n_learning_seqs\n",
    "        n_prediction_seqs = data_manipulator.n_prediction_seqs\n",
    "        \n",
    "        prediction_start = n_learning_seqs - n_prediction_seqs\n",
    "        prediction_end = prediction_start + n_prediction_seqs\n",
    "        \n",
    "        print(\"starting the first prediction from seq:{} to seq:{}\".format(prediction_start, prediction_end-1))\n",
    "        outputs = model.predict_and_verify(data_testing_input[prediction_start:prediction_end], \n",
    "                    data_testing_output[prediction_start:prediction_end])\n",
    "        \n",
    "        print(\"outputs\")\n",
    "        print(outputs.shape)\n",
    "        shape = outputs.shape\n",
    "        assert(shape[2]==1)\n",
    "        outputs = outputs.reshape((shape[0],shape[1]))\n",
    "        np_values, np_errors, next_prediction_seq = self.run_model(model, \n",
    "                                                                  data_testing_input, \n",
    "                                                                  data_testing_output, \n",
    "                                                                  n_learning_seqs, \n",
    "                                                                  n_prediction_seqs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        last_learning_date = self.get_date(timestamps, next_prediction_seq-1)\n",
    "        data_manipulator.update(next_prediction_seq, last_learning_date)\n",
    "        print(\"timestamps\")\n",
    "        print(timestamps[prediction_start:].shape)\n",
    "        print(outputs.shape)\n",
    "        print(np_values.shape)\n",
    "        print(price[prediction_start:].shape)\n",
    "        \n",
    "        outputs = np.concatenate((outputs, np_values), axis=0)\n",
    "        outputs = data_manipulator.inverse_transform_output(outputs)\n",
    "        strategy_data_input = np.stack((timestamps[prediction_start:], \n",
    "                                outputs,\n",
    "                                price[prediction_start:]), axis=2)\n",
    "        tot_profit = 1\n",
    "        for i in range(0, len(strategy_data_input), n_prediction_seqs):\n",
    "            start = i\n",
    "            end = min(i+n_prediction_seqs, len(strategy_data_input))\n",
    "            result = strategy_model.run_test(strategy_data_input[start:end])\n",
    "            tot_profit *= result\n",
    "            strategy_model.append_data(strategy_data_input[start:end])\n",
    "            strategy_model.optimize()\n",
    "        \n",
    "        #print(\"test finished, total profit: {} in {} seqs\".format(tot_profit, len(strategy_data_input)))\n",
    "        return tot_profit\n",
    "    \n",
    "    def get_date(self, timestamps, seq_no):\n",
    "        return timestamps[seq_no][0].date().strftime(\"%y%m%d\")\n",
    "\n",
    "    def get_profit(self, features):\n",
    "        n_neurons = int(features[0])\n",
    "        learning_rate = features[1]\n",
    "        num_layers = int(features[2])\n",
    "        rnn_type = int(features[3])\n",
    "        learning_period = int(features[4])\n",
    "        prediction_period = int(features[5])\n",
    "        n_repeats = int(features[6])\n",
    "        beta = int(features[7])\n",
    "        ema = int(features[8])\n",
    "        time_format = int(features[9])\n",
    "        volume_input = int(features[10])\n",
    "        use_centralized_bid = int(features[11])\n",
    "        split_daily_data = int(features[12])\n",
    "        \n",
    "        data_manipulator = DataManipulator(learning_period,\n",
    "                                           prediction_period,\n",
    "                                           beta, ema, \n",
    "                                           time_format, \n",
    "                                           volume_input, \n",
    "                                           use_centralized_bid, \n",
    "                                           split_daily_data, \n",
    "                                           self.n_training_days)\n",
    "        \n",
    "        data_training_input, data_training_output, timestamps, price \\\n",
    "            = data_manipulator.prep_training_data('npy_files', self.stock_index)\n",
    "        \n",
    "        model = StatefulLstmModel(n_neurons, learning_rate, num_layers, rnn_type, n_repeats)\n",
    "        \n",
    "        n_learning_seqs = data_manipulator.n_learning_seqs\n",
    "        n_prediction_seqs = data_manipulator.n_prediction_seqs\n",
    "        \n",
    "        np_values, np_errors, next_prediction_seq = self.run_model(model, data_training_input, data_training_output, \n",
    "                                            n_learning_seqs, n_prediction_seqs)\n",
    "        \n",
    "        last_learning_date = self.get_date(timestamps, next_prediction_seq-1)\n",
    "        data_manipulator.update(next_prediction_seq, last_learning_date)\n",
    "       \n",
    "        daily_errors = np.mean(np_errors, axis=1)\n",
    "        print(\"daily_errors\")\n",
    "        print(daily_errors.shape)\n",
    "        error_ema = get_ema(daily_errors, int(len(daily_errors)/2))\n",
    "        assert(len(daily_errors) != 0)\n",
    "        error_mean = np.sum(daily_errors)/len(daily_errors)\n",
    "        # find the best trade strategy.\n",
    "        # prepare data for the strategy optimization, including timestamp, value, price.\n",
    "        np_values = data_manipulator.inverse_transform_output(np_values)\n",
    "        strategy_data_input = np.stack((timestamps[n_learning_seqs:], \n",
    "                                        np_values, \n",
    "                                        price[n_learning_seqs:]), axis=2)\n",
    "        print(\"strategy_data_input\")\n",
    "        print(strategy_data_input.shape)\n",
    "        ema_window = int(strategy_data_input.shape[0]/2)\n",
    "        strategy_model = StrategyModel(ema_window)\n",
    "        strategy_model.append_data(strategy_data_input)\n",
    "        strategy_model.optimize()\n",
    "        return error_ema, error_mean, model, data_manipulator, strategy_model\n",
    "    \n",
    "    \n",
    "    # run the model, do learning and prediction at same time, \n",
    "    # this will be used for both training and testing.\n",
    "    # at the test phase, we should do prediction first\n",
    "    def run_model(self, model, data_input, data_output, n_learning_seqs, n_prediction_seqs):\n",
    "        # get the date list.\n",
    "        n_training_seqs = len(data_input)\n",
    "        errors = None\n",
    "        all_outputs = None\n",
    "        n_tot_prediction_seqs = 0\n",
    "        print(\"start training: training_seq:{}, learning_seq:{}, prediction_seq:{}\".format(n_training_seqs, \n",
    "                                                                                           n_learning_seqs, \n",
    "                                                                                           n_prediction_seqs,\n",
    "                                                                                          ))\n",
    "        for i in range(0, n_training_seqs-n_learning_seqs+1, n_prediction_seqs):\n",
    "            learning_end = i + n_learning_seqs\n",
    "            print(\"start training from seq:{} - seq:{}\".format(i, learning_end-1))\n",
    "            model.fit(data_input[i:learning_end], data_output[:learning_end], n_prediction_seqs)\n",
    "            next_prediction_seq = learning_end\n",
    "            prediction_end = min(learning_end+n_prediction_seqs, len(data_input))\n",
    "            \n",
    "            if prediction_end <= learning_end:\n",
    "                break\n",
    "            \n",
    "            print(\"start predicting from seq:{} - seq:{}\".format(learning_end, \n",
    "                                                                       prediction_end-1))\n",
    "            \n",
    "            outputs = model.predict_and_verify(data_input[learning_end:prediction_end], \n",
    "                                     data_output[learning_end:prediction_end])\n",
    "            print(\"output.shape\")\n",
    "            print(outputs.shape)\n",
    "            y = data_output[learning_end:prediction_end]\n",
    "            # error is a 1-D array for the every day error\n",
    "            error = np.square(outputs-y)\n",
    "            \n",
    "            n_tot_prediction_seqs += outputs.shape[0]\n",
    "            if i == 0:\n",
    "                all_outputs = outputs\n",
    "                errors = error\n",
    "            else:\n",
    "                all_outputs = np.concatenate((all_outputs, outputs), axis=0)\n",
    "                errors = np.concatenate((errors, error), axis=0)\n",
    "        return np.squeeze(all_outputs), np.squeeze(errors), next_prediction_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_verbose_func(verbose, msg):\n",
    "    if verbose == True:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradeStrategyDesc:\n",
    "    def __init__(self,\n",
    "                 X_list,\n",
    "                 ema_window,\n",
    "                 optimize_data):\n",
    "        self.buy_threshold = X_list[0]\n",
    "        self.sell_threshold = X_list[1]\n",
    "        self.stop_loss = X_list[2]\n",
    "        self.stop_gain = X_list[3]\n",
    "        self.min_hold_steps = X_list[4]\n",
    "        self.max_hold_steps = X_list[5]\n",
    "        self.ema_window = ema_window\n",
    "        self.optimize_data = optimize_data\n",
    "        \n",
    "    def get_parameter_str(self):\n",
    "        s = \"buy_threshold:{} sell_threshold:{} stop_loss:{} \\\n",
    "            stop_gain:{} min_hold_steps:{} max_hold_steps:{} ema_window:{} optimize_data:{}\".format(self.buy_threshold,\n",
    "                                                  self.sell_threshold,\n",
    "                                                  self.stop_loss,\n",
    "                                                  self.stop_gain,\n",
    "                                                  self.min_hold_steps,\n",
    "                                                  self.max_hold_steps,\n",
    "                                                  self.ema_window,\n",
    "                                                  self.optimize_data.shape)\n",
    "        return s\n",
    "    \n",
    "    \n",
    "    def to_list(self):\n",
    "        return [[self.buy_threshold, self.sell_threshold, self.stop_loss, self.stop_gain, \n",
    "                 self.min_hold_steps,\n",
    "                 self.max_hold_steps]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "class StrategyModel:\n",
    "    mixed_domain = [{'name': 'buy_threshold', 'type': 'continuous', 'domain': (0.0, 0.005)},\n",
    "                 {'name': 'sell_threshold', 'type': 'continuous', 'domain': (-0.005, 0.0)},\n",
    "                 {'name': 'stop_loss', 'type': 'continuous', 'domain': (-0.01,-0.003)},\n",
    "                 {'name': 'stop_gain', 'type': 'continuous', 'domain': (0.002, 0.01)},\n",
    "                 {'name': 'min_hold_steps', 'type': 'discrete', 'domain': range(10,100)},\n",
    "                 {'name': 'max_hold_steps', 'type': 'discrete', 'domain': range(50,200)},\n",
    "         ]\n",
    "    def __init__(self, ema_window=None):\n",
    "        self.max_profit = -999.0\n",
    "        self.strategy_desc = None\n",
    "        self.ema_window = ema_window\n",
    "        self.optimize_data = None\n",
    "        self.tot_profit = None\n",
    "        return\n",
    "    \n",
    "    # append the data for the optimization\n",
    "    def append_data(self, data):\n",
    "        if self.optimize_data is None:\n",
    "            self.optimize_data = data\n",
    "        else:\n",
    "            self.optimize_data = np.concatenate((self.optimize_data, data), axis=0)\n",
    "\n",
    "    def optimize(self):\n",
    "        self.trade_strategy_desc = None\n",
    "        self.max_profit_ema_per_step = -999.0\n",
    "        self.input_data = self.optimize_data\n",
    "        myBopt = GPyOpt.methods.BayesianOptimization(self.get_profit_ema,  # Objective function       \n",
    "                                             domain=self.mixed_domain,          # Box-constraints of the problem\n",
    "                                             initial_design_numdata = 30,   # Number data initial design\n",
    "                                             acquisition_type='EI',        # Expected Improvement\n",
    "                                             exact_feval = True,\n",
    "                                             maximize = True)           # True evaluations, no sample noise\n",
    "\n",
    "        myBopt.run_optimization(150,eps=0)\n",
    "        self.input_data = None\n",
    "        return 0\n",
    "    \n",
    "    def run_test(self, test_data):\n",
    "        print(\"starting test: {}\".format(self.trade_strategy_desc.get_parameter_str()))\n",
    "        X_list = self.trade_strategy_desc.to_list()\n",
    "        return self.get_total_profit(X_list, test_data)\n",
    "    \n",
    "    def get_total_profit(self, X_list, test_data):\n",
    "        assert(len(X_list) == 1)\n",
    "        tot_profit, n_tot_trades, daily_profit_list, _, _ = self.run_test_core(X_list[0], \n",
    "                                                                                     test_data, \n",
    "                                                                                     verbose=True)\n",
    "        \n",
    "        print(\"test finished: tot_profit:{} in {} seqs\".format(tot_profit,\n",
    "                                                                    len(daily_profit_list)))\n",
    "        return tot_profit\n",
    "    \n",
    "    # the input data is in shape (days, steps, [timestamp, value, price])\n",
    "    def get_profit_ema(self, X_list):\n",
    "        assert(len(X_list)==1)\n",
    "        X_list = X_list[0]\n",
    "        input_data = self.input_data[-self.ema_window*2:]\n",
    "        tot_profit, n_tot_trades, seq_profit_list, \\\n",
    "            stock_change_rate, asset_change_rate = self.run_test_core(X_list, input_data)\n",
    "            \n",
    "        profit_ema = get_ema(seq_profit_list, self.ema_window)\n",
    "        \n",
    "        profit_ema_per_step = profit_ema / self.input_data.shape[1]\n",
    "        if profit_ema_per_step > self.max_profit_ema_per_step:\n",
    "            print(\"find best profit_per_step: {} profit_ema:{} tot_profit:{} window:{}\".format(\n",
    "                                                                            profit_ema_per_step,\n",
    "                                                                            profit_ema,\n",
    "                                                                            tot_profit,\n",
    "                                                                            self.ema_window))\n",
    "\n",
    "            self.max_profit_ema_per_step = profit_ema_per_step\n",
    "            \n",
    "            self.change_rate = np.concatenate((input_data, \n",
    "                                              stock_change_rate,\n",
    "                                              asset_change_rate), axis=2)\n",
    "            self.trade_strategy_desc = TradeStrategyDesc(X_list,\n",
    "                                             self.ema_window,\n",
    "                                             self.optimize_data)\n",
    "            self.tot_profit = tot_profit\n",
    "            self.max_profit_list = seq_profit_list\n",
    "        \n",
    "        return np.array(profit_ema_per_step).reshape((1,1))\n",
    "    \n",
    "    def run_test_core(self, X_list, input_data, verbose=False):\n",
    "        print_verbose = partial(print_verbose_func, verbose)\n",
    "\n",
    "        buy_threshold = X_list[0]\n",
    "        sell_threshold = X_list[1]\n",
    "        stop_loss = X_list[2]\n",
    "        stop_gain = X_list[3]\n",
    "        min_hold_steps = int(X_list[4])\n",
    "        max_hold_steps = int(X_list[5])\n",
    "        tot_profit = 1\n",
    "        tot_stock_profit = 1\n",
    "        buy_step = None\n",
    "        max_trades = 3\n",
    "        cost = 0.00015/2\n",
    "        n_tot_trades = 0\n",
    "        # to prepare the result data\n",
    "        shape = input_data.shape\n",
    "\n",
    "        reshaped_price = input_data[:,:,2].reshape((shape[0]*shape[1]))\n",
    "        \n",
    "        stock_change_rate = np.diff(reshaped_price) / reshaped_price[:-1]\n",
    "        stock_change_rate = np.concatenate(([0], stock_change_rate)).reshape((shape[0],shape[1],1))\n",
    "        \n",
    "        asset_change_rate = np.zeros((stock_change_rate.shape))\n",
    "        \n",
    "        \n",
    "        daily_profit_list = []\n",
    "        \n",
    "        for day_idx in range(len(input_data)):\n",
    "            print_verbose(\"starting day {}\".format(day_idx))\n",
    "            n_trades = 0\n",
    "            daily_profit = 1\n",
    "            trade_profit = 1\n",
    "            state = 0\n",
    "            daily_data = input_data[day_idx]\n",
    "            hold_steps = 0\n",
    "            for step in range(len(daily_data)):\n",
    "                time = daily_data[step][0]\n",
    "                value = daily_data[step][1]\n",
    "                price = daily_data[step][2]\n",
    "                change_rate = stock_change_rate[day_idx][step][0]\n",
    "                if state == 0 and time.time().hour >= 9 and \\\n",
    "                    n_trades < max_trades and step < len(daily_data)-min_hold_steps and \\\n",
    "                    value > buy_threshold:\n",
    "                        state = 1\n",
    "                        asset_change_rate[day_idx][step][0] = -cost\n",
    "                        tot_profit *= (1-cost)\n",
    "                        daily_profit *= (1-cost)\n",
    "                        trade_profit *= (1-cost)\n",
    "                        print_verbose(\"buy at step: {} price:{}\".format(step, price))\n",
    "                elif state == 1:\n",
    "                    if (value < sell_threshold and \n",
    "                        hold_steps > min_hold_steps) or step == len(daily_data)-1 or \\\n",
    "                        trade_profit-1 < stop_loss or \\\n",
    "                        trade_profit-1 > stop_gain or \\\n",
    "                        hold_steps >= max_hold_steps:\n",
    "                        # don't do more trade today!\n",
    "                        if trade_profit-1 < stop_loss:\n",
    "                            print_verbose(\"stop loss stop trading!\")\n",
    "                            n_trades = max_trades\n",
    "\n",
    "                        change_rate = (1+change_rate)*(1-cost)-1 \n",
    "                        tot_profit *= (1 + change_rate)\n",
    "                        daily_profit *= (1 + change_rate)\n",
    "                        state = 0\n",
    "                        n_trades += 1\n",
    "                        print_verbose(\"sell at step: {} price:{} trade_profit:{} hold_steps:{}\".format(step, price, trade_profit, hold_steps))\n",
    "                        trade_profit = 1\n",
    "                        asset_change_rate[day_idx][step] = change_rate\n",
    "                        hold_steps = 0\n",
    "                        \n",
    "                    else:\n",
    "                        tot_profit *= (1+change_rate)\n",
    "                        daily_profit *= (1+change_rate)\n",
    "                        trade_profit *= (1+change_rate)\n",
    "                        asset_change_rate[day_idx][step][0] = change_rate\n",
    "                        hold_steps += 1\n",
    "            print_verbose(\"finished day {}, daily profit:{}\".format(day_idx,daily_profit))\n",
    "            daily_profit_list.append(daily_profit - 1)\n",
    "            n_tot_trades += n_trades\n",
    "    \n",
    "        return tot_profit, n_tot_trades, daily_profit_list, stock_change_rate, asset_change_rate\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def get_max_profit_list(self):\n",
    "        return self.max_profit_list\n",
    "    \n",
    "    def get_strategy_desc(self):\n",
    "        return self.trade_strategy_desc\n",
    "    \n",
    "    def get_save_filename(self, path):\n",
    "        return os.path.join(path, 'strategy_desc.pkl')\n",
    "    \n",
    "    def save(self, save_path):\n",
    "        assert(self.trade_strategy_desc != None)\n",
    "        with open(self.get_save_filename(save_path), 'wb') as f:\n",
    "            pickle.dump(self.trade_strategy_desc, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def load(self, save_path):\n",
    "        with open(self.get_save_filename(save_path), 'rb') as f:\n",
    "            self.trade_strategy_desc = pickle.load(f)\n",
    "        this.ema_window = self.trade_strategy_desc.ema_window\n",
    "        this.optimize_data = self.trade_strategy_desc.optimize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neurons:140.0,learning_rate:0.004,num_layers:4.0,rnn_type:1.0,learning_period:10.0,prediction_period:5.0,n_repeats:3.0,beta:99.0,ema:20.0,time_format:0.0,volume_input:1.0,use_centralized_bid:0.0,split_daily_data:0.0,\n",
      "start training: training_seq:60, learning_seq:10, prediction_seq:5\n",
      "start training from seq:0 - seq:9\n",
      "22:44:58.692093 repeat=0 training finished, training MSE=0.45916169811971486\n",
      "22:45:02.712990 repeat=1 training finished, training MSE=0.24278239688719622\n",
      "22:45:06.725486 repeat=2 training finished, training MSE=0.16429335637367332\n",
      "start predicting from seq:10 - seq:14\n",
      "Predicting seq:0 testing MSE: 0.002570953918620944\n",
      "Predicting seq:1 testing MSE: 0.0037227354478091\n",
      "Predicting seq:2 testing MSE: 0.003232399234548211\n",
      "Predicting seq:3 testing MSE: 0.002497389679774642\n",
      "Predicting seq:4 testing MSE: 0.00340624013915658\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:5 - seq:14\n",
      "22:45:11.984062 repeat=0 training finished, training MSE=0.5699627451598644\n",
      "22:45:15.961538 repeat=1 training finished, training MSE=0.30722281415946784\n",
      "22:45:19.945669 repeat=2 training finished, training MSE=0.20807845597737468\n",
      "start predicting from seq:15 - seq:19\n",
      "Predicting seq:0 testing MSE: 0.00021035804820712656\n",
      "Predicting seq:1 testing MSE: 0.0005699320463463664\n",
      "Predicting seq:2 testing MSE: 0.001193752745166421\n",
      "Predicting seq:3 testing MSE: 0.002381432568654418\n",
      "Predicting seq:4 testing MSE: 0.0007643260760232806\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:10 - seq:19\n",
      "22:45:25.636177 repeat=0 training finished, training MSE=0.49394539594650266\n",
      "22:45:29.594952 repeat=1 training finished, training MSE=0.26186395955155606\n",
      "22:45:33.608651 repeat=2 training finished, training MSE=0.17666708306836273\n",
      "start predicting from seq:20 - seq:24\n",
      "Predicting seq:0 testing MSE: 0.007653703913092613\n",
      "Predicting seq:1 testing MSE: 0.0077001312747597694\n",
      "Predicting seq:2 testing MSE: 0.0092935087159276\n",
      "Predicting seq:3 testing MSE: 0.008042637258768082\n",
      "Predicting seq:4 testing MSE: 0.007946829311549664\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:15 - seq:24\n",
      "22:45:38.932294 repeat=0 training finished, training MSE=0.5295735634863377\n",
      "22:45:42.965009 repeat=1 training finished, training MSE=0.28306203172542155\n",
      "22:45:47.020505 repeat=2 training finished, training MSE=0.19101033140226112\n",
      "start predicting from seq:25 - seq:29\n",
      "Predicting seq:0 testing MSE: 0.007937179878354073\n",
      "Predicting seq:1 testing MSE: 0.0027244852390140295\n",
      "Predicting seq:2 testing MSE: 0.0018415285740047693\n",
      "Predicting seq:3 testing MSE: 0.0031055014114826918\n",
      "Predicting seq:4 testing MSE: 0.0030288933776319027\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:20 - seq:29\n",
      "22:45:52.320058 repeat=0 training finished, training MSE=0.53485808968544\n",
      "22:45:56.355330 repeat=1 training finished, training MSE=0.2852710700390162\n",
      "22:46:00.385868 repeat=2 training finished, training MSE=0.1926842675326043\n",
      "start predicting from seq:30 - seq:34\n",
      "Predicting seq:0 testing MSE: 0.0022128408309072256\n",
      "Predicting seq:1 testing MSE: 0.0019148680148646235\n",
      "Predicting seq:2 testing MSE: 0.0017528620082885027\n",
      "Predicting seq:3 testing MSE: 0.002389124594628811\n",
      "Predicting seq:4 testing MSE: 0.001957144122570753\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:25 - seq:34\n",
      "22:46:05.716508 repeat=0 training finished, training MSE=0.4645454157143831\n",
      "22:46:09.761398 repeat=1 training finished, training MSE=0.24410150354960933\n",
      "22:46:13.855526 repeat=2 training finished, training MSE=0.16487142201901103\n",
      "start predicting from seq:35 - seq:39\n",
      "Predicting seq:0 testing MSE: 0.005371038801968098\n",
      "Predicting seq:1 testing MSE: 0.00722908042371273\n",
      "Predicting seq:2 testing MSE: 0.0066063860431313515\n",
      "Predicting seq:3 testing MSE: 0.005771298427134752\n",
      "Predicting seq:4 testing MSE: 0.007014488335698843\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:30 - seq:39\n",
      "22:46:20.258299 repeat=0 training finished, training MSE=0.5300130397081375\n",
      "22:46:24.297273 repeat=1 training finished, training MSE=0.2840779208781896\n",
      "22:46:29.569957 repeat=2 training finished, training MSE=0.19207952865835978\n",
      "start predicting from seq:40 - seq:44\n",
      "Predicting seq:0 testing MSE: 0.002194650936871767\n",
      "Predicting seq:1 testing MSE: 0.0020967295859009027\n",
      "Predicting seq:2 testing MSE: 0.0014239459997043014\n",
      "Predicting seq:3 testing MSE: 0.0011775853345170617\n",
      "Predicting seq:4 testing MSE: 0.007373431231826544\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:35 - seq:44\n",
      "22:46:36.652445 repeat=0 training finished, training MSE=0.4676499240798876\n",
      "22:46:41.825165 repeat=1 training finished, training MSE=0.24555390445166267\n",
      "22:46:46.680094 repeat=2 training finished, training MSE=0.16565270245967742\n",
      "start predicting from seq:45 - seq:49\n",
      "Predicting seq:0 testing MSE: 0.00030576286371797323\n",
      "Predicting seq:1 testing MSE: 0.00034607580164447427\n",
      "Predicting seq:2 testing MSE: 0.00021490569633897394\n",
      "Predicting seq:3 testing MSE: 0.00027146286447532475\n",
      "Predicting seq:4 testing MSE: 0.0001384145871270448\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:40 - seq:49\n",
      "22:46:52.000303 repeat=0 training finished, training MSE=0.5780562415719033\n",
      "22:46:56.010304 repeat=1 training finished, training MSE=0.3178196948720142\n",
      "22:47:00.081762 repeat=2 training finished, training MSE=0.21591787637638238\n",
      "start predicting from seq:50 - seq:54\n",
      "Predicting seq:0 testing MSE: 0.00043280445970594883\n",
      "Predicting seq:1 testing MSE: 0.0003416225372347981\n",
      "Predicting seq:2 testing MSE: 0.0004370682581793517\n",
      "Predicting seq:3 testing MSE: 0.00025776514667086303\n",
      "Predicting seq:4 testing MSE: 0.00023601435532327741\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:45 - seq:54\n",
      "22:47:05.902844 repeat=0 training finished, training MSE=0.49486292712390423\n",
      "22:47:09.920689 repeat=1 training finished, training MSE=0.2617098616086878\n",
      "22:47:13.974017 repeat=2 training finished, training MSE=0.17658615697097654\n",
      "start predicting from seq:55 - seq:59\n",
      "Predicting seq:0 testing MSE: 0.007024227641522884\n",
      "Predicting seq:1 testing MSE: 0.00644799554720521\n",
      "Predicting seq:2 testing MSE: 0.005857787560671568\n",
      "Predicting seq:3 testing MSE: 0.012327628210186958\n",
      "Predicting seq:4 testing MSE: 0.006966511253267527\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:50 - seq:59\n",
      "22:47:19.277700 repeat=0 training finished, training MSE=0.537436430901289\n",
      "22:47:23.282195 repeat=1 training finished, training MSE=0.2893900304508861\n",
      "22:47:27.306882 repeat=2 training finished, training MSE=0.19576979278353973\n",
      "updating, next_prediction_seq=60, last_learning_date=190423\n",
      "daily_errors\n",
      "(50,)\n",
      "strategy_data_input\n",
      "(50, 504, 3)\n",
      "find best profit_per_step: 2.4771087852125125e-06 profit_ema:0.0012484628277471062 tot_profit:1.0160911079463149 window:25\n",
      "find best profit_per_step: 4.557464070502169e-06 profit_ema:0.002296961891533093 tot_profit:1.0418851609020618 window:25\n",
      "find best profit_per_step: 4.992400679538409e-06 profit_ema:0.002516169942487358 tot_profit:1.0491521266900483 window:25\n",
      "find best profit_per_step: 5.1316757186646885e-06 profit_ema:0.002586364562207003 tot_profit:1.0545122403022422 window:25\n",
      "find best profit_per_step: 5.216415376630841e-06 profit_ema:0.002629073349821944 tot_profit:1.061555143873078 window:25\n",
      "find best profit_per_step: 5.35875125638224e-06 profit_ema:0.002700810633216649 tot_profit:1.0561793197856544 window:25\n",
      "find best profit_per_step: 5.567789990578609e-06 profit_ema:0.002806166155251619 tot_profit:1.0507333013142426 window:25\n",
      "starting the first prediction from seq:5 to seq:9\n",
      "Predicting seq:0 testing MSE: 0.0005219506565481424\n",
      "Predicting seq:1 testing MSE: 0.00022012737463228405\n",
      "Predicting seq:2 testing MSE: 0.00015595409786328673\n",
      "Predicting seq:3 testing MSE: 0.0013208136660978198\n",
      "Predicting seq:4 testing MSE: 0.0003441325097810477\n",
      "outputs\n",
      "(5, 504, 1)\n",
      "start training: training_seq:27, learning_seq:10, prediction_seq:5\n",
      "start training from seq:0 - seq:9\n",
      "22:49:17.516184 repeat=0 training finished, training MSE=0.4948042772710323\n",
      "22:49:21.495811 repeat=1 training finished, training MSE=0.26211069023702294\n",
      "22:49:25.554674 repeat=2 training finished, training MSE=0.17690376332902816\n",
      "start predicting from seq:10 - seq:14\n",
      "Predicting seq:0 testing MSE: 0.006013812497258186\n",
      "Predicting seq:1 testing MSE: 0.007326554972678423\n",
      "Predicting seq:2 testing MSE: 0.007946021854877472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting seq:3 testing MSE: 0.006683412939310074\n",
      "Predicting seq:4 testing MSE: 0.008816185407340527\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:5 - seq:14\n",
      "22:49:30.869865 repeat=0 training finished, training MSE=0.4934246141463518\n",
      "22:49:34.912743 repeat=1 training finished, training MSE=0.2605507613858208\n",
      "22:49:38.942441 repeat=2 training finished, training MSE=0.175759832172965\n",
      "start predicting from seq:15 - seq:19\n",
      "Predicting seq:0 testing MSE: 0.007307407446205616\n",
      "Predicting seq:1 testing MSE: 0.007426689378917217\n",
      "Predicting seq:2 testing MSE: 0.007452842313796282\n",
      "Predicting seq:3 testing MSE: 0.00518311420455575\n",
      "Predicting seq:4 testing MSE: 0.006016259081661701\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:10 - seq:19\n",
      "22:49:44.332192 repeat=0 training finished, training MSE=0.506155239790678\n",
      "22:49:48.455599 repeat=1 training finished, training MSE=0.26655471262492936\n",
      "22:49:52.547081 repeat=2 training finished, training MSE=0.17920345944003202\n",
      "start predicting from seq:20 - seq:24\n",
      "Predicting seq:0 testing MSE: 0.005130081437528133\n",
      "Predicting seq:1 testing MSE: 0.005699778441339731\n",
      "Predicting seq:2 testing MSE: 0.004044748842716217\n",
      "Predicting seq:3 testing MSE: 0.005910879001021385\n",
      "Predicting seq:4 testing MSE: 0.0055007897317409515\n",
      "output.shape\n",
      "(5, 504, 1)\n",
      "start training from seq:15 - seq:24\n",
      "22:49:57.935079 repeat=0 training finished, training MSE=0.5026339679956436\n",
      "22:50:02.045275 repeat=1 training finished, training MSE=0.2658001526491717\n",
      "22:50:06.196628 repeat=2 training finished, training MSE=0.17898077057034242\n",
      "start predicting from seq:25 - seq:26\n",
      "Predicting seq:0 testing MSE: 0.0062752109952270985\n",
      "Predicting seq:1 testing MSE: 0.005549131892621517\n",
      "output.shape\n",
      "(2, 504, 1)\n",
      "updating, next_prediction_seq=25, last_learning_date=190515\n",
      "timestamps\n",
      "(22, 504)\n",
      "(5, 504)\n",
      "(17, 504)\n",
      "(22, 504)\n",
      "starting test: buy_threshold:0.0007740756748902063 sell_threshold:-0.0029685560007890886 stop_loss:-0.005613201519512829             stop_gain:0.007594102646985928 min_hold_steps:97.0 max_hold_steps:153.0 ema_window:25 optimize_data:(50, 504, 3)\n",
      "starting day 0\n",
      "buy at step: 0 price:77.56\n",
      "sell at step: 17 price:78.3 trade_profit:1.008176057246004 hold_steps:16\n",
      "finished day 0, daily profit:1.0093895750443211\n",
      "starting day 1\n",
      "finished day 1, daily profit:1\n",
      "starting day 2\n",
      "finished day 2, daily profit:1\n",
      "starting day 3\n",
      "finished day 3, daily profit:1\n",
      "starting day 4\n",
      "finished day 4, daily profit:1\n",
      "test finished: tot_profit:1.0093895750443211 in 5 seqs\n",
      "find best profit_per_step: 1.6281214918424118e-06 profit_ema:0.0008205732318885755 tot_profit:1.0160911079463149 window:25\n",
      "find best profit_per_step: 3.5471897557142655e-06 profit_ema:0.0017877836368799898 tot_profit:1.0462955139595995 window:25\n",
      "find best profit_per_step: 3.5641832223483516e-06 profit_ema:0.0017963483440635692 tot_profit:1.0409627534007435 window:25\n",
      "find best profit_per_step: 3.5903329069486683e-06 profit_ema:0.001809527785102129 tot_profit:1.042821089761904 window:25\n",
      "find best profit_per_step: 3.969280479850068e-06 profit_ema:0.0020005173618444345 tot_profit:1.0475038872973348 window:25\n",
      "find best profit_per_step: 4.398119477659946e-06 profit_ema:0.002216652216740613 tot_profit:1.0632235233871818 window:25\n",
      "find best profit_per_step: 4.586845085246753e-06 profit_ema:0.0023117699229643638 tot_profit:1.0716356146275978 window:25\n",
      "find best profit_per_step: 4.608991173046845e-06 profit_ema:0.0023229315512156095 tot_profit:1.0727234780100117 window:25\n",
      "starting test: buy_threshold:0.0002389123513463703 sell_threshold:-0.0017547405237379958 stop_loss:-0.00554431757577464             stop_gain:0.005882362352545393 min_hold_steps:83.0 max_hold_steps:155.0 ema_window:25 optimize_data:(55, 504, 3)\n",
      "starting day 0\n",
      "finished day 0, daily profit:1\n",
      "starting day 1\n",
      "finished day 1, daily profit:1\n",
      "starting day 2\n",
      "finished day 2, daily profit:1\n",
      "starting day 3\n",
      "finished day 3, daily profit:1\n",
      "starting day 4\n",
      "finished day 4, daily profit:1\n",
      "test finished: tot_profit:1 in 5 seqs\n",
      "find best profit_per_step: -2.0202155395169795e-07 profit_ema:-0.00010181886319165576 tot_profit:0.9899440318059827 window:25\n",
      "find best profit_per_step: 2.046560700369395e-06 profit_ema:0.0010314665929861751 tot_profit:1.0597754264996755 window:25\n",
      "find best profit_per_step: 3.1890889310742038e-06 profit_ema:0.0016073008212613986 tot_profit:1.083047211638388 window:25\n",
      "starting test: buy_threshold:0.00018563491971790137 sell_threshold:-0.0008337282688914592 stop_loss:-0.007812948429740896             stop_gain:0.009570525544123503 min_hold_steps:85.0 max_hold_steps:189.0 ema_window:25 optimize_data:(60, 504, 3)\n",
      "starting day 0\n",
      "finished day 0, daily profit:1\n",
      "starting day 1\n",
      "finished day 1, daily profit:1\n",
      "starting day 2\n",
      "finished day 2, daily profit:1\n",
      "starting day 3\n",
      "finished day 3, daily profit:1\n",
      "starting day 4\n",
      "finished day 4, daily profit:1\n",
      "test finished: tot_profit:1 in 5 seqs\n",
      "find best profit_per_step: -3.3962813206361745e-07 profit_ema:-0.0001711725785600632 tot_profit:0.9773129344229019 window:25\n",
      "find best profit_per_step: 1.1705398929071047e-06 profit_ema:0.0005899521060251807 tot_profit:1.040909966937127 window:25\n",
      "find best profit_per_step: 1.318711048127459e-06 profit_ema:0.0006646303682562393 tot_profit:1.0644622862437088 window:25\n",
      "find best profit_per_step: 1.3404443712368114e-06 profit_ema:0.0006755839631033529 tot_profit:1.0603193266551756 window:25\n",
      "find best profit_per_step: 1.6663413446997437e-06 profit_ema:0.0008398360377286708 tot_profit:1.081200932581916 window:25\n",
      "find best profit_per_step: 1.6738266785795386e-06 profit_ema:0.0008436086460040875 tot_profit:1.0819544736705002 window:25\n",
      "find best profit_per_step: 1.8223290516418332e-06 profit_ema:0.0009184538420274839 tot_profit:1.0985124767350316 window:25\n",
      "find best profit_per_step: 1.8653705467044109e-06 profit_ema:0.000940146755539023 tot_profit:1.1013963256584374 window:25\n",
      "starting test: buy_threshold:0.0 sell_threshold:-0.005 stop_loss:-0.003             stop_gain:0.01 min_hold_steps:63.0 max_hold_steps:183.0 ema_window:25 optimize_data:(65, 504, 3)\n",
      "starting day 0\n",
      "finished day 0, daily profit:1\n",
      "starting day 1\n",
      "finished day 1, daily profit:1\n",
      "starting day 2\n",
      "finished day 2, daily profit:1\n",
      "starting day 3\n",
      "finished day 3, daily profit:1\n",
      "starting day 4\n",
      "finished day 4, daily profit:1\n",
      "test finished: tot_profit:1 in 5 seqs\n",
      "find best profit_per_step: 4.0895833458576564e-08 profit_ema:2.061150006312259e-05 tot_profit:1.003728309084486 window:25\n",
      "find best profit_per_step: 5.82850301051089e-08 profit_ema:2.9375655172974886e-05 tot_profit:1.0054117590363445 window:25\n",
      "find best profit_per_step: 8.910811681154235e-07 profit_ema:0.00044910490873017344 tot_profit:1.0647235905284846 window:25\n",
      "find best profit_per_step: 9.991580133542573e-07 profit_ema:0.0005035756387305457 tot_profit:1.0752898807726425 window:25\n",
      "find best profit_per_step: 1.1472537025124018e-06 profit_ema:0.0005782158660662505 tot_profit:1.0900304693889373 window:25\n",
      "find best profit_per_step: 1.2099136621468006e-06 profit_ema:0.0006097964857219875 tot_profit:1.0964347219162285 window:25\n",
      "starting test: buy_threshold:0.00016929977902948535 sell_threshold:-0.00425655095203854 stop_loss:-0.0035433278241691645             stop_gain:0.008967258110379912 min_hold_steps:60.0 max_hold_steps:151.0 ema_window:25 optimize_data:(70, 504, 3)\n",
      "starting day 0\n",
      "finished day 0, daily profit:1\n",
      "starting day 1\n",
      "finished day 1, daily profit:1\n",
      "test finished: tot_profit:1 in 2 seqs\n",
      "find best profit_per_step: -2.1069309664127737e-07 profit_ema:-0.00010618932070720379 tot_profit:0.9803706368030038 window:25\n",
      "find best profit_per_step: -1.0963227249381979e-07 profit_ema:-5.525466533688517e-05 tot_profit:0.9896980997983847 window:25\n",
      "find best profit_per_step: 4.41512417577233e-07 profit_ema:0.00022252225845892544 tot_profit:1.0345254156414507 window:25\n",
      "find best profit_per_step: 7.484050689478213e-07 profit_ema:0.00037719615474970193 tot_profit:1.0552364919736577 window:25\n",
      "find best profit_per_step: 9.418553158107932e-07 profit_ema:0.00047469507916863976 tot_profit:1.074265735809814 window:25\n",
      "find best profit_per_step: 1.0074364704195047e-06 profit_ema:0.0005077479810914304 tot_profit:1.0777321210228394 window:25\n",
      "find best profit_per_step: 1.070069770250238e-06 profit_ema:0.00053931516420612 tot_profit:1.0868058369314888 window:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find best profit_per_step: 1.073439010913584e-06 profit_ema:0.0005410132615004463 tot_profit:1.0871632834453597 window:25\n",
      "find best profit_per_step: 1.1267418906869273e-06 profit_ema:0.0005678779129062114 tot_profit:1.0926108164771289 window:25\n",
      "FINAL RESULT: 0.002806166155251619,0.0010105144741955519,0.0039017133803441735,0.003558308855627555,1.0093895750443211\n",
      "Model saved in path: model_Nordea_60\n",
      "n_neurons:80.0,learning_rate:0.001,num_layers:1.0,rnn_type:1.0,learning_period:10.0,prediction_period:10.0,n_repeats:3.0,beta:99.0,ema:10.0,time_format:0.0,volume_input:1.0,use_centralized_bid:0.0,split_daily_data:0.0,\n",
      "start training: training_seq:60, learning_seq:10, prediction_seq:10\n",
      "start training from seq:0 - seq:9\n",
      "22:59:30.305718 repeat=0 training finished, training MSE=0.23663867795839905\n",
      "22:59:31.154432 repeat=1 training finished, training MSE=0.12852569535316433\n",
      "22:59:31.977198 repeat=2 training finished, training MSE=0.0883199328246216\n",
      "start predicting from seq:10 - seq:19\n",
      "Predicting seq:0 testing MSE: 0.0019658710807561874\n",
      "Predicting seq:1 testing MSE: 0.0010226002195850015\n",
      "Predicting seq:2 testing MSE: 0.0013235145015642047\n",
      "Predicting seq:3 testing MSE: 0.0019712590146809816\n",
      "Predicting seq:4 testing MSE: 0.0020877027418464422\n",
      "Predicting seq:5 testing MSE: 0.0015963275218382478\n",
      "Predicting seq:6 testing MSE: 0.002218711655586958\n",
      "Predicting seq:7 testing MSE: 0.0038152989000082016\n",
      "Predicting seq:8 testing MSE: 0.006764721125364304\n",
      "Predicting seq:9 testing MSE: 0.0027398765087127686\n",
      "output.shape\n",
      "(10, 504, 1)\n",
      "start training from seq:10 - seq:19\n",
      "22:59:33.306728 repeat=0 training finished, training MSE=0.2367313601076603\n",
      "22:59:33.936826 repeat=1 training finished, training MSE=0.12810396243585273\n",
      "22:59:34.563394 repeat=2 training finished, training MSE=0.08793259659044755\n",
      "start predicting from seq:20 - seq:29\n",
      "Predicting seq:0 testing MSE: 0.00118539750110358\n",
      "Predicting seq:1 testing MSE: 0.0013449047692120075\n",
      "Predicting seq:2 testing MSE: 0.0010390101233497262\n",
      "Predicting seq:3 testing MSE: 0.0013095657341182232\n",
      "Predicting seq:4 testing MSE: 0.0012211306020617485\n",
      "Predicting seq:5 testing MSE: 0.008650141768157482\n",
      "Predicting seq:6 testing MSE: 0.0019162798998877406\n",
      "Predicting seq:7 testing MSE: 0.0027346047572791576\n",
      "Predicting seq:8 testing MSE: 0.0017329126130789518\n",
      "Predicting seq:9 testing MSE: 0.0006960938917472959\n",
      "output.shape\n",
      "(10, 504, 1)\n",
      "start training from seq:20 - seq:29\n",
      "22:59:35.895143 repeat=0 training finished, training MSE=0.23598381779156624\n",
      "22:59:36.525745 repeat=1 training finished, training MSE=0.12951879959728102\n",
      "22:59:37.221466 repeat=2 training finished, training MSE=0.08907908849262942\n",
      "start predicting from seq:30 - seq:39\n",
      "Predicting seq:0 testing MSE: 0.0007895795279182494\n",
      "Predicting seq:1 testing MSE: 0.0006928351940587163\n",
      "Predicting seq:2 testing MSE: 0.0009331859182566404\n",
      "Predicting seq:3 testing MSE: 0.00046656778431497514\n",
      "Predicting seq:4 testing MSE: 0.0009186888346448541\n",
      "Predicting seq:5 testing MSE: 0.0005672598490491509\n",
      "Predicting seq:6 testing MSE: 0.001436231192201376\n",
      "Predicting seq:7 testing MSE: 0.0007750688819214702\n",
      "Predicting seq:8 testing MSE: 0.0005875863716937602\n",
      "Predicting seq:9 testing MSE: 0.0009349167812615633\n",
      "output.shape\n",
      "(10, 504, 1)\n",
      "start training from seq:30 - seq:39\n",
      "22:59:38.568035 repeat=0 training finished, training MSE=0.23651695069856943\n",
      "22:59:39.283264 repeat=1 training finished, training MSE=0.12959273153101095\n",
      "22:59:40.052370 repeat=2 training finished, training MSE=0.08896870034222956\n",
      "start predicting from seq:40 - seq:49\n",
      "Predicting seq:0 testing MSE: 0.0010741138830780983\n",
      "Predicting seq:1 testing MSE: 0.0008098449325188994\n",
      "Predicting seq:2 testing MSE: 0.003270740620791912\n",
      "Predicting seq:3 testing MSE: 0.004760687705129385\n",
      "Predicting seq:4 testing MSE: 0.007432162761688232\n",
      "Predicting seq:5 testing MSE: 0.0019307542825117707\n",
      "Predicting seq:6 testing MSE: 0.00146204954944551\n",
      "Predicting seq:7 testing MSE: 0.0012059247819706798\n",
      "Predicting seq:8 testing MSE: 0.0016121187945827842\n",
      "Predicting seq:9 testing MSE: 0.0009565853397361934\n",
      "output.shape\n",
      "(10, 504, 1)\n",
      "start training from seq:40 - seq:49\n",
      "22:59:42.450278 repeat=0 training finished, training MSE=0.23489050026983022\n",
      "22:59:43.274428 repeat=1 training finished, training MSE=0.1281982061889721\n",
      "22:59:44.004140 repeat=2 training finished, training MSE=0.08821381520441113\n",
      "start predicting from seq:50 - seq:59\n",
      "Predicting seq:0 testing MSE: 0.0007494358578696847\n",
      "Predicting seq:1 testing MSE: 0.0005686702788807452\n",
      "Predicting seq:2 testing MSE: 0.0009505213238298893\n",
      "Predicting seq:3 testing MSE: 0.0008077928214333951\n",
      "Predicting seq:4 testing MSE: 0.0006670037400908768\n",
      "Predicting seq:5 testing MSE: 0.0010255568195134401\n",
      "Predicting seq:6 testing MSE: 0.0006265841075219214\n",
      "Predicting seq:7 testing MSE: 0.00087959278607741\n",
      "Predicting seq:8 testing MSE: 0.013337907381355762\n",
      "Predicting seq:9 testing MSE: 0.003712958190590143\n",
      "output.shape\n",
      "(10, 504, 1)\n",
      "start training from seq:50 - seq:59\n",
      "22:59:45.406802 repeat=0 training finished, training MSE=0.2463922725059092\n",
      "22:59:46.030263 repeat=1 training finished, training MSE=0.1426776582666207\n",
      "22:59:46.709842 repeat=2 training finished, training MSE=0.1015163542275938\n",
      "updating, next_prediction_seq=60, last_learning_date=190423\n",
      "daily_errors\n",
      "(50,)\n",
      "strategy_data_input\n",
      "(50, 504, 3)\n",
      "find best profit_per_step: 3.6281265326369757e-06 profit_ema:0.0018285757724490358 tot_profit:0.9967558056564335 window:25\n",
      "find best profit_per_step: 4.022142137875676e-06 profit_ema:0.0020271596374893406 tot_profit:1.0147799013766947 window:25\n",
      "find best profit_per_step: 4.56071304452677e-06 profit_ema:0.0022985993744414923 tot_profit:1.0283142167130424 window:25\n",
      "find best profit_per_step: 4.582527652893551e-06 profit_ema:0.0023095939370583497 tot_profit:1.0202602380267913 window:25\n",
      "find best profit_per_step: 5.965022361235569e-06 profit_ema:0.003006371270062727 tot_profit:1.055305850162218 window:25\n",
      "find best profit_per_step: 6.101156707017145e-06 profit_ema:0.003074982980336641 tot_profit:1.042128395814403 window:25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-511-c2ce4ce8a761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvalue_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValueModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Nordea'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalue_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-507-f7c262eecef6>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, max_iter, is_test)\u001b[0m\n\u001b[1;32m     81\u001b[0m                                      \u001b[0macquisition_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EI'\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m# Expected Improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                                      \u001b[0mexact_feval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                                      maximize = True)           # True evaluations, no sample noise\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mopt_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/methods/bayesian_optimization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, domain, constraints, cost_withGradients, model_type, X, Y, initial_design_numdata, initial_design_type, acquisition_type, normalize_Y, exact_feval, acquisition_optimizer_type, model_update_interval, evaluator_type, batch_size, num_cores, verbosity, verbosity_model, maximize, de_duplication, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_type\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minitial_design_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_numdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_design_numdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_design_chooser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# --- CHOOSE the model type. If an instance of a GPyOpt model is passed (possibly user defined), it is used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/methods/bayesian_optimization.py\u001b[0m in \u001b[0;36m_init_design_chooser\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_design\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_design_numdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;31m# Case 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/core/task/objective.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_procs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/core/task/objective.py\u001b[0m in \u001b[0;36m_eval_func\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mst_time\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mrlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mf_evals\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrlt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mcost_evals\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/methods/bayesian_optimization.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    199\u001b[0m          \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m              \u001b[0mf_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m              \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mf_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m          \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-507-f7c262eecef6>\u001b[0m in \u001b[0;36mopt_func\u001b[0;34m(self, X_list)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# do 2-layer optimizations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0merror_ema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_manipulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy_model\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_profit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mmax_profit_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_max_profit_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-507-f7c262eecef6>\u001b[0m in \u001b[0;36mget_profit\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mstrategy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStrategyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mema_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mstrategy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy_data_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mstrategy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0merror_ema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_manipulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-510-cac648b975ff>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m                                              maximize = True)           # True evaluations, no sample noise\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mmyBopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/core/bo.py\u001b[0m in \u001b[0;36mrun_optimization\u001b[0;34m(self, max_iter, max_time, eps, context, verbosity, save_models_parameters, report_file, evaluations_file, models_file)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggested_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_next_evaluations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# --- Augment X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/core/bo.py\u001b[0m in \u001b[0;36m_compute_next_evaluations\u001b[0;34m(self, pending_zipped_X, ignored_zipped_X)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m### We zip the value in case there are categorical variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduplicate_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduplicate_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquisition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalization_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'stats'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/core/evaluators/sequential.py\u001b[0m in \u001b[0;36mcompute_batch\u001b[0;34m(self, duplicate_manager, context_manager)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mSelects\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0mto\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquisition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduplicate_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduplicate_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/acquisitions/base.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, duplicate_manager)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduplicate_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduplicate_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquisition_function_withGradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduplicate_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduplicate_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/optimization/acquisition_optimizer.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, f, df, f_df, duplicate_manager)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m## -- Select the anchor points (with context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0manchor_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor_points_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduplicate_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduplicate_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m## --- Applying local optimizers at the anchor points and update bounds of the optimizer (according to the context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/optimization/anchor_points_generator.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, num_anchor, duplicate_manager, unique, context_manager)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mis_duplicate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mnon_duplicate_anchor_point_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnon_duplicate_anchor_point_indexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/GPyOpt/optimization/anchor_points_generator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mis_duplicate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mnon_duplicate_anchor_point_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnon_duplicate_anchor_point_indexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "value_model = ValueModel('Nordea', 5, 60)\n",
    "value_model.optimize(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_model = ValueModel('Nordea', 5, 60)\n",
    "value_model.load()\n",
    "value_model.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
